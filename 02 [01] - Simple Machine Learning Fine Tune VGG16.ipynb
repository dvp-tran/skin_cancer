{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Â Skin Cancer Classification Challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Summary : ** skin cancer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminaries and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#general & system\\n\",\n",
    "import os\n",
    "\n",
    "#data processing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.rcParams['figure.figsize'] = 10, 10  #default setting\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "#data augmentation\n",
    "from PIL import Image\n",
    "from random import choice\n",
    "import cv2\n",
    "import numpy as np\n",
    "#import keras.preprocessing.image as prep\n",
    "\n",
    "#ML part\n",
    "from keras.applications import VGG16\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.preprocessing import image as kimage\n",
    "from keras.models import Sequential\n",
    "from keras.layers import GlobalMaxPooling2D, Dense, BatchNormalization, GlobalAveragePooling2D, Dropout,Activation,Flatten\n",
    "from keras.models import Model\n",
    "from keras.optimizers import SGD\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "#validation\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Rq : ** Datasets are quite light, can be fully loaded in a laptop memory with ease."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8 ms, sys: 0 ns, total: 8 ms\n",
      "Wall time: 6.05 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "meta = pd.read_csv(\"data/metadata.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.3 s, sys: 172 ms, total: 3.47 s\n",
      "Wall time: 3.47 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "filelist = os.listdir(\"data/resized/\")\n",
    "X_train = np.array([np.array(Image.open(\"data/resized/\"+fname)) for fname in filelist])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1900, 299, 299, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get target\n",
    "filelist = [x.replace(\".jpg\",\"\") for x in filelist]\n",
    "strates = [meta[meta[\"name\"]==x][\"meta_clinical_benign_malignant\"].values[0] for x in filelist]\n",
    "Y_train = [1 if x==\"malignant\" else 0 for x in strates]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ISIC_0000256', 'ISIC_0012768', 'ISIC_0012987', 'ISIC_0013676', 'ISIC_0013911']\n",
      "[0, 0, 0, 0, 0]\n",
      "['benign', 'benign', 'benign', 'indeterminate/benign', 'benign']\n"
     ]
    }
   ],
   "source": [
    "#control\n",
    "print(filelist[0:5])\n",
    "print(Y_train[0:5])\n",
    "print(strates[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Resampling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Class weights**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class_weight = class_weight.compute_class_weight('balanced', np.unique(Y_train), Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Data splitting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#data splitting\n",
    "X_train, X_valid, Y_train, Y_valid = train_test_split(X_train, Y_train, random_state=42, train_size=0.80,\n",
    "                                                      stratify = strates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III. Deep Learning with Transfer Learning"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# generator from folder\n",
    "batch_size = 16\n",
    "\n",
    "# prepare data augmentation configuration\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        target_size=(img_height, img_width),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        validation_data_dir,\n",
    "        target_size=(img_height, img_width),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary')\n",
    "\n",
    "# fine-tune the model\n",
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=nb_train_samples // batch_size,\n",
    "        epochs=epochs,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=nb_validation_samples // batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weights_path = 'model/checkpoints/'\n",
    "\n",
    "if not os.path.exists(weights_path):\n",
    "    os.makedirs(weights_path)\n",
    "    \n",
    "epochs = 500\n",
    "batch_size = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Using VGG16 : **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 299, 299, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 299, 299, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 299, 299, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 149, 149, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 149, 149, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 149, 149, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 74, 74, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 74, 74, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 74, 74, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 74, 74, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 37, 37, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 37, 37, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 37, 37, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 37, 37, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 18, 18, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 9, 9, 512)         0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#load base model\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(299,299,3))\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 299, 299, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 299, 299, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 299, 299, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 149, 149, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 149, 149, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 149, 149, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 74, 74, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 74, 74, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 74, 74, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 74, 74, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 37, 37, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 37, 37, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 37, 37, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 37, 37, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 18, 18, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 9, 9, 512)         0         \n",
      "_________________________________________________________________\n",
      "sequential_1 (Sequential)    (None, 1)                 42993665  \n",
      "=================================================================\n",
      "Total params: 57,708,353\n",
      "Trainable params: 57,708,353\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#adding top layers\n",
    "    #sequentialy\n",
    "add_model = Sequential()\n",
    "add_model.add(Flatten(input_shape=base_model.output_shape[1:])) #Flatten/GlobalAveragePooling2D\n",
    "add_model.add(Dense(1024, activation='relu'))\n",
    "add_model.add(Dropout(0.25))\n",
    "add_model.add(Dense(512, activation='relu'))\n",
    "add_model.add(Dropout(0.25))\n",
    "add_model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=add_model(base_model.output))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#adding top layers\n",
    "    #need to check api to add layers sequentialy\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x) #Flatten instead?\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "x = Dropout(0.25)(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = Dropout(0.25)(x)\n",
    "predictions = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#freeze lower layers of the model\n",
    "#for layer in model.layers[:]:\n",
    "    #layer.trainable = False\n",
    "for layer in model.layers[0:]:\n",
    "    layer.trainable = True\n",
    "    \n",
    "#compile\n",
    "#model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.compile(optimizer=SGD(lr=0.0001, momentum=0.9), loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "151/152 [============================>.] - ETA: 1s - loss: 0.6879 - acc: 0.7483Epoch 00001: val_loss improved from inf to 0.56682, saving model to model/checkpoints/BestKerasModelVGG16_flat.h5\n",
      "152/152 [==============================] - 191s 1s/step - loss: 0.6863 - acc: 0.7487 - val_loss: 0.5668 - val_acc: 0.7737\n",
      "Epoch 2/500\n",
      "151/152 [============================>.] - ETA: 1s - loss: 0.5457 - acc: 0.7735Epoch 00002: val_loss improved from 0.56682 to 0.52996, saving model to model/checkpoints/BestKerasModelVGG16_flat.h5\n",
      "152/152 [==============================] - 194s 1s/step - loss: 0.5461 - acc: 0.7730 - val_loss: 0.5300 - val_acc: 0.7737\n",
      "Epoch 3/500\n",
      "151/152 [============================>.] - ETA: 1s - loss: 0.5327 - acc: 0.7735Epoch 00003: val_loss improved from 0.52996 to 0.52082, saving model to model/checkpoints/BestKerasModelVGG16_flat.h5\n",
      "152/152 [==============================] - 196s 1s/step - loss: 0.5339 - acc: 0.7730 - val_loss: 0.5208 - val_acc: 0.7737\n",
      "Epoch 4/500\n",
      "151/152 [============================>.] - ETA: 1s - loss: 0.5333 - acc: 0.7728Epoch 00004: val_loss did not improve\n",
      "152/152 [==============================] - 193s 1s/step - loss: 0.5333 - acc: 0.7724 - val_loss: 0.5228 - val_acc: 0.7737\n",
      "Epoch 5/500\n",
      "151/152 [============================>.] - ETA: 1s - loss: 0.5228 - acc: 0.7735Epoch 00005: val_loss did not improve\n",
      "152/152 [==============================] - 201s 1s/step - loss: 0.5225 - acc: 0.7737 - val_loss: 0.5273 - val_acc: 0.7737\n",
      "Epoch 6/500\n",
      "151/152 [============================>.] - ETA: 1s - loss: 0.5158 - acc: 0.7742Epoch 00006: val_loss improved from 0.52082 to 0.49873, saving model to model/checkpoints/BestKerasModelVGG16_flat.h5\n",
      "152/152 [==============================] - 205s 1s/step - loss: 0.5149 - acc: 0.7750 - val_loss: 0.4987 - val_acc: 0.7737\n",
      "Epoch 7/500\n",
      "151/152 [============================>.] - ETA: 1s - loss: 0.5113 - acc: 0.7682Epoch 00007: val_loss did not improve\n",
      "152/152 [==============================] - 204s 1s/step - loss: 0.5116 - acc: 0.7684 - val_loss: 0.5113 - val_acc: 0.7816\n",
      "Epoch 8/500\n",
      "151/152 [============================>.] - ETA: 1s - loss: 0.5041 - acc: 0.7695Epoch 00008: val_loss did not improve\n",
      "152/152 [==============================] - 202s 1s/step - loss: 0.5040 - acc: 0.7697 - val_loss: 0.5066 - val_acc: 0.7737\n",
      "Epoch 9/500\n",
      "151/152 [============================>.] - ETA: 1s - loss: 0.4917 - acc: 0.7755Epoch 00009: val_loss did not improve\n",
      "152/152 [==============================] - 202s 1s/step - loss: 0.4926 - acc: 0.7743 - val_loss: 0.5249 - val_acc: 0.7711\n",
      "Epoch 10/500\n",
      "151/152 [============================>.] - ETA: 1s - loss: 0.4967 - acc: 0.7689Epoch 00010: val_loss improved from 0.49873 to 0.48724, saving model to model/checkpoints/BestKerasModelVGG16_flat.h5\n",
      "152/152 [==============================] - 211s 1s/step - loss: 0.4968 - acc: 0.7678 - val_loss: 0.4872 - val_acc: 0.7763\n",
      "Epoch 11/500\n",
      "151/152 [============================>.] - ETA: 1s - loss: 0.4828 - acc: 0.7755Epoch 00011: val_loss did not improve\n",
      "152/152 [==============================] - 193s 1s/step - loss: 0.4817 - acc: 0.7757 - val_loss: 0.5119 - val_acc: 0.7763\n",
      "Epoch 12/500\n",
      "151/152 [============================>.] - ETA: 1s - loss: 0.4781 - acc: 0.7801Epoch 00012: val_loss improved from 0.48724 to 0.48380, saving model to model/checkpoints/BestKerasModelVGG16_flat.h5\n",
      "152/152 [==============================] - 209s 1s/step - loss: 0.4766 - acc: 0.7809 - val_loss: 0.4838 - val_acc: 0.7789\n",
      "Epoch 13/500\n",
      "151/152 [============================>.] - ETA: 1s - loss: 0.4753 - acc: 0.7762Epoch 00013: val_loss improved from 0.48380 to 0.47683, saving model to model/checkpoints/BestKerasModelVGG16_flat.h5\n",
      "152/152 [==============================] - 206s 1s/step - loss: 0.4770 - acc: 0.7757 - val_loss: 0.4768 - val_acc: 0.7868\n",
      "Epoch 14/500\n",
      "151/152 [============================>.] - ETA: 1s - loss: 0.4719 - acc: 0.7755Epoch 00014: val_loss did not improve\n",
      "152/152 [==============================] - 196s 1s/step - loss: 0.4721 - acc: 0.7757 - val_loss: 0.5292 - val_acc: 0.7474\n",
      "Epoch 15/500\n",
      "151/152 [============================>.] - ETA: 1s - loss: 0.4885 - acc: 0.7669Epoch 00015: val_loss did not improve\n",
      "152/152 [==============================] - 195s 1s/step - loss: 0.4884 - acc: 0.7671 - val_loss: 0.5005 - val_acc: 0.7789\n",
      "Epoch 16/500\n",
      "151/152 [============================>.] - ETA: 1s - loss: 0.4617 - acc: 0.7715Epoch 00016: val_loss did not improve\n",
      "152/152 [==============================] - 188s 1s/step - loss: 0.4611 - acc: 0.7717 - val_loss: 0.4812 - val_acc: 0.8026\n",
      "Epoch 17/500\n",
      "151/152 [============================>.] - ETA: 1s - loss: 0.4543 - acc: 0.7987Epoch 00017: val_loss did not improve\n",
      "152/152 [==============================] - 183s 1s/step - loss: 0.4573 - acc: 0.7967 - val_loss: 0.5049 - val_acc: 0.7947\n",
      "Epoch 18/500\n",
      "151/152 [============================>.] - ETA: 1s - loss: 0.4611 - acc: 0.7921Epoch 00018: val_loss did not improve\n",
      "152/152 [==============================] - 184s 1s/step - loss: 0.4610 - acc: 0.7921 - val_loss: 0.4790 - val_acc: 0.7974\n",
      "Epoch 19/500\n",
      "151/152 [============================>.] - ETA: 1s - loss: 0.4530 - acc: 0.7874Epoch 00019: val_loss did not improve\n",
      "152/152 [==============================] - 180s 1s/step - loss: 0.4527 - acc: 0.7875 - val_loss: 0.4842 - val_acc: 0.7868\n",
      "Epoch 20/500\n",
      "151/152 [============================>.] - ETA: 1s - loss: 0.4620 - acc: 0.7821Epoch 00020: val_loss did not improve\n",
      "152/152 [==============================] - 172s 1s/step - loss: 0.4610 - acc: 0.7829 - val_loss: 0.4907 - val_acc: 0.7974\n",
      "Epoch 21/500\n",
      "151/152 [============================>.] - ETA: 1s - loss: 0.4372 - acc: 0.7894Epoch 00021: val_loss did not improve\n",
      "152/152 [==============================] - 173s 1s/step - loss: 0.4377 - acc: 0.7882 - val_loss: 0.4796 - val_acc: 0.8105\n",
      "Epoch 22/500\n",
      "151/152 [============================>.] - ETA: 1s - loss: 0.4488 - acc: 0.7901Epoch 00022: val_loss did not improve\n",
      "152/152 [==============================] - 172s 1s/step - loss: 0.4512 - acc: 0.7882 - val_loss: 0.4937 - val_acc: 0.7868\n",
      "Epoch 23/500\n",
      "151/152 [============================>.] - ETA: 1s - loss: 0.4355 - acc: 0.8000Epoch 00023: val_loss did not improve\n",
      "152/152 [==============================] - 173s 1s/step - loss: 0.4342 - acc: 0.8007 - val_loss: 0.4802 - val_acc: 0.7684\n",
      "Epoch 24/500\n",
      "151/152 [============================>.] - ETA: 1s - loss: 0.4205 - acc: 0.7907Epoch 00024: val_loss did not improve\n",
      "152/152 [==============================] - 172s 1s/step - loss: 0.4223 - acc: 0.7901 - val_loss: 0.4887 - val_acc: 0.8053\n",
      "Epoch 25/500\n",
      "151/152 [============================>.] - ETA: 1s - loss: 0.4108 - acc: 0.7967Epoch 00025: val_loss did not improve\n",
      "152/152 [==============================] - 172s 1s/step - loss: 0.4092 - acc: 0.7980 - val_loss: 0.5235 - val_acc: 0.8000\n",
      "Epoch 26/500\n",
      "151/152 [============================>.] - ETA: 1s - loss: 0.4146 - acc: 0.8199Epoch 00026: val_loss did not improve\n",
      "152/152 [==============================] - 173s 1s/step - loss: 0.4144 - acc: 0.8204 - val_loss: 0.4782 - val_acc: 0.7737\n",
      "Epoch 27/500\n",
      "151/152 [============================>.] - ETA: 1s - loss: 0.4150 - acc: 0.8066Epoch 00027: val_loss improved from 0.47683 to 0.47597, saving model to model/checkpoints/BestKerasModelVGG16_flat.h5\n",
      "152/152 [==============================] - 173s 1s/step - loss: 0.4139 - acc: 0.8072 - val_loss: 0.4760 - val_acc: 0.8079\n",
      "Epoch 28/500\n",
      "151/152 [============================>.] - ETA: 0s - loss: 0.3969 - acc: 0.8219Epoch 00028: val_loss improved from 0.47597 to 0.45936, saving model to model/checkpoints/BestKerasModelVGG16_flat.h5\n",
      "152/152 [==============================] - 156s 1s/step - loss: 0.3980 - acc: 0.8191 - val_loss: 0.4594 - val_acc: 0.7789\n",
      "Epoch 29/500\n",
      "151/152 [============================>.] - ETA: 0s - loss: 0.3958 - acc: 0.8079Epoch 00029: val_loss did not improve\n",
      "152/152 [==============================] - 149s 981ms/step - loss: 0.3954 - acc: 0.8079 - val_loss: 0.4685 - val_acc: 0.7868\n",
      "Epoch 30/500\n",
      "151/152 [============================>.] - ETA: 0s - loss: 0.3891 - acc: 0.8245Epoch 00030: val_loss did not improve\n",
      "152/152 [==============================] - 150s 984ms/step - loss: 0.3884 - acc: 0.8243 - val_loss: 0.4666 - val_acc: 0.8000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/500\n",
      "151/152 [============================>.] - ETA: 0s - loss: 0.3843 - acc: 0.8212Epoch 00031: val_loss did not improve\n",
      "152/152 [==============================] - 149s 980ms/step - loss: 0.3839 - acc: 0.8211 - val_loss: 0.5118 - val_acc: 0.8132\n",
      "Epoch 32/500\n",
      "151/152 [============================>.] - ETA: 0s - loss: 0.3836 - acc: 0.8278Epoch 00032: val_loss did not improve\n",
      "152/152 [==============================] - 149s 981ms/step - loss: 0.3836 - acc: 0.8276 - val_loss: 0.4660 - val_acc: 0.7789\n",
      "Epoch 33/500\n",
      "151/152 [============================>.] - ETA: 0s - loss: 0.3856 - acc: 0.8166Epoch 00033: val_loss did not improve\n",
      "152/152 [==============================] - 149s 981ms/step - loss: 0.3851 - acc: 0.8164 - val_loss: 0.4974 - val_acc: 0.8053\n",
      "Epoch 34/500\n",
      "151/152 [============================>.] - ETA: 0s - loss: 0.3813 - acc: 0.8212Epoch 00034: val_loss did not improve\n",
      "152/152 [==============================] - 152s 998ms/step - loss: 0.3795 - acc: 0.8217 - val_loss: 0.5485 - val_acc: 0.7868\n",
      "Epoch 35/500\n",
      "151/152 [============================>.] - ETA: 0s - loss: 0.3684 - acc: 0.8331Epoch 00035: val_loss did not improve\n",
      "152/152 [==============================] - 150s 990ms/step - loss: 0.3687 - acc: 0.8336 - val_loss: 0.4903 - val_acc: 0.8000\n",
      "Epoch 36/500\n",
      "151/152 [============================>.] - ETA: 0s - loss: 0.4101 - acc: 0.8060Epoch 00036: val_loss did not improve\n",
      "152/152 [==============================] - 150s 989ms/step - loss: 0.4105 - acc: 0.8053 - val_loss: 0.4699 - val_acc: 0.8132\n",
      "Epoch 37/500\n",
      "151/152 [============================>.] - ETA: 0s - loss: 0.3531 - acc: 0.8391Epoch 00037: val_loss did not improve\n",
      "152/152 [==============================] - 151s 992ms/step - loss: 0.3527 - acc: 0.8388 - val_loss: 0.4692 - val_acc: 0.8000\n",
      "Epoch 38/500\n",
      "151/152 [============================>.] - ETA: 0s - loss: 0.3551 - acc: 0.8411Epoch 00038: val_loss did not improve\n",
      "152/152 [==============================] - 150s 989ms/step - loss: 0.3541 - acc: 0.8421 - val_loss: 0.4658 - val_acc: 0.8132\n",
      "Epoch 39/500\n",
      "151/152 [============================>.] - ETA: 0s - loss: 0.3518 - acc: 0.8497Epoch 00039: val_loss did not improve\n",
      "152/152 [==============================] - 150s 990ms/step - loss: 0.3506 - acc: 0.8500 - val_loss: 0.5034 - val_acc: 0.8158\n",
      "Epoch 40/500\n",
      "151/152 [============================>.] - ETA: 0s - loss: 0.3383 - acc: 0.8483Epoch 00040: val_loss improved from 0.45936 to 0.44683, saving model to model/checkpoints/BestKerasModelVGG16_flat.h5\n",
      "152/152 [==============================] - 152s 1s/step - loss: 0.3401 - acc: 0.8480 - val_loss: 0.4468 - val_acc: 0.8026\n",
      "Epoch 41/500\n",
      "151/152 [============================>.] - ETA: 0s - loss: 0.3445 - acc: 0.8503Epoch 00041: val_loss improved from 0.44683 to 0.44288, saving model to model/checkpoints/BestKerasModelVGG16_flat.h5\n",
      "152/152 [==============================] - 151s 992ms/step - loss: 0.3443 - acc: 0.8500 - val_loss: 0.4429 - val_acc: 0.8211\n",
      "Epoch 42/500\n",
      "151/152 [============================>.] - ETA: 0s - loss: 0.3382 - acc: 0.8543Epoch 00042: val_loss did not improve\n",
      "152/152 [==============================] - 151s 992ms/step - loss: 0.3375 - acc: 0.8546 - val_loss: 0.5346 - val_acc: 0.8211\n",
      "Epoch 43/500\n",
      "151/152 [============================>.] - ETA: 0s - loss: 0.3408 - acc: 0.8358Epoch 00043: val_loss did not improve\n",
      "152/152 [==============================] - 150s 987ms/step - loss: 0.3400 - acc: 0.8368 - val_loss: 0.4486 - val_acc: 0.7947\n",
      "Epoch 44/500\n",
      "151/152 [============================>.] - ETA: 0s - loss: 0.3238 - acc: 0.8444Epoch 00044: val_loss did not improve\n",
      "152/152 [==============================] - 150s 989ms/step - loss: 0.3263 - acc: 0.8434 - val_loss: 0.4816 - val_acc: 0.7947\n",
      "Epoch 45/500\n",
      "151/152 [============================>.] - ETA: 0s - loss: 0.3286 - acc: 0.8570Epoch 00045: val_loss did not improve\n",
      "152/152 [==============================] - 150s 990ms/step - loss: 0.3287 - acc: 0.8572 - val_loss: 0.5140 - val_acc: 0.7632\n",
      "Epoch 46/500\n",
      "151/152 [============================>.] - ETA: 0s - loss: 0.3288 - acc: 0.8503Epoch 00046: val_loss did not improve\n",
      "152/152 [==============================] - 150s 987ms/step - loss: 0.3278 - acc: 0.8507 - val_loss: 0.5044 - val_acc: 0.8263\n",
      "Epoch 47/500\n",
      "151/152 [============================>.] - ETA: 0s - loss: 0.3215 - acc: 0.8563Epoch 00047: val_loss did not improve\n",
      "152/152 [==============================] - 150s 990ms/step - loss: 0.3228 - acc: 0.8553 - val_loss: 0.5219 - val_acc: 0.7842\n",
      "Epoch 48/500\n",
      "106/152 [===================>..........] - ETA: 43s - loss: 0.2984 - acc: 0.8642"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Lets define the image transormations that we wan\n",
    "\n",
    "gen = ImageDataGenerator(horizontal_flip=True,\n",
    "                         vertical_flip=True,\n",
    "                         width_shift_range=0.2,\n",
    "                         height_shift_range=0.2,\n",
    "                         zoom_range=0.2,\n",
    "                         rotation_range=40)\n",
    "\n",
    "# Here is the function that merges our two generators\n",
    "# We use the exact same generator with the same random seed for both the y and angle arrays\n",
    "def gen_flow_for_one_input(X1, y):\n",
    "    genX1 = gen.flow(X1, y, batch_size=batch_size, seed=42)\n",
    "    while True:\n",
    "        X1i = genX1.next()\n",
    "        yield X1i[0], X1i[1]\n",
    "\n",
    "#Finally create out generator\n",
    "gen_flow = gen_flow_for_one_input(X_train, Y_train)\n",
    "\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "epochs_to_wait_for_improve = 50\n",
    "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=epochs_to_wait_for_improve)\n",
    "checkpoint_callback = ModelCheckpoint(weights_path + 'BestKerasModelVGG16_flat.h5', monitor='val_loss',\n",
    "                                      verbose=1, save_best_only=True, mode='min')\n",
    "#fit the model\n",
    "model.fit_generator(gen_flow, validation_data=(X_valid, Y_valid),\n",
    "                    steps_per_epoch=int(np.ceil(len(X_train)/batch_size)),\n",
    "                    epochs=500, verbose=1, callbacks=[early_stopping_callback, checkpoint_callback])\n",
    "                    #class_weights = class_weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Â IV. Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(weights_path+\"BestKerasModelVGG16_flat.h5\")\n",
    "score = model.evaluate(X_valid, Y_valid, verbose=1)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#compute log loss\n",
    "pred = model.predict(X_valid)\n",
    "log_loss(Y_valid,pred)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#Generate the training data\n",
    "#Create 3 bands having HH, HV and avg of both\n",
    "X_band_1=np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in train[\"band_1\"]])\n",
    "X_band_2=np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in train[\"band_2\"]])\n",
    "X_train = np.concatenate([X_band_1[:, :, :, np.newaxis], X_band_2[:, :, :, np.newaxis],\n",
    "                          ((X_band_1+X_band_2)/2)[:, :, :, np.newaxis]], axis=-1)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#parse corrupted notebook file\n",
    "t = [\"#Generate the training data\\n\",\n",
    "    \"#Create 3 bands having HH, HV and avg of both\\n\",\n",
    "    \"X_band_1=np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in train[\\\"band_1\\\"]])\\n\",\n",
    "    \"X_band_2=np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in train[\\\"band_2\\\"]])\\n\",\n",
    "    \"X_train = np.concatenate([X_band_1[:, :, :, np.newaxis], X_band_2[:, :, :, np.newaxis],\\n\",\n",
    "    \"                          ((X_band_1+X_band_2)/2)[:, :, :, np.newaxis]], axis=-1)\"]\n",
    "#t.remove(\"\\n\")\n",
    "t=[x.replace(\"\\n\",'') for x in t]\n",
    "for x in t:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
