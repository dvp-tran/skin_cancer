{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Skin Cancer Classification Challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Summary : ** skin cancer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminaries and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#general & system\\n\",\n",
    "import os\n",
    "\n",
    "#data processing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.rcParams['figure.figsize'] = 10, 10  #default setting\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "#data augmentation\n",
    "from PIL import Image\n",
    "from random import choice\n",
    "import cv2\n",
    "import numpy as np\n",
    "#import keras.preprocessing.image as prep\n",
    "\n",
    "#ML part\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.applications.resnet50 import preprocess_input\n",
    "from keras.preprocessing import image as kimage\n",
    "from keras.models import Sequential\n",
    "from keras.layers import GlobalMaxPooling2D, Dense, BatchNormalization, GlobalAveragePooling2D, Dropout,Activation,Flatten\n",
    "from keras.models import Model\n",
    "from keras.optimizers import SGD\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "#validation\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import roc_curve, auc,classification_report,roc_auc_score\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import roc_curve, auc,classification_report,roc_auc_score\n",
    "\n",
    "\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.utils import resample\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Rq : ** Datasets are quite light, can be fully loaded in a laptop memory with ease."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4 ms, sys: 0 ns, total: 4 ms\n",
      "Wall time: 5.7 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "meta = pd.read_csv(\"../data/label_learn.csv\", sep = \";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000000.jpg</td>\n",
       "      <td>benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000002.jpg</td>\n",
       "      <td>malignant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0000006.jpg</td>\n",
       "      <td>benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0000008.jpg</td>\n",
       "      <td>benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0000009.jpg</td>\n",
       "      <td>benign</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          name      label\n",
       "0  0000000.jpg     benign\n",
       "1  0000002.jpg  malignant\n",
       "2  0000006.jpg     benign\n",
       "3  0000008.jpg     benign\n",
       "4  0000009.jpg     benign"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 4 ms, total: 4 ms\n",
      "Wall time: 3.86 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_list = os.listdir(\"../data/resized_train/\")\n",
    "len(train_list) == len(meta.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_list.sort() == list(meta.name).sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 21.8 s, sys: 1.87 s, total: 23.6 s\n",
      "Wall time: 23.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train = np.array([np.array(Image.open(\"../data/resized_train/\"+fname)) for fname in meta.name])\n",
    "Y_train = [1 if x==\"malignant\" else 0 for x in meta.label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8581, 299, 299, 3)\n",
      "8581\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(len(Y_train))\n",
    "X_train.shape[0] == len(meta.name) == len(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0000000.jpg\n",
      "1    0000002.jpg\n",
      "2    0000006.jpg\n",
      "3    0000008.jpg\n",
      "4    0000009.jpg\n",
      "Name: name, dtype: object\n",
      "[0, 1, 0, 0, 0]\n",
      "0       benign\n",
      "1    malignant\n",
      "2       benign\n",
      "3       benign\n",
      "4       benign\n",
      "Name: label, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#control\n",
    "print(meta.name[0:5])\n",
    "print(Y_train[0:5])\n",
    "print(meta.label[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Class weights**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class_weight_or = class_weight.compute_class_weight('balanced', np.unique(Y_train), Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Data splitting**"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#data splitting\n",
    "X_train, X_valid, Y_train, Y_valid = train_test_split(X_train, Y_train, random_state=42, train_size=0.80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Resampling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8581\n",
      "679\n",
      "7902\n"
     ]
    }
   ],
   "source": [
    "temp = sum(Y_train)\n",
    "sample_size = temp*2700/(374+254)  #1372\n",
    "sample_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def random_undersampling(X, Y,sample_size = sample_size, n_sample=1):\n",
    "    \"\"\"\n",
    "    X,y : numpy arrays\n",
    "    return :\n",
    "    5 random ensemble of indices general_balenced_set:\n",
    "        general_balenced_set[0] = the shuffeled indices that inssure the class balance\n",
    "    \"\"\"\n",
    "    indices = np.array(range(len(Y)))\n",
    "    positive_samples = indices[Y==1]\n",
    "    #print(type(positive_samples))\n",
    "    negative_samples = indices[Y==0]\n",
    "    #print(type(negative_samples))\n",
    "    general_balenced_set = []\n",
    "    for k in range(n_sample):\n",
    "        indices_ = np.random.choice(negative_samples, sample_size, replace=False)\n",
    "        #print(len(indices_))\n",
    "        # append positive and negative\n",
    "        balenced_set = np.append(indices_, positive_samples)\n",
    "        #print(len(balenced_set))\n",
    "        # shuffle indices\n",
    "        np.random.shuffle(balenced_set)\n",
    "        #print(len(balenced_set))\n",
    "        general_balenced_set.append(balenced_set)\n",
    "    return general_balenced_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "general_balenced_set = random_undersampling(X_train,Y_train)\n",
    "X_train = X_train[general_balenced_set]\n",
    "Y_train = Y_train[general_balenced_set]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III. Deep Learning with Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weights_path = '../model/checkpoints/'\n",
    "\n",
    "if not os.path.exists(weights_path):\n",
    "    os.makedirs(weights_path)\n",
    "    \n",
    "epochs = 500\n",
    "batch_size = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Using RESNET : **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#load base model\n",
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(299,299,3))\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#adding top layers\n",
    "    #sequentialy\n",
    "add_model = Sequential()\n",
    "add_model.add(GlobalAveragePooling2D(input_shape=base_model.output_shape[1:])) #Flatten/GlobalAveragePooling2D\n",
    "add_model.add(Dense(1024, activation='relu'))\n",
    "add_model.add(Dropout(0.25))\n",
    "add_model.add(Dense(512, activation='relu'))\n",
    "add_model.add(Dropout(0.25))\n",
    "add_model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=add_model(base_model.output))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#adding top layers\n",
    "    #need to check api to add layers sequentialy\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x) #Flatten instead?\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "x = Dropout(0.25)(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = Dropout(0.25)(x)\n",
    "predictions = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "def weighted_categorical_crossentropy(weights):\n",
    "    \"\"\"\n",
    "    [w_0, w_1] : weight of 0 class and weight of 1 class\n",
    "    \"\"\"\n",
    "    weights = K.variable(weights)\n",
    "\n",
    "    def loss(y_true, y_pred):\n",
    "        # scale predictions so that the class probas of each sample sum to 1\n",
    "        #y_pred /= K.sum(y_pred, axis=-1, keepdims=True)\n",
    "        # clip to prevent NaN's and Inf's\n",
    "        y_pred = K.clip(y_pred, K.epsilon(), 1 - K.epsilon())\n",
    "        # calc\n",
    "        loss = y_true * K.log(y_pred) * weights[1] + (1 - y_true) * K.log(1 - y_pred) * weights[0]\n",
    "        loss = -K.sum(loss, -1)\n",
    "        return loss\n",
    "\n",
    "    return loss\n",
    "\n",
    "\n",
    "\n",
    "from keras import backend as K\n",
    "\n",
    "def sensitivity(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    return true_positives / (possible_positives + K.epsilon())\n",
    "\n",
    "def specificity(y_true, y_pred):\n",
    "    true_negatives = K.sum(K.round(K.clip((1-y_true) * (1-y_pred), 0, 1)))\n",
    "    possible_negatives = K.sum(K.round(K.clip(1-y_true, 0, 1)))\n",
    "    return true_negatives / (possible_negatives + K.epsilon())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.54296381,  6.31885125])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weight_or"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss1 = weighted_categorical_crossentropy(np.array([1.8,6]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#freeze lower layers of the model\n",
    "#for layer in model.layers[:]:\n",
    "    #layer.trainable = False\n",
    "for layer in model.layers[0:]:\n",
    "    layer.trainable = True\n",
    "    \n",
    "\n",
    "\n",
    "#model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.compile(optimizer=SGD(lr=0.0001, momentum=0.9), loss=loss1, #binary_crossentropy\n",
    "              metrics=[sensitivity, specificity,\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "#Lets define the image transormations that we wan\n",
    "\n",
    "gen = ImageDataGenerator(horizontal_flip=True,\n",
    "                         vertical_flip=True,\n",
    "                         width_shift_range=0.2,\n",
    "                         height_shift_range=0.2,\n",
    "                         zoom_range=0.2,\n",
    "                         rotation_range=40)\n",
    "\n",
    "val_datagen = ImageDataGenerator()\n",
    "# Here is the function that merges our two generators\n",
    "# We use the exact same generator with the same random seed for both the y and angle arrays\n",
    "def gen_flow_for_one_input(X1, y):\n",
    "    genX1 = gen.flow(X1, y, batch_size=batch_size, seed=42)\n",
    "    while True:\n",
    "        X1i = genX1.next()\n",
    "        yield X1i[0], X1i[1]\n",
    "\n",
    "def val_datagen_(X1, y):\n",
    "    genX1 = val_datagen.flow(X1, y, batch_size=batch_size, seed=42)\n",
    "    while True:\n",
    "        X1i = genX1.next()\n",
    "        yield X1i[0], X1i[1]\n",
    "#Finally create out generator\n",
    "gen_flow_train = gen_flow_for_one_input(X_train, Y_train)\n",
    "#gen_flow_val = gen_flow_for_one_input(X_valid, Y_valid)\n",
    "#gen_flow_val = val_datagen_(X_valid, Y_valid)\n",
    "\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "epochs_to_wait_for_improve = 20\n",
    "early_stopping_callback = EarlyStopping(monitor='loss',min_delta = 0.01, patience=epochs_to_wait_for_improve)\n",
    "checkpoint_callback = ModelCheckpoint(weights_path + 'BestKerasResnet50_flat_2_full.h5', monitor='val_loss',\n",
    "                                      verbose=1, save_best_only=True, mode='min')\n",
    "#fit the model\n",
    "model.fit_generator(gen_flow_train,\n",
    "                    steps_per_epoch=int(np.ceil(len(X_train)/batch_size)),\n",
    "                    epochs=500, verbose=1, callbacks=[early_stopping_callback, checkpoint_callback],\n",
    "                    class_weight = class_weight_or)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "if model_name == \"vgg16\":\n",
    "\tbase_model = VGG16(weights=weights)\n",
    "\tmodel = Model(input=base_model.input, output=base_model.get_layer('fc1').output)\n",
    "\timage_size = (224, 224)\n",
    "elif model_name == \"vgg19\":\n",
    "\tbase_model = VGG19(weights=weights)\n",
    "\tmodel = Model(input=base_model.input, output=base_model.get_layer('fc1').output)\n",
    "\timage_size = (224, 224)\n",
    "elif model_name == \"resnet50\":\n",
    "\tbase_model = ResNet50(weights=weights)\n",
    "\tmodel = Model(input=base_model.input, output=base_model.get_layer('flatten').output)\n",
    "\timage_size = (224, 224)\n",
    "elif model_name == \"inceptionv3\":\n",
    "\tbase_model = InceptionV3(weights=weights)\n",
    "\tmodel = Model(input=base_model.input, output=base_model.get_layer('flatten').output)\n",
    "\timage_size = (299, 299)\n",
    "elif model_name == \"xception\":\n",
    "\tbase_model = Xception(weights=weights)\n",
    "\tmodel = Model(input=base_model.input, output=base_model.get_layer('avg_pool').output)\n",
    "\timage_size = (299, 299)\n",
    "else:\n",
    "\tbase_model = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IV. Visualize  TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "# visualize the points' distribution of train data using features built from base_model\n",
    "import matplotlib.pyplot as plt\n",
    "# dimension reduction\n",
    "from sklearn.manifold import TSNE \n",
    "import numpy as np\n",
    "\n",
    "def t_sne_vis(name, base_model, x_processed_images, random_state, labels):\n",
    "    \"\"\"\n",
    "    :param name: the name of the cnn model used to build features\n",
    "    :param base_model: the model obj\n",
    "    :param x_processed_images: the input images for our model\n",
    "    :param random_state: for fixing the results\n",
    "    :param labels: 0/1 classification labels\n",
    "    :return:\n",
    "    the graph of image distribution based on features extracted from the model and the t-sne features\n",
    "    \"\"\"\n",
    "    # convert data to images\n",
    "    print('Converting data points to composite image')\n",
    "    X_train = x_processed_images\n",
    "    print('we got %d different images of shape %dx%d ' % (len(X_train), X_train.shape[1], X_train.shape[1]))\n",
    "    print('build usefull features from the selected model')\n",
    "    features = base_model.predict(X_train)\n",
    "    x_data1 = np.asarray(features).astype('float64')\n",
    "    x_data1 = x_data1.reshape((x_data1.shape[0], -1))\n",
    "    # perform t-SNE embedding\n",
    "    print('performing t-sne reduction')\n",
    "    vis_data = TSNE(perplexity=100, random_state=random_state).fit_transform(x_data1)\n",
    "    # plot the result\n",
    "    fig = plt.figure(figsize=(15, 15))\n",
    "    vis_x = vis_data[:, 0]\n",
    "    vis_y = vis_data[:, 1]\n",
    "    plt.scatter(vis_x, vis_y, c=labels, cmap=plt.cm.get_cmap(\"winter\", 2))\n",
    "    plt.colorbar(ticks=range(2))\n",
    "    plt.clim(0, 1)\n",
    "    plt.title(name)\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "    fig.savefig('tsne_vis_'+name+'.png')\n",
    "    return vis_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "name = 'Resnet'\n",
    "print('visualizing for %s' %name)\n",
    "base_model_ = Model(input=model.input, output=model.get_layer('avg_pool').output)\n",
    "tsne_feats = t_sne_vis(name, base_model_, X_valid, np.random.RandomState(42), Y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## V. Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8581/8581 [==============================] - 48s 6ms/step\n",
      "('Test loss:', 0.096961811329991876)\n",
      "('Test sensitivity:', 0.16887641778262868)\n",
      "('Test specificity:', 0.98164011368369763)\n",
      "('Test acc:', 0.9594452861041376)\n"
     ]
    }
   ],
   "source": [
    "model = load_model(weights_path+\"BestKerasResnet50_flat_3_loss_no_weight_raw.h5\", custom_objects={'sensitivity': sensitivity,\n",
    "                                                                             \"specificity\":specificity,\n",
    "                                                                              \"loss1\":loss1})\n",
    "score = model.evaluate(X_train, Y_train, verbose=1)\n",
    "print('Test loss:', score[0])\n",
    "print('Test sensitivity:', score[1])\n",
    "print('Test specificity:', score[2])\n",
    "print('Test acc:', score[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average precision-recall score: 0.81\n"
     ]
    }
   ],
   "source": [
    "#compute metrics\n",
    "pred = model.predict(X_train)\n",
    "average_precision = average_precision_score(Y_train, pred)\n",
    "\n",
    "print('Average precision-recall score: {0:0.2f}'.format(\n",
    "      average_precision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,u'2-class Precision-Recall curve: AP=0.81')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEWCAYAAAB42tAoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAIABJREFUeJzt3XmYXNV55/HvT92tbu2NFgRoZREC\nWQgbxKLYAWxjDNiGjO1giJ2YxDHZnNVxkpnMxJjE48QZJ+MkTmISHO/GwCSOYrPEGJAgtrAki00C\nGUkgJATa0L4v7/zx3nKXWt3VpVZXV3fr93meerpu1albb93uvm+dc+45RxGBmZlZZwbVOwAzM+vb\nnCjMzKwiJwozM6vIicLMzCpyojAzs4qcKMzMrCInin5M0s2SHqt3HD1N0lJJV3RRZrKknZIaeims\nmpP0oqQri/u3SvpqvWMyAyeKXiepWdIdklZL2iFpiaRr6h1XNYoT2Z7iBL1e0r9IGt7T7xMRr4uI\nR7oo81JEDI+IQz39/sVJ+kDxObdK+r6kOT39PicKSV+UdFDSae0e75HjLOnniv+nXZK+JWl0hbJv\nkfQjSdslrZJ0S9lzp0qaK2mdpJA09VhjGaicKHpfI7AGuBwYBfwv4K5+9Ef5rogYDlwAXAT8z/YF\nlPr739Y3i885FngYuLvO8fQ4SY298B7DgPcA24D3d1CkdJzHAY8B/ypJx7D/1wGfB34eGA/sBv6+\nk7JNwL8V5UcB7wP+StL5RZHDwP1FvFamv/8z9zsRsSsibo2IFyPicER8G3gBuLCz10iaJOlfJW2U\ntFnS33VS7rOS1hTflhZL+umy5y6WtKh4br2kvyoeb5H01WK/WyUtlDS+is/xMnAfMLPYzyOSPinp\nv8h/1jMkjSpqT69IelnSn5U3FUn6sKRni5rVMkkXFI+XN8F0FvfU4ltfY7F9WvFt8DVJKyR9uOx9\nbpV0l6QvF++1VNLsrj5j8TkPAl8DJkgaV7bPd0p6ouyb8Kyy5zr8fUk6U9JDxWObJH1NUms1cbQn\n6fri/bdLWinp6vbHruyzf7XdMfuQpJeAhyTdL+kj7fb9pKR3F/fPkfTd4rgul3TDMYb6HmArcBvw\nwc4KRcQB4EvAKcCYY9j/+4H/iIj5EbGT/OL1bkkjOig7GhgJfCXSQuBZYEYRw/qI+Htg4TG8/wnB\niaLOipPy2cDSTp5vAL4NrAamAhOAOzvZ3ULg9eQ/xNeBuyW1FM99FvhsRIwEzgTuKh7/IPntahL5\nD/qrwJ4q4p4EXAssKXv454FbgBFFvF8CDgJnAW8ArgJ+uXj9zwK3Ar9A/vNeB2zu4K06i7u9bwBr\ngdOA9wL/W9Jby56/jjxurcBcoMNk28HnHFzEuBnYUjx2AfAF4FfIY/Z5YK6yWbHS70vAp4oYzyWP\n+a3VxNEupouBLwMfKz7PZcCLx7CLy4v3fzv5d3JT2b5nAFOA7xS1ge8WZU4uyv198S2+1OTzVBfv\n9UHyd3MncE7py0AHn6kZuBlYGxGbJL2pSMKd3d5UvPR1wJOl/UTESmA/+T91hIhYX8Tyi5IalM1c\nU8iajFUSEb7V6QY0AQ8Cn69QZg6wEWjs4LmbgccqvHYLcH5xfz7wCWBsuzK/BHwfmFVFvC8CO8lv\niKvJKv6Q4rlHgNvKyo4H9pWeLx67CXi4uP8A8NsV3ufKLuKeCgTZlDcJOASMKHv+U8AXi/u3Ag+W\nPTcD2FPhc95Knmy2FvvdDFxR9vw/AH/a7jXLyRNwp7+vDt7nZ4AlnXzuW4GvdvK6zwN/3dWxa7+f\nsmN2RtnzI4BdwJRi+5PAF4r77wMe7eC9P17l3/dksjnn9WW/8892cpw3AA8BFx7j/9D3gF9t99jL\n5b+vds+9C1hPfoE5CHy4gzKNxXGaeiyxDOSbaxR1omzD/wr5j/KRssfvU3bu7ZT0fvIkuDqyCaSr\nfX60aMrZJmkrWVMYWzz9IfJb1nNF89I7i8e/Qv4D36nsxPu0si23Mz8TEa0RMSUifj0iymsfa8ru\nTyET4Sulb4HkSebk4vlJwMquPlOFuMudBrwWETvKHltNfpsvebXs/m6gRVKjpPeXHe/7ysrcFRGt\nZMJ7hiObBqcAHy3/hlt8ntOo8PuSdLKkO4tmuO3AV2n7/RyLao9dZ37yeyqO2XeAG4uHbiSb2iA/\n5yXtPuf7yeahavw88GxEPFFsfw34uXZ/X3cVf08nR8RbImLxMX6WnWSNtNxIYEf7gpLOAb5J1hAH\nk7WRP5D0jmN8zxNOzTuz7GiSBNxBnoSujWyfBSAirmlXdg4wWVJjpWSh7I/4Q+CtwNKIOCxpC9nc\nQUQ8D9xUJKh3A/dIGhMRu8hv7J9QdqjfS347vqMbH618KuI1ZI1ibCdxryGbkirvsJO42xVbB4yW\nNKIsWUwmv1l2tf+v0XZi7Oj5TZJ+BVgo6esR8UoR+ycj4pPty3fx+/oUeYxmRcRmST9DlU1g7VQ6\ndruAoWXbHZ3U208Z/Q3g45LmA0PIzvvS+8yLiLd1I0bIE/JkSaUk3Ug21V1DNv91qvh7vq9CkWsi\n4lGyybbUGY2kM4Bm4McdvGYmsDwiHii2l0v6ThHPd7r+OCcu1yjq4x/INuJ3tftG3pEfAq8Afy5p\nmLLz+Y0dlBtBVqU3Ao2S/oSyb1qSPiBpXEQcJqv6AIckvVnSeUXb+nbgANncclyKE+p/Ap+RNFLS\nIGVn7uVFkX8Gfl/ShUpnSZrSfj+dxd3uvdaQzWefKo7PLLIm0mkCOMbP8hxZ6/qD4qF/An5V0iVF\n7MMkvaPoQK30+xpB0XQnaQLZx9Add5Dt7G8tjuuE4tsywBPAjZKalB32761if/eStYfbyKuQDheP\nfxs4W9LPF/trknSRpHO72mGRMM8ELib7zV5Pnqi/ToVO7ZKIeDTy8ufObo8WRb8GvEvSTxd9KrcB\n/9qudlmyBJimvERWks4E3klZH4eyT6+52GxWWx/fCc2JopcVJ8NfIf9xXm3XzHSUyHEC7yI7hF8i\nO2zf10HRB8hvYD8mm132cmRT0NXAUkk7yQ7iGyNiL/mN8x4ySTwLzCObRHpCqYq/jOwvuQc4tfhc\nd5Pt4V8nmwm+RXbCt9dZ3O3dRLbBryMvgfx4RHy3hz4HwF8Ct0g6OSIWAR8mawNbgBVkf1FXv69P\nkJcVbyO/wf5rdwKJiB8Cvwj8dbGveeSJHvKqnzOLuD5BHt+u9reviOXK8vLFyfYqsjlqHdl89xcU\nJ9Ki2a7DizDIZPDvEfF0RLxaupG/w3eqwliHYxERS8kLML5G9nOMAH699HzRlPs/irIryT65vyH/\n3ucB/48ja897yGQO8BxVXNhxIlCEFy4yM7POuUZhZmYVOVGYmVlFThRmZlaRE4WZmVXU78ZRjB07\nNqZOnVrvMMzM+pXFixdviohxXZc8Wr9LFFOnTmXRokX1DsPMrF+RtLq7r3XTk5mZVeREYWZmFTlR\nmJlZRU4UZmZWkROFmZlV5ERhZmYV1SxRSPqCpA2SnunkeUn6G+X6xk+pkyUSzcysvmpZo/giOUV0\nZ64BphW3W8g1Gqpy+HD3bmZmduxqNuAuIuYXK6Z15nrgy5HznC+Q1Crp1GLBm07t3AmPPlqpROcm\nToQzu1xTzczMytVzZPYEjlxYZ23x2FGJQtItZK2DsWOnsmYNDDrGutCmTbBhgxOFmdmxqmeiUAeP\ndbiKUkTcDtwOMH367Jg2DRqPMXI3PZmZdU89r3paC0wq255ILrdoZmZ9SD1rFHOBj0i6E7gE2NZV\n/0RPO3QItm2DXbuy72P3bti7F6ZNg5NP7s1IzMz6rpolCknfAK4AxkpaC3wcaAKIiH8E7gWuJRem\n300uFl9z27fD2rWwZ08mhW3bYMeO/Hn4cCaL3bvhbW/rjWjMzPq+Wl71dFMXzwfwG7V6//YOHMjE\nsHhxdmy/9hrs3w8tLTB6dHZyDxsGTz1VHuORNY7Dh6G5Gc44o7eiNjOrv363HkV3HT6cJ/ynn4ax\nY+Gss2DUKFBZl3oUXekbN2ZCOXAgE8XOnbB1ayaawYNh0iRoaqrP5zAz620nTKI477xMAOPHH5kc\n2ovIhPKjH2XzVEMDjBmTYzB2785mqxdeaKthHDwIM2fC8OHdjy0i+0uO9UouM7PecMKcmhoa4JRT\nKpeRshN7/fpsimptPXK8xrPPZmJ48sm2zu99+2DoUJg1q7o4DhzI15ZeX7rt3Qunn97WrLVvX/ad\n7N2bCWvfvkwmgwfDued27xiYmXXHCZMoqjV5ct46cuqpsHp1nsBPPTX7N5Yty8fGjIEJE44sf/hw\n9oXs3t2WHHbtartt25a1CSmbtlavzs72UvLYsyd/7tqV/Sn792fCGzEiazhmZr3BieIYtLbC1WWz\nV+3dm7e1a7NZ6+abs6N8/fo8qbe/qqqkpSVP9qUO9Kam7BPZtQsWLMhajARDhmQ/ytix+Zq1azOZ\nPPAAXHZZ1m4ich9TpvT64TCzE4QTxXFoaYGf+qm2pqgFCzIhbN2aP/fvz6ukSp3nw4dnjaAjF1wA\nmzfDyJHZvNSRs87KfW/dCo89ls1YBw7kPi+7LBNPc3PtPq+ZnZicKI7T4MGZANavh0WLsnZw8snZ\njzBsWOWO83JSJpSunH8+LF8OJ52USeXll2HdOnjooezDOO+84/s8ZmbtOVH0gHPPzaupRo6s/ZVL\nTU15lVXJOefkez/3XDZFmZn1NCeKHjJ6dP3ee+jQ7NfYsiVrNkOHZh8IZNPUjh15O3Agy02dmkll\n9+7cHjmybV/79mVfSakzXcqrxZqasomrPBFGZPlS2T17srmt9B4tLb15FMysVpwoBoDSwkxr1uRU\n6pC1jtLVVnv2ZKLYvj2TxVln5Ql/z57cnjw5t0tXWO3dmz9LyWXoUDjttEwMZ5yRyaA8Oezblz93\n7cr7Bw/CuHFwww3VN72ZWd/lRDEADBmS39737MlaRWnqEWi7emrEiOxLeeKJHDA4aFAmhJ07sxP9\n0KEsWyo/fHj2mSxfnsln48Z8bs2aI5u4GhvzvYcNy1pVS0u+x8aNMG9evm+pZnLOOVnGycOsf3Gi\nGCDe8Ib8eehQXkY7enSevNsv8FQadFg6WW/alD9HjOj4iqlLLsmfhw/npbnDhuVtyJDOF4+aNSuT\nxLPPZpndu3Pfa9bk/saOzdd7JLpZ/+B/1QGmoaHymIr23+arudIK8oR/+unVlR02DK66KmsSw4Zl\n89XixfD885lwRo7MPo9TTslxIlOnVrdfM6sPJwqricbGtg715ma49NJc63zHDnilWHXk+efz8uLz\nzsvEsW9fjngvza91PPNnmVnPcaKwXjFoEFx+edv2nj3ZN/LMMzlg8cCBbDYbNSrvjxwJ735354MP\nzaz3OFFYXQwZkvNVjRuXiWHYMHjppWwaW7s2k8hDD+XVW3v2ZAd6a2uOGemsb8TMasOJwuqqubmt\nE73UtzJ+PDz8MLz4YttcWaVFpk4/Hd785rqFa3ZCcqKwPqe5GS66CFasaJsra+fOXHRq166sgVx1\nVcevLc3Ga2Y9x4nC+qQxY/JWUmp2evDB7ARvaMh+jL17syN8yJC2dT1aWrJvY/fuTBytrW1rpI8b\nB9On5+sPHcrHwR3nZpU4UVi/0dSUzU4PP5xjNJqasqZRmsLk8OHcHjYsE8GuXfmzpaVtPY9hw3Ii\nxZEj2xJLqY/koovaBhwOGuS+ELMSJwrrV1pack2QHTuyFhCRi0ONGpW1iEOHMlmUpnTfvr2tH2Tn\nTpg/v23ZWSnLvPJKlt+8uW3G39KAwFmzct8lhw+3da6XxoiUpjM5cCDja2jIfTQ1ZbmWFtdYrH9z\norB+RzpyIsNx49ruNzQceWIvLzd8ePZtHDiQiaBk5swc47FlS44+j8jaRFNTNnP99E93PPmhlMmp\nNNfV9u25PWRI1mZGj85E0dQE73hH52uRmPV1ThR2QmlsPHrqkMbGjq+kWrw4k8f8+ZlcSnNhNTVl\nLWTo0ExEzc2ZhPbvz5pOU1PWTgYNylrMvn1tC0yZ9UdOFGaduPDCtrmwhg/PhFC6omrWrMqvnT49\nfz77bE79/uCDOep8/Picidf9H9afOFGYVVDtXFidmTYtZ+tdsSKbtVpacrzIiBHZx7F/f1sCcfKw\nvsqJwqyGGhvh2mvb1gZZtKjtaqxSp3dDQ853VZqp16yvcaIw6wVDh+btmmvyyqkdOzKJbNiQy9ge\nPpxNUuPGeWVA63ucKMx6UakG0dqa28OHt60hcv/9Of/V5MltfRxes8P6Av8ZmtXZtGmZOH70o6xh\nrFkDK1fmZbZjxmRNZPRoOPlkT1Fi9eFEYdYHjBsHb3979l/Mm5dNUwcPwkkntQ3kO+usrH0MH57b\nkybl82a15kRh1ocMG5ad35BJY9++nEH3xz/OAX0HD+YVU1KO87joolyL3E1UVkv+8zLro0rrk48e\nfeQytBs3wqpV8Oqr8PjjsGwZTJiQTVSjRmVZN09ZT6ppopB0NfBZoAH454j483bPTwa+BLQWZf4o\nIu6tZUxm/d24cXnbuhW+//0cCb5pU9uUIi+8kFdQjR+fTVWtrVnGrLtqligkNQCfA94GrAUWSpob\nEcvKiv1P4K6I+AdJM4B7gam1islsIGltzWaqw4ezltHUlDWM3btzjqqTTmqbWn3MmOzrOOmkrH2U\n5sAqTUsCuR8P+rOO1LJGcTGwIiJWAUi6E7geKE8UAZSmbRsFrKthPGYD0qBBWXuAnFn3tdeyT2P3\n7pxSff367NfYsyebplpbs09j5Mi8imrkyLa1OSKy7MSJcMop9f1c1nfUMlFMANaUba8F2o89vRX4\nT0m/CQwDruxoR5JuAW4BGD9+co8HajZQSFl7mDMnt2fNymlCGhszgSxblhMaDh6c4zkism+joSFH\njpe2n3kmL9v9qZ9yf4fVNlF09OcV7bZvAr4YEZ+RNAf4iqSZEXH4iBdF3A7cDjB9+uz2+zCzCgYP\nzp9jx8Jllx353KFDbeuRS3lV1csvw9KlWcMYMyY7xwcPbltzY+hQ93mcaGqZKNYCk8q2J3J009KH\ngKsBIuIHklqAscCGGsZlZoWGhiPX5mhszEkLR46EH/wg56ZaujSvvNq/Py/XbW7OmkZpcScb+Gr5\na14ITJN0OvAycCPwc+3KvAS8FfiipHOBFmBjDWMysyq0tmYfxbp1bQP/mpvz6qrBg/PxyUUr8Jw5\nWcuwgatmiSIiDkr6CPAAeenrFyJiqaTbgEURMRf4KPBPkn6XbJa6OSLctGRWZxJccEHHzz31VCaM\njRuzRrJ2LbznPV7udSBTfzsvT58+O7785UWu8pr1AQsW5Ajy8ePzUt3yZWmtb5G0OCJmd+e1vmra\nzLrt0kvzctqNG2Hu3BwtvmZNjsmwgcOJwsyOy8UXZ2f31q3wn/+Zy74+8US9o7Ke5ERhZsftda/L\nDu9Bg7LPYtEi2LKl3lFZT3FLv5kdt8ZGOP/8vL97d465+Pd/zwQydmxeQVV+Ga71L04UZtajLrww\nr4xaty7HXkTkgL45c/Ky29GjPf6iv/Gvy8x63KxZuZzrxo2wenWuqfHYY5kwRo3KAXtedKn/cKIw\ns5pobs7JBSdOzKuhXn45p0AfOjQTyOmnZ7KYOrVtNlvrm5wozKzmTjmlbTba5cvhxRezs7upCZYs\ngZ/92ZxHasQIT3XeFzlRmFmvmj49b3v3wtNPZ8K4775MGgcPZuf3SSfl7LUtLfWO1sCJwszqpKUF\nZs6ERx7JpqhNm7KT+8UXsx9jyZJMKOed57mk6s2JwszqZsgQuOaaIx/bvBkWLswmqD174Lnn4Mwz\nYdKknNnWep8ThZn1KWPG5Ep9Bw/mXFKbN+eo72XL4B3vyHmlfHlt7/LhNrM+qbER3vSmvL92ba66\n9+CDmUhOO63z2W2t5zlRmFmfN3FiNkOtWtU28eCwYXD22V6qtTc4UZhZvzBtWt5KtYt582D7drjo\nonpHNvA5UZhZvzJxYl4V9dhjeWXUvn05aG/QoGySsp7nRGFm/c6IEXD55TB/Pjz5JKxYkQP23vAG\nmN2tpXmsEo+BNLN+aejQvDqqtTWXYV2/HhYvzv4L61lOFGbWr51zTs4bdeaZOfngAw/As8/mrLXW\nM5wozGxAOPtsmDEDNmyARx/NhLF1a72jGhjcR2FmA8app2b/xaOPws6deVXUDTfUO6r+zzUKMxtQ\nhg/PaUGGD89R3QsW5BTn1n1OFGY2II0fn01PS5bAt78Nzz+fV0bZsXPTk5kNSBMn5pTlr72WA/Qe\neyyTxZgxuTbGxInQ0FDvKPsHJwozG7BaWnIQXlMTLFqUSaO5OR8fMwbOOiunMbfKnCjMbMAbNy77\nLfbtg/37s7P7tddy7MXmzTk1yIQJ9Y6y73KiMLMTRnNz3q69Nvsr5s3Lkd3Ll8OcOVnD8CJJR3Nn\ntpmdkJqa4Mors2lq2zb4/vfhnnuyH2P9ejh0qN4R9h2uUZjZCe2MM7Jz+wc/yLEX8+fn1OWnnnr0\n6nsnKicKMzvhDR0Kb3lLjurevBlWr4bdu7NPo7m53tHVn5uezMzIWsT48TkNyKxZ2en9/PP1jqpv\nqLpGIWkCMKX8NRExvxZBmZnV0/jx2cm9cCHs2pVrXUhZu5gyBUaOrHeEvauqRCHpL4D3AcuAUhdP\nABUThaSrgc8CDcA/R8Sfd1DmBuDWYn9PRsTPVRu8mVktNDbmYkjr1mWiiMhkATk1yMyZ2a8xfHgu\nojTQVVuj+BlgekTsq3bHkhqAzwFvA9YCCyXNjYhlZWWmAf8deGNEbJF0cvWhm5nVzowZcO652U/R\n2Jg/163LeaMWLMhBe42NOWvtJZe0JZKBqNpEsQpoAqpOFMDFwIqIWAUg6U7gerJWUvJh4HMRsQUg\nIjYcw/7NzGpKyoQAmRSmTcuaxP792em9ahXs2JHTgUyaVN9Ya6naRLEbeELS9yhLFhHxWxVeMwEo\nX2tqLXBJuzJnA0j6L7J56taIuL/KmMzMet2IEflzzJgcg/GjHw38yQarTRRzi9uxUAePtV9zqhGY\nBlwBTAQelTQzIo5YbkTSLcAtAOPHTz7GMMzMaiMiaxobNmSfxkBtfqoqUUTElyQNpqgBAMsjoqsc\nuhYor4xNBNZ1UGZBsa8XJC0nE8fCdu9/O3A7wPTps73AoZn1CYcOwZ49sHQpbNwIr3vdwEwYVX0c\nSVcAz5Od038P/FjSZV28bCEwTdLpRZK5kaNrJd8C3ly8x1gyEa2qOnozszpqbc0xF9u3Z3/Fffdl\n0hhoqm16+gxwVUQsB5B0NvAN4MLOXhARByV9BHiA7H/4QkQslXQbsCgi5hbPXSWpdNntxyJic/c/\njplZ7xo3Lm+bNmV/xQ9/mE1Rb3lLdoYPBNUmiqZSkgCIiB9LaurqRRFxL3Bvu8f+pOx+AL9X3MzM\n+q2xY+H88zNZ7NmTV0ZdfHGOs2js55MlVRv+Ikl3AF8ptt8PLK5NSGZm/dP48fD2t8MDD8DKlVnL\nGD06H7/ggv7bd1Ft2L8GLAV+C/htcizEr9YqKDOz/mrQoJx1dvBgeOklWLYspzD/7ndz0N7Bg/WO\n8NhVe9XTPuCvipuZmXXhwqIH9+DBTBLPP5+D80aMgDe9CYYNq298x6JiopB0V0TcIOlpjh4DQUTM\nqllkZmYDQGMjvPnN8PDDOW9UadzFTTf1n76LrsL87eLnO2sdiJnZQNXS0rYI0oIF8OqrsGVLXi3V\nH1Tso4iIV4q7m4A1EbEaaAbO5+jBc2Zm1oXp0+HwYbj//v4z9Ue1ndnzgZZiTYrvAb8IfLFWQZmZ\nDVQnnZTTk2/YAEuW1Dua6lSbKBQRu4F3A38bEf8NmFG7sMzMBq5LL81O7pUr6x1JdapOFJLmkOMn\nvlM81k+6YczM+p5Ro2DrVti2rd6RdK3aRPE75AJD/1ZMw3EG8HDtwjIzG9imT88k8a1v5Sy0fVm1\n4yjmAfPKtleRg+/MzKwbRo7Mq542b86+ivPOg6YuJ0aqj67GUfzfiPgdSf9Bx+MorqtZZGZmA9w5\n58C8ebBoUS6x+q531TuijnVVoyjN7fR/ah2ImdmJpqUFLr88B+Pt3ZvJYsKEekd1tIqJIiJKE/8t\nAvZExGEASQ3keAozMzsOLS1wxRUwf34OxnvPe+od0dGq7cz+HjC0bHsI8GDPh2NmduJpacmroDZu\n7JuD8KpNFC0RsbO0UdwfWqG8mZlVSYIpU3IuqIceqnc0R6s2UeySdEFpQ9KFwJ7ahGRmduI5+eRc\n8OjHP87pyfuSagfN/Q5wt6TS/E6nAu+rTUhmZieehoacZfaRR2D5cpg8ud4Rtal2HMVCSecA0wEB\nz0VEH2xJMzPrvwYPhtbWrFFs3gxjxtQ7olRV05OkocAfAr8dEU8DUyV56nEzsx40aFD2VaxfnzWL\nvqLaPop/AfYDc4rttcCf1SQiM7MT2CmntM0u+/TTOSV5vVWbKM6MiE8DBwAiYg/ZBGVmZj1Igtmz\ns+nphz/Mq6BefLG+a21X25m9X9IQimk8JJ0J7KtZVGZmJ7Dm5kwWixfnSngrV+aI7WuuyU7v3lZt\njeLjwP3AJElfIwfg/UHNojIzO8GNGwdXXw1vfGM2Q61enVN91EOXiUKSgOfIRYtuBr4BzI6IR2oa\nmZmZMXgwXHVVrl3x/PP1aYLqsukpIkLStyLiQtoWLTIzs17S2AgzZ8Krr9bn/attelog6aKaRmJm\nZhXt31+fq6CqTRRvJpPFSklPSXpa0lO1DMzMzNpIOWHgfffB7t29+97VXvV0TU2jMDOziiZMgCef\nhBdegLvvhne/G0aM6J33rlijkNQi6XeAjwFXAy9HxOrSrVciNDMzAK69FoYNy47tf/s3WLasd963\nq6anLwGzgafJWsVnah6RmZl16vWvh6FD83LZRYsgjlqkuud11fQ0IyLOA5B0B/DD2odkZmadGTQI\nLrggJw5cuzYThWo8T0ZXNYqfzBAbEXUcQG5mZuUi4NChXL+i1rpKFOdL2l7cdgCzSvclbe9q55Ku\nlrRc0gpJf1Sh3HslhaTZx/oBzMxORKNHw44d8Pjj2cldSxWbniKi27OKSGoAPge8jZxtdqGkuRGx\nrF25EcBvAY93973MzE40I0Z1OAFZAAAKoklEQVTA2WdnjeLAATj//Nq9V7XjKLrjYmBFRKyKiP3A\nncD1HZT7U+DTwN4axmJmNuCcdRbMmJFLqN5/f/6shVomignAmrLttcVjPyHpDcCkiPh2pR1JukXS\nIkmLtm3b2PORmpn1UxMmwM6dsHRpLqFaC7VMFB31w//kQi5Jg4C/Bj7a1Y4i4vaImB0Rs0eNGteD\nIZqZ9W9NTXDZZdmx/eSTsGRJNkX1pFomirXApLLticC6su0RwEzgEUkvApcCc92hbWZ2bFpa4Jxz\n8nLZxx/v+enIa5koFgLTJJ0uaTBwIzC39GREbIuIsRExNSKmAguA6yJiUQ1jMjMbkCZMgLe+NZuh\nnn++Z2sVNUsUxbiLjwAPAM8Cd0XEUkm3SbquVu9rZnaiamrKK6F27cqR2z2l2kkBuyUi7gXubffY\nn3RS9opaxmJmdiI46aT8uXBhXhXVE2rZ9GRmZr1s6NAcY7F5Mzz6aM/s04nCzGyAueCCnGH2qadg\n5crj358ThZnZANPYmB3bW7bA4sXHvz8nCjOzAWjwYDjjDDjYA9O5OlGYmQ1gO3Yc/5oVThRmZgNU\nQ0Our71hw/Htx4nCzGyAGjcuFzo63uYnJwozswFsUA+c5Z0ozMwGOPdRmJlZh6Sc82nVquPbjxOF\nmdkANXw4HD6cs8oeDycKM7MBatAgOOUU2LbtOPfTM+GYmVlfNGRIziYLjQ3d3YcThZnZANbaCs3N\nQMerjlbFicLMzCpyojAzs4qcKMzMrCInCjOzAaylBfbtAxjS3N19OFGYmQ1gLS0wZw7k8LvucaIw\nMxvgGrp9YWxyojAzs4qcKMzMrCInCjMzq8iJwszMKnKiMDOzipwozMysIicKMzOryInCzMwqcqIw\nM7OKnCjMzKwiJwozM6vIicLMzCqqaaKQdLWk5ZJWSPqjDp7/PUnLJD0l6XuSptQyHjMzO3Y1SxSS\nGoDPAdcAM4CbJM1oV2wJMDsiZgH3AJ+uVTxmZtY9taxRXAysiIhVEbEfuBO4vrxARDwcEbuLzQXA\nxBrGY2Zm3VDLRDEBWFO2vbZ4rDMfAu7r6AlJt0haJGnRtm0bezBEMzPrSi0TRUerKUWHBaUPALOB\nv+zo+Yi4PSJmR8TsUaPG9WCIZmbWlcYa7nstMKlseyKwrn0hSVcCfwxcHhH7ahiPmZl1Qy1rFAuB\naZJOlzQYuBGYW15A0huAzwPXRcSGGsZiZmbdVLNEEREHgY8ADwDPAndFxFJJt0m6rij2l8Bw4G5J\nT0ia28nuzMysTmrZ9ERE3Avc2+6xPym7f2Ut39/MzI6fR2abmVlFThRmZlaRE4WZmVXkRGFmZhU5\nUZiZWUVOFGZmVpEThZmZVeREYWZmFTlRmJlZRU4UZmZWkROFmZlV5ERhZmYVOVGYmVlFThRmZlaR\nE4WZmVXkRGFmZhU5UZiZWUVOFGZmVpEThZmZVeREYWZmFTlRmJlZRU4UZmZWkROFmZlV5ERhZmYV\nOVGYmVlFThRmZlaRE4WZmVXkRGFmZhU5UZiZWUVOFGZmVpEThZmZVeREYWZmFTlRmJlZRTVNFJKu\nlrRc0gpJf9TB882Svlk8/7ikqbWMx8zMjl3NEoWkBuBzwDXADOAmSTPaFfsQsCUizgL+GviLWsVj\nZmbd01jDfV8MrIiIVQCS7gSuB5aVlbkeuLW4fw/wd5IUEdHZTiNg715orGXkZmYDyP79AOr262t5\nup0ArCnbXgtc0lmZiDgoaRswBthUXkjSLcAtxdb+K64YuRI6zSUnkAMnQdOWekfRN/hYtPGxaONj\nkSTYObm7r65lougofbU/u1dThoi4HbgdQNKiiO2zjz+8/i+PxV4fC3wsyvlYtPGxaCNpUXdfW8vO\n7LXApLLticC6zspIagRGAa/VMCYzMztGtUwUC4Fpkk6XNBi4EZjbrsxc4IPF/fcCD1XqnzAzs95X\ns6anos/hI8ADQAPwhYhYKuk2YFFEzAXuAL4iaQVZk7ixil3fXquY+yEfizY+Fm18LNr4WLTp9rGQ\nv8CbmVklHpltZmYVOVGYmVlFfTZRePqPNlUci9+TtEzSU5K+J2lKPeLsDV0di7Jy75UUkgbspZHV\nHAtJNxR/G0slfb23Y+wtVfyPTJb0sKQlxf/JtfWIs9YkfUHSBknPdPK8JP1NcZyeknRBVTuOiD53\nIzu/VwJnAIOBJ4EZ7cr8OvCPxf0bgW/WO+46Hos3A0OL+792Ih+LotwIYD6wAJhd77jr+HcxDVgC\nnFRsn1zvuOt4LG4Hfq24PwN4sd5x1+hYXAZcADzTyfPXAveRY9guBR6vZr99tUbxk+k/ImI/UJr+\no9z1wJeK+/cAb5XU/THqfVeXxyIiHo6I3cXmAnLMykBUzd8FwJ8Cnwb29mZwvayaY/Fh4HMRsQUg\nIjb0coy9pZpjEcDI4v4ojh7TNSBExHwqj0W7HvhypAVAq6RTu9pvX00UHU3/MaGzMhFxEChN/zHQ\nVHMsyn2I/MYwEHV5LCS9AZgUEd/uzcDqoJq/i7OBsyX9l6QFkq7uteh6VzXH4lbgA5LWAvcCv9k7\nofU5x3o+AWo7hcfx6LHpPwaAqj+npA8As4HLaxpR/VQ8FpIGkbMQ39xbAdVRNX8XjWTz0xVkLfNR\nSTMjYmuNY+tt1RyLm4AvRsRnJM0hx2/NjIjDtQ+vT+nWebOv1ig8/Uebao4Fkq4E/hi4LiL29VJs\nva2rYzECmAk8IulFsg127gDt0K72f+TfI+JARLwALCcTx0BTzbH4EHAXQET8AGgBxvZKdH1LVeeT\n9vpqovD0H226PBZFc8vnySQxUNuhoYtjERHbImJsREyNiKlkf811EdHtydD6sGr+R75FXuiApLFk\nU9SqXo2yd1RzLF4C3gog6VwyUWzs1Sj7hrnALxRXP10KbIuIV7p6UZ9seoraTf/R71R5LP4SGA7c\nXfTnvxQR19Ut6Bqp8licEKo8Fg8AV0laBhwCPhYRm+sXdW1UeSw+CvyTpN8lm1puHohfLCV9g2xq\nHFv0x3wcaAKIiH8k+2euBVYAu4FfrGq/A/BYmZlZD+qrTU9mZtZHOFGYmVlFThRmZlaRE4WZmVXk\nRGFmZhU5UZi1I+mQpCckPSPpPyS19vD+b5b0d8X9WyX9fk/u36ynOVGYHW1PRLw+ImaSY3R+o94B\nmdWTE4VZZT+gbNI0SR+TtLCYy/8TZY//QvHYk5K+Ujz2rmKtlCWSHpQ0vg7xmx23Pjky26wvkNRA\nTvtwR7F9FTlX0sXk5GpzJV0GbCbn2XpjRGySNLrYxWPApRERkn4Z+ANyhLBZv+JEYXa0IZKeAKYC\ni4HvFo9fVdyWFNvDycRxPnBPRGwCiIjS5JQTgW8W8/0PBl7olejNepibnsyOticiXg9MIU/wpT4K\nAZ8q+i9eHxFnRcQdxeMdzYXzt8DfRcR5wK+QE9GZ9TtOFGadiIhtwG8Bvy+piZx07pckDQeQNEHS\nycD3gBskjSkeLzU9jQJeLu5/ELN+yk1PZhVExBJJTwI3RsRXiimqf1DM0rsT+EAxU+kngXmSDpFN\nUzeTq6rdLellcsrz0+vxGcyOl2ePNTOzitz0ZGZmFTlRmJlZRU4UZmZWkROFmZlV5ERhZmYVOVGY\nmVlFThRmZlbR/wcptRy814UgzAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f2c53fe1fd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "precision, recall, _ = precision_recall_curve(Y_train, pred)\n",
    "\n",
    "plt.step(recall, precision, color='b', alpha=0.2,\n",
    "         where='post')\n",
    "plt.fill_between(recall, precision, step='post', alpha=0.2,\n",
    "                 color='b')\n",
    "\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.title('2-class Precision-Recall curve: AP={0:0.2f}'.format(\n",
    "          average_precision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_results(y_test, y_score):\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_score)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlim([0.0, 1.05])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver operating characteristic curve')\n",
    "    plt.show()\n",
    "    print('AUC: %f' % roc_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#compute log loss\n",
    "pred = model.predict(X_valid)\n",
    "log_loss(Y_valid,pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VI. Submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_list = os.listdir(\"../data/resized_test/\")\n",
    "test = pd.read_csv(\"../data/example.csv\",sep = \";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_list) == len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5009030541978553"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[\"risk\"] = test[\"risk\"].apply(lambda x : float(x.replace(\",\",\".\")))\n",
    "test.risk.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4291, 299, 299, 3)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.DataFrame()\n",
    "submission[\"name\"] = test.name\n",
    "\n",
    "X_test = np.array([np.array(Image.open(\"../data/resized_test/\"+fname)) for fname in test.name])\n",
    "X_test.shape\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4291, 1)\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(X_test)\n",
    "print(pred.shape)\n",
    "\n",
    "submission[\"prediction\"] = pred\n",
    "submission.to_csv(\"submission_Resnet50_finetu.csv\",index=False,sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000001.jpg</td>\n",
       "      <td>0.161760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000003.jpg</td>\n",
       "      <td>0.115472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0000004.jpg</td>\n",
       "      <td>0.032326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0000005.jpg</td>\n",
       "      <td>0.146522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0000007.jpg</td>\n",
       "      <td>0.064424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0000010.jpg</td>\n",
       "      <td>0.026847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0000013.jpg</td>\n",
       "      <td>0.310791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0000015.jpg</td>\n",
       "      <td>0.120671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0000021.jpg</td>\n",
       "      <td>0.545047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0000022.jpg</td>\n",
       "      <td>0.237165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0000024.jpg</td>\n",
       "      <td>0.590793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0000025.jpg</td>\n",
       "      <td>0.594284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0000033.jpg</td>\n",
       "      <td>0.256039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0000034.jpg</td>\n",
       "      <td>0.142294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0000037.jpg</td>\n",
       "      <td>0.110917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0000039.jpg</td>\n",
       "      <td>0.114074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0000040.jpg</td>\n",
       "      <td>0.216947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0000042.jpg</td>\n",
       "      <td>0.774481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0000044.jpg</td>\n",
       "      <td>0.052501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0000048.jpg</td>\n",
       "      <td>0.089817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0000054.jpg</td>\n",
       "      <td>0.100403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0000057.jpg</td>\n",
       "      <td>0.095889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0000058.jpg</td>\n",
       "      <td>0.486844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0000062.jpg</td>\n",
       "      <td>0.081486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0000063.jpg</td>\n",
       "      <td>0.122045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0000072.jpg</td>\n",
       "      <td>0.946216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0000079.jpg</td>\n",
       "      <td>0.076243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0000080.jpg</td>\n",
       "      <td>0.155975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0000081.jpg</td>\n",
       "      <td>0.003051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0000083.jpg</td>\n",
       "      <td>0.080021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4261</th>\n",
       "      <td>0015992.jpg</td>\n",
       "      <td>0.020733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4262</th>\n",
       "      <td>0015994.jpg</td>\n",
       "      <td>0.001711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4263</th>\n",
       "      <td>0015999.jpg</td>\n",
       "      <td>0.012513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4264</th>\n",
       "      <td>0016001.jpg</td>\n",
       "      <td>0.019446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4265</th>\n",
       "      <td>0016002.jpg</td>\n",
       "      <td>0.009060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4266</th>\n",
       "      <td>0016005.jpg</td>\n",
       "      <td>0.011919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4267</th>\n",
       "      <td>0016008.jpg</td>\n",
       "      <td>0.759376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4268</th>\n",
       "      <td>0016009.jpg</td>\n",
       "      <td>0.014438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4269</th>\n",
       "      <td>0016013.jpg</td>\n",
       "      <td>0.003507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4270</th>\n",
       "      <td>0016015.jpg</td>\n",
       "      <td>0.009132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4271</th>\n",
       "      <td>0016017.jpg</td>\n",
       "      <td>0.000652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4272</th>\n",
       "      <td>0016019.jpg</td>\n",
       "      <td>0.003294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4273</th>\n",
       "      <td>0016022.jpg</td>\n",
       "      <td>0.137800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4274</th>\n",
       "      <td>0016035.jpg</td>\n",
       "      <td>0.136391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4275</th>\n",
       "      <td>0016038.jpg</td>\n",
       "      <td>0.003752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4276</th>\n",
       "      <td>0016046.jpg</td>\n",
       "      <td>0.018010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4277</th>\n",
       "      <td>0016049.jpg</td>\n",
       "      <td>0.434860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4278</th>\n",
       "      <td>0016051.jpg</td>\n",
       "      <td>0.012498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4279</th>\n",
       "      <td>0016053.jpg</td>\n",
       "      <td>0.004389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4280</th>\n",
       "      <td>0016054.jpg</td>\n",
       "      <td>0.054312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4281</th>\n",
       "      <td>0016055.jpg</td>\n",
       "      <td>0.001240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4282</th>\n",
       "      <td>0016056.jpg</td>\n",
       "      <td>0.094652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4283</th>\n",
       "      <td>0016057.jpg</td>\n",
       "      <td>0.363461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4284</th>\n",
       "      <td>0016058.jpg</td>\n",
       "      <td>0.000996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4285</th>\n",
       "      <td>0016061.jpg</td>\n",
       "      <td>0.006404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4286</th>\n",
       "      <td>0016063.jpg</td>\n",
       "      <td>0.017621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4287</th>\n",
       "      <td>0016065.jpg</td>\n",
       "      <td>0.000834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4288</th>\n",
       "      <td>0016069.jpg</td>\n",
       "      <td>0.045580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4289</th>\n",
       "      <td>0016071.jpg</td>\n",
       "      <td>0.012955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4290</th>\n",
       "      <td>0016072.jpg</td>\n",
       "      <td>0.798217</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4291 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             name  prediction\n",
       "0     0000001.jpg    0.161760\n",
       "1     0000003.jpg    0.115472\n",
       "2     0000004.jpg    0.032326\n",
       "3     0000005.jpg    0.146522\n",
       "4     0000007.jpg    0.064424\n",
       "5     0000010.jpg    0.026847\n",
       "6     0000013.jpg    0.310791\n",
       "7     0000015.jpg    0.120671\n",
       "8     0000021.jpg    0.545047\n",
       "9     0000022.jpg    0.237165\n",
       "10    0000024.jpg    0.590793\n",
       "11    0000025.jpg    0.594284\n",
       "12    0000033.jpg    0.256039\n",
       "13    0000034.jpg    0.142294\n",
       "14    0000037.jpg    0.110917\n",
       "15    0000039.jpg    0.114074\n",
       "16    0000040.jpg    0.216947\n",
       "17    0000042.jpg    0.774481\n",
       "18    0000044.jpg    0.052501\n",
       "19    0000048.jpg    0.089817\n",
       "20    0000054.jpg    0.100403\n",
       "21    0000057.jpg    0.095889\n",
       "22    0000058.jpg    0.486844\n",
       "23    0000062.jpg    0.081486\n",
       "24    0000063.jpg    0.122045\n",
       "25    0000072.jpg    0.946216\n",
       "26    0000079.jpg    0.076243\n",
       "27    0000080.jpg    0.155975\n",
       "28    0000081.jpg    0.003051\n",
       "29    0000083.jpg    0.080021\n",
       "...           ...         ...\n",
       "4261  0015992.jpg    0.020733\n",
       "4262  0015994.jpg    0.001711\n",
       "4263  0015999.jpg    0.012513\n",
       "4264  0016001.jpg    0.019446\n",
       "4265  0016002.jpg    0.009060\n",
       "4266  0016005.jpg    0.011919\n",
       "4267  0016008.jpg    0.759376\n",
       "4268  0016009.jpg    0.014438\n",
       "4269  0016013.jpg    0.003507\n",
       "4270  0016015.jpg    0.009132\n",
       "4271  0016017.jpg    0.000652\n",
       "4272  0016019.jpg    0.003294\n",
       "4273  0016022.jpg    0.137800\n",
       "4274  0016035.jpg    0.136391\n",
       "4275  0016038.jpg    0.003752\n",
       "4276  0016046.jpg    0.018010\n",
       "4277  0016049.jpg    0.434860\n",
       "4278  0016051.jpg    0.012498\n",
       "4279  0016053.jpg    0.004389\n",
       "4280  0016054.jpg    0.054312\n",
       "4281  0016055.jpg    0.001240\n",
       "4282  0016056.jpg    0.094652\n",
       "4283  0016057.jpg    0.363461\n",
       "4284  0016058.jpg    0.000996\n",
       "4285  0016061.jpg    0.006404\n",
       "4286  0016063.jpg    0.017621\n",
       "4287  0016065.jpg    0.000834\n",
       "4288  0016069.jpg    0.045580\n",
       "4289  0016071.jpg    0.012955\n",
       "4290  0016072.jpg    0.798217\n",
       "\n",
       "[4291 rows x 2 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#Generate the training data\n",
    "#Create 3 bands having HH, HV and avg of both\n",
    "X_band_1=np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in train[\"band_1\"]])\n",
    "X_band_2=np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in train[\"band_2\"]])\n",
    "X_train = np.concatenate([X_band_1[:, :, :, np.newaxis], X_band_2[:, :, :, np.newaxis],\n",
    "                          ((X_band_1+X_band_2)/2)[:, :, :, np.newaxis]], axis=-1)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#parse corrupted notebook file\n",
    "t = [\"#Generate the training data\\n\",\n",
    "    \"#Create 3 bands having HH, HV and avg of both\\n\",\n",
    "    \"X_band_1=np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in train[\\\"band_1\\\"]])\\n\",\n",
    "    \"X_band_2=np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in train[\\\"band_2\\\"]])\\n\",\n",
    "    \"X_train = np.concatenate([X_band_1[:, :, :, np.newaxis], X_band_2[:, :, :, np.newaxis],\\n\",\n",
    "    \"                          ((X_band_1+X_band_2)/2)[:, :, :, np.newaxis]], axis=-1)\"]\n",
    "#t.remove(\"\\n\")\n",
    "t=[x.replace(\"\\n\",'') for x in t]\n",
    "for x in t:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
