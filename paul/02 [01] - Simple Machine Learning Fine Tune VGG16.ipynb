{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Â Skin Cancer Classification Challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Summary : ** skin cancer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminaries and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#general & system\\n\",\n",
    "import os\n",
    "\n",
    "#data processing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.rcParams['figure.figsize'] = 10, 10  #default setting\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "#data augmentation\n",
    "from PIL import Image\n",
    "from random import choice\n",
    "import cv2\n",
    "import numpy as np\n",
    "#import keras.preprocessing.image as prep\n",
    "\n",
    "#ML part\n",
    "from keras.applications import VGG16\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.preprocessing import image as kimage\n",
    "from keras.models import Sequential\n",
    "from keras.layers import GlobalMaxPooling2D, Dense, BatchNormalization, GlobalAveragePooling2D, Dropout,Activation,Flatten\n",
    "from keras.models import Model\n",
    "from keras.optimizers import SGD\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "#validation\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Rq : ** Datasets are quite light, can be fully loaded in a laptop memory with ease."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8 ms, sys: 0 ns, total: 8 ms\n",
      "Wall time: 6.05 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "meta = pd.read_csv(\"data/metadata.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.3 s, sys: 172 ms, total: 3.47 s\n",
      "Wall time: 3.47 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "filelist = os.listdir(\"data/resized/\")\n",
    "X_train = np.array([np.array(Image.open(\"data/resized/\"+fname)) for fname in filelist])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1900, 299, 299, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get target\n",
    "filelist = [x.replace(\".jpg\",\"\") for x in filelist]\n",
    "strates = [meta[meta[\"name\"]==x][\"meta_clinical_benign_malignant\"].values[0] for x in filelist]\n",
    "Y_train = [1 if x==\"malignant\" else 0 for x in strates]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ISIC_0000256', 'ISIC_0012768', 'ISIC_0012987', 'ISIC_0013676', 'ISIC_0013911']\n",
      "[0, 0, 0, 0, 0]\n",
      "['benign', 'benign', 'benign', 'indeterminate/benign', 'benign']\n"
     ]
    }
   ],
   "source": [
    "#control\n",
    "print(filelist[0:5])\n",
    "print(Y_train[0:5])\n",
    "print(strates[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Resampling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Class weights**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class_weight = class_weight.compute_class_weight('balanced', np.unique(Y_train), Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Data splitting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#data splitting\n",
    "X_train, X_valid, Y_train, Y_valid = train_test_split(X_train, Y_train, random_state=42, train_size=0.80,\n",
    "                                                      stratify = strates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III. Deep Learning with Transfer Learning"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# generator from folder\n",
    "batch_size = 16\n",
    "\n",
    "# prepare data augmentation configuration\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        target_size=(img_height, img_width),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        validation_data_dir,\n",
    "        target_size=(img_height, img_width),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary')\n",
    "\n",
    "# fine-tune the model\n",
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=nb_train_samples // batch_size,\n",
    "        epochs=epochs,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=nb_validation_samples // batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weights_path = 'model/checkpoints/'\n",
    "\n",
    "if not os.path.exists(weights_path):\n",
    "    os.makedirs(weights_path)\n",
    "    \n",
    "epochs = 500\n",
    "batch_size = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Using VGG16 : **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 299, 299, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 299, 299, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 299, 299, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 149, 149, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 149, 149, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 149, 149, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 74, 74, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 74, 74, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 74, 74, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 74, 74, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 37, 37, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 37, 37, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 37, 37, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 37, 37, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 18, 18, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 9, 9, 512)         0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#load base model\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(299,299,3))\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 299, 299, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 299, 299, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 299, 299, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 149, 149, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 149, 149, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 149, 149, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 74, 74, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 74, 74, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 74, 74, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 74, 74, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 37, 37, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 37, 37, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 37, 37, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 37, 37, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 18, 18, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 9, 9, 512)         0         \n",
      "_________________________________________________________________\n",
      "sequential_1 (Sequential)    (None, 1)                 42993665  \n",
      "=================================================================\n",
      "Total params: 57,708,353\n",
      "Trainable params: 57,708,353\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#adding top layers\n",
    "    #sequentialy\n",
    "add_model = Sequential()\n",
    "add_model.add(Flatten(input_shape=base_model.output_shape[1:])) #Flatten/GlobalAveragePooling2D\n",
    "add_model.add(Dense(1024, activation='relu'))\n",
    "add_model.add(Dropout(0.25))\n",
    "add_model.add(Dense(512, activation='relu'))\n",
    "add_model.add(Dropout(0.25))\n",
    "add_model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=add_model(base_model.output))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#adding top layers\n",
    "    #need to check api to add layers sequentialy\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x) #Flatten instead?\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "x = Dropout(0.25)(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = Dropout(0.25)(x)\n",
    "predictions = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#freeze lower layers of the model\n",
    "#for layer in model.layers[:]:\n",
    "    #layer.trainable = False\n",
    "for layer in model.layers[0:]:\n",
    "    layer.trainable = True\n",
    "    \n",
    "#compile\n",
    "#model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.compile(optimizer=SGD(lr=0.0001, momentum=0.9), loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "151/152 [============================>.] - ETA: 1s - loss: 0.6879 - acc: 0.7483Epoch 00001: val_loss improved from inf to 0.56682, saving model to model/checkpoints/BestKerasModelVGG16_flat.h5\n",
      "152/152 [==============================] - 191s 1s/step - loss: 0.6863 - acc: 0.7487 - val_loss: 0.5668 - val_acc: 0.7737\n",
      "Epoch 2/500\n",
      "151/152 [============================>.] - ETA: 1s - loss: 0.5457 - acc: 0.7735Epoch 00002: val_loss improved from 0.56682 to 0.52996, saving model to model/checkpoints/BestKerasModelVGG16_flat.h5\n",
      "152/152 [==============================] - 194s 1s/step - loss: 0.5461 - acc: 0.7730 - val_loss: 0.5300 - val_acc: 0.7737\n",
      "Epoch 3/500\n",
      "151/152 [============================>.] - ETA: 1s - loss: 0.5327 - acc: 0.7735Epoch 00003: val_loss improved from 0.52996 to 0.52082, saving model to model/checkpoints/BestKerasModelVGG16_flat.h5\n",
      "152/152 [==============================] - 196s 1s/step - loss: 0.5339 - acc: 0.7730 - val_loss: 0.5208 - val_acc: 0.7737\n",
      "Epoch 4/500\n",
      "151/152 [============================>.] - ETA: 1s - loss: 0.5333 - acc: 0.7728Epoch 00004: val_loss did not improve\n",
      "152/152 [==============================] - 193s 1s/step - loss: 0.5333 - acc: 0.7724 - val_loss: 0.5228 - val_acc: 0.7737\n",
      "Epoch 5/500\n",
      "151/152 [============================>.] - ETA: 1s - loss: 0.5228 - acc: 0.7735Epoch 00005: val_loss did not improve\n",
      "152/152 [==============================] - 201s 1s/step - loss: 0.5225 - acc: 0.7737 - val_loss: 0.5273 - val_acc: 0.7737\n",
      "Epoch 6/500\n",
      "151/152 [============================>.] - ETA: 1s - loss: 0.5158 - acc: 0.7742Epoch 00006: val_loss improved from 0.52082 to 0.49873, saving model to model/checkpoints/BestKerasModelVGG16_flat.h5\n",
      "152/152 [==============================] - 205s 1s/step - loss: 0.5149 - acc: 0.7750 - val_loss: 0.4987 - val_acc: 0.7737\n",
      "Epoch 7/500\n",
      "151/152 [============================>.] - ETA: 1s - loss: 0.5113 - acc: 0.7682Epoch 00007: val_loss did not improve\n",
      "152/152 [==============================] - 204s 1s/step - loss: 0.5116 - acc: 0.7684 - val_loss: 0.5113 - val_acc: 0.7816\n",
      "Epoch 8/500\n",
      "151/152 [============================>.] - ETA: 1s - loss: 0.5041 - acc: 0.7695Epoch 00008: val_loss did not improve\n",
      "152/152 [==============================] - 202s 1s/step - loss: 0.5040 - acc: 0.7697 - val_loss: 0.5066 - val_acc: 0.7737\n",
      "Epoch 9/500\n",
      "151/152 [============================>.] - ETA: 1s - loss: 0.4917 - acc: 0.7755Epoch 00009: val_loss did not improve\n",
      "152/152 [==============================] - 202s 1s/step - loss: 0.4926 - acc: 0.7743 - val_loss: 0.5249 - val_acc: 0.7711\n",
      "Epoch 10/500\n",
      "151/152 [============================>.] - ETA: 1s - loss: 0.4967 - acc: 0.7689Epoch 00010: val_loss improved from 0.49873 to 0.48724, saving model to model/checkpoints/BestKerasModelVGG16_flat.h5\n",
      "152/152 [==============================] - 211s 1s/step - loss: 0.4968 - acc: 0.7678 - val_loss: 0.4872 - val_acc: 0.7763\n",
      "Epoch 11/500\n",
      "151/152 [============================>.] - ETA: 1s - loss: 0.4828 - acc: 0.7755Epoch 00011: val_loss did not improve\n",
      "152/152 [==============================] - 193s 1s/step - loss: 0.4817 - acc: 0.7757 - val_loss: 0.5119 - val_acc: 0.7763\n",
      "Epoch 12/500\n",
      "151/152 [============================>.] - ETA: 1s - loss: 0.4781 - acc: 0.7801Epoch 00012: val_loss improved from 0.48724 to 0.48380, saving model to model/checkpoints/BestKerasModelVGG16_flat.h5\n",
      "152/152 [==============================] - 209s 1s/step - loss: 0.4766 - acc: 0.7809 - val_loss: 0.4838 - val_acc: 0.7789\n",
      "Epoch 13/500\n",
      "151/152 [============================>.] - ETA: 1s - loss: 0.4753 - acc: 0.7762Epoch 00013: val_loss improved from 0.48380 to 0.47683, saving model to model/checkpoints/BestKerasModelVGG16_flat.h5\n",
      "152/152 [==============================] - 206s 1s/step - loss: 0.4770 - acc: 0.7757 - val_loss: 0.4768 - val_acc: 0.7868\n",
      "Epoch 14/500\n",
      "151/152 [============================>.] - ETA: 1s - loss: 0.4719 - acc: 0.7755Epoch 00014: val_loss did not improve\n",
      "152/152 [==============================] - 196s 1s/step - loss: 0.4721 - acc: 0.7757 - val_loss: 0.5292 - val_acc: 0.7474\n",
      "Epoch 15/500\n",
      "151/152 [============================>.] - ETA: 1s - loss: 0.4885 - acc: 0.7669Epoch 00015: val_loss did not improve\n",
      "152/152 [==============================] - 195s 1s/step - loss: 0.4884 - acc: 0.7671 - val_loss: 0.5005 - val_acc: 0.7789\n",
      "Epoch 16/500\n",
      "151/152 [============================>.] - ETA: 1s - loss: 0.4617 - acc: 0.7715Epoch 00016: val_loss did not improve\n",
      "152/152 [==============================] - 188s 1s/step - loss: 0.4611 - acc: 0.7717 - val_loss: 0.4812 - val_acc: 0.8026\n",
      "Epoch 17/500\n",
      "151/152 [============================>.] - ETA: 1s - loss: 0.4543 - acc: 0.7987Epoch 00017: val_loss did not improve\n",
      "152/152 [==============================] - 183s 1s/step - loss: 0.4573 - acc: 0.7967 - val_loss: 0.5049 - val_acc: 0.7947\n",
      "Epoch 18/500\n",
      "151/152 [============================>.] - ETA: 1s - loss: 0.4611 - acc: 0.7921Epoch 00018: val_loss did not improve\n",
      "152/152 [==============================] - 184s 1s/step - loss: 0.4610 - acc: 0.7921 - val_loss: 0.4790 - val_acc: 0.7974\n",
      "Epoch 19/500\n",
      "151/152 [============================>.] - ETA: 1s - loss: 0.4530 - acc: 0.7874Epoch 00019: val_loss did not improve\n",
      "152/152 [==============================] - 180s 1s/step - loss: 0.4527 - acc: 0.7875 - val_loss: 0.4842 - val_acc: 0.7868\n",
      "Epoch 20/500\n",
      "151/152 [============================>.] - ETA: 1s - loss: 0.4620 - acc: 0.7821Epoch 00020: val_loss did not improve\n",
      "152/152 [==============================] - 172s 1s/step - loss: 0.4610 - acc: 0.7829 - val_loss: 0.4907 - val_acc: 0.7974\n",
      "Epoch 21/500\n",
      "151/152 [============================>.] - ETA: 1s - loss: 0.4372 - acc: 0.7894Epoch 00021: val_loss did not improve\n",
      "152/152 [==============================] - 173s 1s/step - loss: 0.4377 - acc: 0.7882 - val_loss: 0.4796 - val_acc: 0.8105\n",
      "Epoch 22/500\n",
      "151/152 [============================>.] - ETA: 1s - loss: 0.4488 - acc: 0.7901Epoch 00022: val_loss did not improve\n",
      "152/152 [==============================] - 172s 1s/step - loss: 0.4512 - acc: 0.7882 - val_loss: 0.4937 - val_acc: 0.7868\n",
      "Epoch 23/500\n",
      "151/152 [============================>.] - ETA: 1s - loss: 0.4355 - acc: 0.8000Epoch 00023: val_loss did not improve\n",
      "152/152 [==============================] - 173s 1s/step - loss: 0.4342 - acc: 0.8007 - val_loss: 0.4802 - val_acc: 0.7684\n",
      "Epoch 24/500\n",
      "151/152 [============================>.] - ETA: 1s - loss: 0.4205 - acc: 0.7907Epoch 00024: val_loss did not improve\n",
      "152/152 [==============================] - 172s 1s/step - loss: 0.4223 - acc: 0.7901 - val_loss: 0.4887 - val_acc: 0.8053\n",
      "Epoch 25/500\n",
      "151/152 [============================>.] - ETA: 1s - loss: 0.4108 - acc: 0.7967Epoch 00025: val_loss did not improve\n",
      "152/152 [==============================] - 172s 1s/step - loss: 0.4092 - acc: 0.7980 - val_loss: 0.5235 - val_acc: 0.8000\n",
      "Epoch 26/500\n",
      "151/152 [============================>.] - ETA: 1s - loss: 0.4146 - acc: 0.8199Epoch 00026: val_loss did not improve\n",
      "152/152 [==============================] - 173s 1s/step - loss: 0.4144 - acc: 0.8204 - val_loss: 0.4782 - val_acc: 0.7737\n",
      "Epoch 27/500\n",
      "151/152 [============================>.] - ETA: 1s - loss: 0.4150 - acc: 0.8066Epoch 00027: val_loss improved from 0.47683 to 0.47597, saving model to model/checkpoints/BestKerasModelVGG16_flat.h5\n",
      "152/152 [==============================] - 173s 1s/step - loss: 0.4139 - acc: 0.8072 - val_loss: 0.4760 - val_acc: 0.8079\n",
      "Epoch 28/500\n",
      "151/152 [============================>.] - ETA: 0s - loss: 0.3969 - acc: 0.8219Epoch 00028: val_loss improved from 0.47597 to 0.45936, saving model to model/checkpoints/BestKerasModelVGG16_flat.h5\n",
      "152/152 [==============================] - 156s 1s/step - loss: 0.3980 - acc: 0.8191 - val_loss: 0.4594 - val_acc: 0.7789\n",
      "Epoch 29/500\n",
      "151/152 [============================>.] - ETA: 0s - loss: 0.3958 - acc: 0.8079Epoch 00029: val_loss did not improve\n",
      "152/152 [==============================] - 149s 981ms/step - loss: 0.3954 - acc: 0.8079 - val_loss: 0.4685 - val_acc: 0.7868\n",
      "Epoch 30/500\n",
      "151/152 [============================>.] - ETA: 0s - loss: 0.3891 - acc: 0.8245Epoch 00030: val_loss did not improve\n",
      "152/152 [==============================] - 150s 984ms/step - loss: 0.3884 - acc: 0.8243 - val_loss: 0.4666 - val_acc: 0.8000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/500\n",
      "151/152 [============================>.] - ETA: 0s - loss: 0.3843 - acc: 0.8212Epoch 00031: val_loss did not improve\n",
      "152/152 [==============================] - 149s 980ms/step - loss: 0.3839 - acc: 0.8211 - val_loss: 0.5118 - val_acc: 0.8132\n",
      "Epoch 32/500\n",
      "151/152 [============================>.] - ETA: 0s - loss: 0.3836 - acc: 0.8278Epoch 00032: val_loss did not improve\n",
      "152/152 [==============================] - 149s 981ms/step - loss: 0.3836 - acc: 0.8276 - val_loss: 0.4660 - val_acc: 0.7789\n",
      "Epoch 33/500\n",
      "151/152 [============================>.] - ETA: 0s - loss: 0.3856 - acc: 0.8166Epoch 00033: val_loss did not improve\n",
      "152/152 [==============================] - 149s 981ms/step - loss: 0.3851 - acc: 0.8164 - val_loss: 0.4974 - val_acc: 0.8053\n",
      "Epoch 34/500\n",
      "151/152 [============================>.] - ETA: 0s - loss: 0.3813 - acc: 0.8212Epoch 00034: val_loss did not improve\n",
      "152/152 [==============================] - 152s 998ms/step - loss: 0.3795 - acc: 0.8217 - val_loss: 0.5485 - val_acc: 0.7868\n",
      "Epoch 35/500\n",
      "151/152 [============================>.] - ETA: 0s - loss: 0.3684 - acc: 0.8331Epoch 00035: val_loss did not improve\n",
      "152/152 [==============================] - 150s 990ms/step - loss: 0.3687 - acc: 0.8336 - val_loss: 0.4903 - val_acc: 0.8000\n",
      "Epoch 36/500\n",
      "151/152 [============================>.] - ETA: 0s - loss: 0.4101 - acc: 0.8060Epoch 00036: val_loss did not improve\n",
      "152/152 [==============================] - 150s 989ms/step - loss: 0.4105 - acc: 0.8053 - val_loss: 0.4699 - val_acc: 0.8132\n",
      "Epoch 37/500\n",
      "151/152 [============================>.] - ETA: 0s - loss: 0.3531 - acc: 0.8391Epoch 00037: val_loss did not improve\n",
      "152/152 [==============================] - 151s 992ms/step - loss: 0.3527 - acc: 0.8388 - val_loss: 0.4692 - val_acc: 0.8000\n",
      "Epoch 38/500\n",
      "151/152 [============================>.] - ETA: 0s - loss: 0.3551 - acc: 0.8411Epoch 00038: val_loss did not improve\n",
      "152/152 [==============================] - 150s 989ms/step - loss: 0.3541 - acc: 0.8421 - val_loss: 0.4658 - val_acc: 0.8132\n",
      "Epoch 39/500\n",
      "151/152 [============================>.] - ETA: 0s - loss: 0.3518 - acc: 0.8497Epoch 00039: val_loss did not improve\n",
      "152/152 [==============================] - 150s 990ms/step - loss: 0.3506 - acc: 0.8500 - val_loss: 0.5034 - val_acc: 0.8158\n",
      "Epoch 40/500\n",
      "151/152 [============================>.] - ETA: 0s - loss: 0.3383 - acc: 0.8483Epoch 00040: val_loss improved from 0.45936 to 0.44683, saving model to model/checkpoints/BestKerasModelVGG16_flat.h5\n",
      "152/152 [==============================] - 152s 1s/step - loss: 0.3401 - acc: 0.8480 - val_loss: 0.4468 - val_acc: 0.8026\n",
      "Epoch 41/500\n",
      "151/152 [============================>.] - ETA: 0s - loss: 0.3445 - acc: 0.8503Epoch 00041: val_loss improved from 0.44683 to 0.44288, saving model to model/checkpoints/BestKerasModelVGG16_flat.h5\n",
      "152/152 [==============================] - 151s 992ms/step - loss: 0.3443 - acc: 0.8500 - val_loss: 0.4429 - val_acc: 0.8211\n",
      "Epoch 42/500\n",
      "151/152 [============================>.] - ETA: 0s - loss: 0.3382 - acc: 0.8543Epoch 00042: val_loss did not improve\n",
      "152/152 [==============================] - 151s 992ms/step - loss: 0.3375 - acc: 0.8546 - val_loss: 0.5346 - val_acc: 0.8211\n",
      "Epoch 43/500\n",
      "151/152 [============================>.] - ETA: 0s - loss: 0.3408 - acc: 0.8358Epoch 00043: val_loss did not improve\n",
      "152/152 [==============================] - 150s 987ms/step - loss: 0.3400 - acc: 0.8368 - val_loss: 0.4486 - val_acc: 0.7947\n",
      "Epoch 44/500\n",
      "151/152 [============================>.] - ETA: 0s - loss: 0.3238 - acc: 0.8444Epoch 00044: val_loss did not improve\n",
      "152/152 [==============================] - 150s 989ms/step - loss: 0.3263 - acc: 0.8434 - val_loss: 0.4816 - val_acc: 0.7947\n",
      "Epoch 45/500\n",
      "151/152 [============================>.] - ETA: 0s - loss: 0.3286 - acc: 0.8570Epoch 00045: val_loss did not improve\n",
      "152/152 [==============================] - 150s 990ms/step - loss: 0.3287 - acc: 0.8572 - val_loss: 0.5140 - val_acc: 0.7632\n",
      "Epoch 46/500\n",
      "151/152 [============================>.] - ETA: 0s - loss: 0.3288 - acc: 0.8503Epoch 00046: val_loss did not improve\n",
      "152/152 [==============================] - 150s 987ms/step - loss: 0.3278 - acc: 0.8507 - val_loss: 0.5044 - val_acc: 0.8263\n",
      "Epoch 47/500\n",
      "151/152 [============================>.] - ETA: 0s - loss: 0.3215 - acc: 0.8563Epoch 00047: val_loss did not improve\n",
      "152/152 [==============================] - 150s 990ms/step - loss: 0.3228 - acc: 0.8553 - val_loss: 0.5219 - val_acc: 0.7842\n",
      "Epoch 48/500\n",
      "151/152 [============================>.] - ETA: 0s - loss: 0.3073 - acc: 0.8596Epoch 00048: val_loss did not improve\n",
      "152/152 [==============================] - 157s 1s/step - loss: 0.3067 - acc: 0.8605 - val_loss: 0.5091 - val_acc: 0.7763\n",
      "Epoch 49/500\n",
      "151/152 [============================>.] - ETA: 1s - loss: 0.3067 - acc: 0.8669Epoch 00049: val_loss did not improve\n",
      "152/152 [==============================] - 176s 1s/step - loss: 0.3057 - acc: 0.8671 - val_loss: 0.5739 - val_acc: 0.8263\n",
      "Epoch 50/500\n",
      "151/152 [============================>.] - ETA: 1s - loss: 0.2879 - acc: 0.8742Epoch 00050: val_loss did not improve\n",
      "152/152 [==============================] - 184s 1s/step - loss: 0.2876 - acc: 0.8743 - val_loss: 0.5185 - val_acc: 0.7763\n",
      "Epoch 51/500\n",
      "151/152 [============================>.] - ETA: 1s - loss: 0.3093 - acc: 0.8675Epoch 00051: val_loss did not improve\n",
      "152/152 [==============================] - 184s 1s/step - loss: 0.3084 - acc: 0.8684 - val_loss: 0.5060 - val_acc: 0.8184\n",
      "Epoch 52/500\n",
      "151/152 [============================>.] - ETA: 1s - loss: 0.3076 - acc: 0.8709Epoch 00052: val_loss did not improve\n",
      "152/152 [==============================] - 184s 1s/step - loss: 0.3081 - acc: 0.8697 - val_loss: 0.4765 - val_acc: 0.8342\n",
      "Epoch 53/500\n",
      " 57/152 [==========>...................] - ETA: 1:39 - loss: 0.3115 - acc: 0.8596"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[10,64,149,149]\n\t [[Node: training/SGD/gradients/block1_pool/MaxPool_grad/MaxPoolGrad = MaxPoolGrad[T=DT_FLOAT, _class=[\"loc:@block1_pool/MaxPool\"], data_format=\"NHWC\", ksize=[1, 2, 2, 1], padding=\"VALID\", strides=[1, 2, 2, 1], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](block1_conv2/Relu, block1_pool/MaxPool, training/SGD/gradients/block2_conv1/convolution_grad/Conv2DBackpropInput)]]\n\nCaused by op u'training/SGD/gradients/block1_pool/MaxPool_grad/MaxPoolGrad', defined at:\n  File \"/home/paul/anaconda2/lib/python2.7/runpy.py\", line 174, in _run_module_as_main\n    \"__main__\", fname, loader, pkg_name)\n  File \"/home/paul/anaconda2/lib/python2.7/runpy.py\", line 72, in _run_code\n    exec code in run_globals\n  File \"/home/paul/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/paul/anaconda2/lib/python2.7/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/paul/anaconda2/lib/python2.7/site-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/home/paul/anaconda2/lib/python2.7/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/paul/anaconda2/lib/python2.7/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/home/paul/anaconda2/lib/python2.7/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/paul/anaconda2/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/paul/anaconda2/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/paul/anaconda2/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/paul/anaconda2/lib/python2.7/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/paul/anaconda2/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/paul/anaconda2/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/paul/anaconda2/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/paul/anaconda2/lib/python2.7/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/paul/anaconda2/lib/python2.7/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/paul/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2718, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/paul/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2828, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/paul/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-12-a80d80e8f991>\", line 1, in <module>\n    get_ipython().run_cell_magic(u'time', u'', u\"#Lets define the image transormations that we wan\\n\\ngen = ImageDataGenerator(horizontal_flip=True,\\n                         vertical_flip=True,\\n                         width_shift_range=0.2,\\n                         height_shift_range=0.2,\\n                         zoom_range=0.2,\\n                         rotation_range=40)\\n\\n# Here is the function that merges our two generators\\n# We use the exact same generator with the same random seed for both the y and angle arrays\\ndef gen_flow_for_one_input(X1, y):\\n    genX1 = gen.flow(X1, y, batch_size=batch_size, seed=42)\\n    while True:\\n        X1i = genX1.next()\\n        yield X1i[0], X1i[1]\\n\\n#Finally create out generator\\ngen_flow = gen_flow_for_one_input(X_train, Y_train)\\n\\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint\\nepochs_to_wait_for_improve = 50\\nearly_stopping_callback = EarlyStopping(monitor='val_loss', patience=epochs_to_wait_for_improve)\\ncheckpoint_callback = ModelCheckpoint(weights_path + 'BestKerasModelVGG16_flat.h5', monitor='val_loss',\\n                                      verbose=1, save_best_only=True, mode='min')\\n#fit the model\\nmodel.fit_generator(gen_flow, validation_data=(X_valid, Y_valid),\\n                    steps_per_epoch=int(np.ceil(len(X_train)/batch_size)),\\n                    epochs=500, verbose=1, callbacks=[early_stopping_callback, checkpoint_callback])\")\n  File \"/home/paul/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2117, in run_cell_magic\n    result = fn(magic_arg_s, cell)\n  File \"<decorator-gen-60>\", line 2, in time\n  File \"/home/paul/anaconda2/lib/python2.7/site-packages/IPython/core/magic.py\", line 188, in <lambda>\n    call = lambda f, *a, **k: f(*a, **k)\n  File \"/home/paul/anaconda2/lib/python2.7/site-packages/IPython/core/magics/execution.py\", line 1185, in time\n    exec(code, glob, local_ns)\n  File \"<timed exec>\", line 29, in <module>\n  File \"/home/paul/anaconda2/lib/python2.7/site-packages/keras/legacy/interfaces.py\", line 87, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/paul/anaconda2/lib/python2.7/site-packages/keras/engine/training.py\", line 1961, in fit_generator\n    self._make_train_function()\n  File \"/home/paul/anaconda2/lib/python2.7/site-packages/keras/engine/training.py\", line 990, in _make_train_function\n    loss=self.total_loss)\n  File \"/home/paul/anaconda2/lib/python2.7/site-packages/keras/legacy/interfaces.py\", line 87, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/paul/anaconda2/lib/python2.7/site-packages/keras/optimizers.py\", line 156, in get_updates\n    grads = self.get_gradients(loss, params)\n  File \"/home/paul/anaconda2/lib/python2.7/site-packages/keras/optimizers.py\", line 73, in get_gradients\n    grads = K.gradients(loss, params)\n  File \"/home/paul/anaconda2/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py\", line 2369, in gradients\n    return tf.gradients(loss, variables, colocate_gradients_with_ops=True)\n  File \"/home/paul/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/gradients_impl.py\", line 581, in gradients\n    grad_scope, op, func_call, lambda: grad_fn(op, *out_grads))\n  File \"/home/paul/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/gradients_impl.py\", line 353, in _MaybeCompile\n    return grad_fn()  # Exit early\n  File \"/home/paul/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/gradients_impl.py\", line 581, in <lambda>\n    grad_scope, op, func_call, lambda: grad_fn(op, *out_grads))\n  File \"/home/paul/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/nn_grad.py\", line 555, in _MaxPoolGrad\n    data_format=op.get_attr(\"data_format\"))\n  File \"/home/paul/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/gen_nn_ops.py\", line 3083, in _max_pool_grad\n    data_format=data_format, name=name)\n  File \"/home/paul/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/paul/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 2956, in create_op\n    op_def=op_def)\n  File \"/home/paul/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1470, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\n...which was originally created as op u'block1_pool/MaxPool', defined at:\n  File \"/home/paul/anaconda2/lib/python2.7/runpy.py\", line 174, in _run_module_as_main\n    \"__main__\", fname, loader, pkg_name)\n[elided 16 identical lines from previous traceback]\n  File \"/home/paul/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2718, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/paul/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2822, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/paul/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-9-a05e4143959a>\", line 2, in <module>\n    base_model = VGG16(weights='imagenet', include_top=False, input_shape=(299,299,3))\n  File \"/home/paul/anaconda2/lib/python2.7/site-packages/keras/applications/vgg16.py\", line 114, in VGG16\n    x = MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool')(x)\n  File \"/home/paul/anaconda2/lib/python2.7/site-packages/keras/engine/topology.py\", line 603, in __call__\n    output = self.call(inputs, **kwargs)\n  File \"/home/paul/anaconda2/lib/python2.7/site-packages/keras/layers/pooling.py\", line 154, in call\n    data_format=self.data_format)\n  File \"/home/paul/anaconda2/lib/python2.7/site-packages/keras/layers/pooling.py\", line 217, in _pooling_function\n    pool_mode='max')\n  File \"/home/paul/anaconda2/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py\", line 3456, in pool2d\n    data_format=tf_data_format)\n  File \"/home/paul/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/nn_ops.py\", line 1958, in max_pool\n    name=name)\n  File \"/home/paul/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/gen_nn_ops.py\", line 2806, in _max_pool\n    data_format=data_format, name=name)\n  File \"/home/paul/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/paul/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 2956, in create_op\n    op_def=op_def)\n  File \"/home/paul/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1470, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[10,64,149,149]\n\t [[Node: training/SGD/gradients/block1_pool/MaxPool_grad/MaxPoolGrad = MaxPoolGrad[T=DT_FLOAT, _class=[\"loc:@block1_pool/MaxPool\"], data_format=\"NHWC\", ksize=[1, 2, 2, 1], padding=\"VALID\", strides=[1, 2, 2, 1], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](block1_conv2/Relu, block1_pool/MaxPool, training/SGD/gradients/block2_conv1/convolution_grad/Conv2DBackpropInput)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-a80d80e8f991>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mu'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mu''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mu\"#Lets define the image transormations that we wan\\n\\ngen = ImageDataGenerator(horizontal_flip=True,\\n                         vertical_flip=True,\\n                         width_shift_range=0.2,\\n                         height_shift_range=0.2,\\n                         zoom_range=0.2,\\n                         rotation_range=40)\\n\\n# Here is the function that merges our two generators\\n# We use the exact same generator with the same random seed for both the y and angle arrays\\ndef gen_flow_for_one_input(X1, y):\\n    genX1 = gen.flow(X1, y, batch_size=batch_size, seed=42)\\n    while True:\\n        X1i = genX1.next()\\n        yield X1i[0], X1i[1]\\n\\n#Finally create out generator\\ngen_flow = gen_flow_for_one_input(X_train, Y_train)\\n\\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint\\nepochs_to_wait_for_improve = 50\\nearly_stopping_callback = EarlyStopping(monitor='val_loss', patience=epochs_to_wait_for_improve)\\ncheckpoint_callback = ModelCheckpoint(weights_path + 'BestKerasModelVGG16_flat.h5', monitor='val_loss',\\n                                      verbose=1, save_best_only=True, mode='min')\\n#fit the model\\nmodel.fit_generator(gen_flow, validation_data=(X_valid, Y_valid),\\n                    steps_per_epoch=int(np.ceil(len(X_train)/batch_size)),\\n                    epochs=500, verbose=1, callbacks=[early_stopping_callback, checkpoint_callback])\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/paul/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.pyc\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2115\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2116\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2117\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2118\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<decorator-gen-60>\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n",
      "\u001b[0;32m/home/paul/anaconda2/lib/python2.7/site-packages/IPython/core/magic.pyc\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/paul/anaconda2/lib/python2.7/site-packages/IPython/core/magics/execution.pyc\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1183\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1184\u001b[0m             \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1185\u001b[0;31m             \u001b[0;32mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1186\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1187\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/home/paul/anaconda2/lib/python2.7/site-packages/keras/legacy/interfaces.pyc\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     86\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/paul/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2075\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[1;32m   2076\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2077\u001b[0;31m                                                class_weight=class_weight)\n\u001b[0m\u001b[1;32m   2078\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2079\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/paul/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1795\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1796\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1797\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1798\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1799\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/paul/anaconda2/lib/python2.7/site-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2330\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[1;32m   2331\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2332\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2333\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2334\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/paul/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/paul/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/paul/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/paul/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1334\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1335\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1336\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1338\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[10,64,149,149]\n\t [[Node: training/SGD/gradients/block1_pool/MaxPool_grad/MaxPoolGrad = MaxPoolGrad[T=DT_FLOAT, _class=[\"loc:@block1_pool/MaxPool\"], data_format=\"NHWC\", ksize=[1, 2, 2, 1], padding=\"VALID\", strides=[1, 2, 2, 1], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](block1_conv2/Relu, block1_pool/MaxPool, training/SGD/gradients/block2_conv1/convolution_grad/Conv2DBackpropInput)]]\n\nCaused by op u'training/SGD/gradients/block1_pool/MaxPool_grad/MaxPoolGrad', defined at:\n  File \"/home/paul/anaconda2/lib/python2.7/runpy.py\", line 174, in _run_module_as_main\n    \"__main__\", fname, loader, pkg_name)\n  File \"/home/paul/anaconda2/lib/python2.7/runpy.py\", line 72, in _run_code\n    exec code in run_globals\n  File \"/home/paul/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/paul/anaconda2/lib/python2.7/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/paul/anaconda2/lib/python2.7/site-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/home/paul/anaconda2/lib/python2.7/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/paul/anaconda2/lib/python2.7/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/home/paul/anaconda2/lib/python2.7/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/paul/anaconda2/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/paul/anaconda2/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/paul/anaconda2/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/paul/anaconda2/lib/python2.7/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/paul/anaconda2/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/paul/anaconda2/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/paul/anaconda2/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/paul/anaconda2/lib/python2.7/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/paul/anaconda2/lib/python2.7/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/paul/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2718, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/paul/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2828, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/paul/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-12-a80d80e8f991>\", line 1, in <module>\n    get_ipython().run_cell_magic(u'time', u'', u\"#Lets define the image transormations that we wan\\n\\ngen = ImageDataGenerator(horizontal_flip=True,\\n                         vertical_flip=True,\\n                         width_shift_range=0.2,\\n                         height_shift_range=0.2,\\n                         zoom_range=0.2,\\n                         rotation_range=40)\\n\\n# Here is the function that merges our two generators\\n# We use the exact same generator with the same random seed for both the y and angle arrays\\ndef gen_flow_for_one_input(X1, y):\\n    genX1 = gen.flow(X1, y, batch_size=batch_size, seed=42)\\n    while True:\\n        X1i = genX1.next()\\n        yield X1i[0], X1i[1]\\n\\n#Finally create out generator\\ngen_flow = gen_flow_for_one_input(X_train, Y_train)\\n\\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint\\nepochs_to_wait_for_improve = 50\\nearly_stopping_callback = EarlyStopping(monitor='val_loss', patience=epochs_to_wait_for_improve)\\ncheckpoint_callback = ModelCheckpoint(weights_path + 'BestKerasModelVGG16_flat.h5', monitor='val_loss',\\n                                      verbose=1, save_best_only=True, mode='min')\\n#fit the model\\nmodel.fit_generator(gen_flow, validation_data=(X_valid, Y_valid),\\n                    steps_per_epoch=int(np.ceil(len(X_train)/batch_size)),\\n                    epochs=500, verbose=1, callbacks=[early_stopping_callback, checkpoint_callback])\")\n  File \"/home/paul/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2117, in run_cell_magic\n    result = fn(magic_arg_s, cell)\n  File \"<decorator-gen-60>\", line 2, in time\n  File \"/home/paul/anaconda2/lib/python2.7/site-packages/IPython/core/magic.py\", line 188, in <lambda>\n    call = lambda f, *a, **k: f(*a, **k)\n  File \"/home/paul/anaconda2/lib/python2.7/site-packages/IPython/core/magics/execution.py\", line 1185, in time\n    exec(code, glob, local_ns)\n  File \"<timed exec>\", line 29, in <module>\n  File \"/home/paul/anaconda2/lib/python2.7/site-packages/keras/legacy/interfaces.py\", line 87, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/paul/anaconda2/lib/python2.7/site-packages/keras/engine/training.py\", line 1961, in fit_generator\n    self._make_train_function()\n  File \"/home/paul/anaconda2/lib/python2.7/site-packages/keras/engine/training.py\", line 990, in _make_train_function\n    loss=self.total_loss)\n  File \"/home/paul/anaconda2/lib/python2.7/site-packages/keras/legacy/interfaces.py\", line 87, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/paul/anaconda2/lib/python2.7/site-packages/keras/optimizers.py\", line 156, in get_updates\n    grads = self.get_gradients(loss, params)\n  File \"/home/paul/anaconda2/lib/python2.7/site-packages/keras/optimizers.py\", line 73, in get_gradients\n    grads = K.gradients(loss, params)\n  File \"/home/paul/anaconda2/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py\", line 2369, in gradients\n    return tf.gradients(loss, variables, colocate_gradients_with_ops=True)\n  File \"/home/paul/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/gradients_impl.py\", line 581, in gradients\n    grad_scope, op, func_call, lambda: grad_fn(op, *out_grads))\n  File \"/home/paul/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/gradients_impl.py\", line 353, in _MaybeCompile\n    return grad_fn()  # Exit early\n  File \"/home/paul/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/gradients_impl.py\", line 581, in <lambda>\n    grad_scope, op, func_call, lambda: grad_fn(op, *out_grads))\n  File \"/home/paul/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/nn_grad.py\", line 555, in _MaxPoolGrad\n    data_format=op.get_attr(\"data_format\"))\n  File \"/home/paul/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/gen_nn_ops.py\", line 3083, in _max_pool_grad\n    data_format=data_format, name=name)\n  File \"/home/paul/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/paul/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 2956, in create_op\n    op_def=op_def)\n  File \"/home/paul/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1470, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\n...which was originally created as op u'block1_pool/MaxPool', defined at:\n  File \"/home/paul/anaconda2/lib/python2.7/runpy.py\", line 174, in _run_module_as_main\n    \"__main__\", fname, loader, pkg_name)\n[elided 16 identical lines from previous traceback]\n  File \"/home/paul/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2718, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/paul/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2822, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/paul/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-9-a05e4143959a>\", line 2, in <module>\n    base_model = VGG16(weights='imagenet', include_top=False, input_shape=(299,299,3))\n  File \"/home/paul/anaconda2/lib/python2.7/site-packages/keras/applications/vgg16.py\", line 114, in VGG16\n    x = MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool')(x)\n  File \"/home/paul/anaconda2/lib/python2.7/site-packages/keras/engine/topology.py\", line 603, in __call__\n    output = self.call(inputs, **kwargs)\n  File \"/home/paul/anaconda2/lib/python2.7/site-packages/keras/layers/pooling.py\", line 154, in call\n    data_format=self.data_format)\n  File \"/home/paul/anaconda2/lib/python2.7/site-packages/keras/layers/pooling.py\", line 217, in _pooling_function\n    pool_mode='max')\n  File \"/home/paul/anaconda2/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py\", line 3456, in pool2d\n    data_format=tf_data_format)\n  File \"/home/paul/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/nn_ops.py\", line 1958, in max_pool\n    name=name)\n  File \"/home/paul/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/gen_nn_ops.py\", line 2806, in _max_pool\n    data_format=data_format, name=name)\n  File \"/home/paul/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/paul/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 2956, in create_op\n    op_def=op_def)\n  File \"/home/paul/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1470, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[10,64,149,149]\n\t [[Node: training/SGD/gradients/block1_pool/MaxPool_grad/MaxPoolGrad = MaxPoolGrad[T=DT_FLOAT, _class=[\"loc:@block1_pool/MaxPool\"], data_format=\"NHWC\", ksize=[1, 2, 2, 1], padding=\"VALID\", strides=[1, 2, 2, 1], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](block1_conv2/Relu, block1_pool/MaxPool, training/SGD/gradients/block2_conv1/convolution_grad/Conv2DBackpropInput)]]\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Lets define the image transormations that we wan\n",
    "\n",
    "gen = ImageDataGenerator(horizontal_flip=True,\n",
    "                         vertical_flip=True,\n",
    "                         width_shift_range=0.2,\n",
    "                         height_shift_range=0.2,\n",
    "                         zoom_range=0.2,\n",
    "                         rotation_range=40)\n",
    "\n",
    "# Here is the function that merges our two generators\n",
    "# We use the exact same generator with the same random seed for both the y and angle arrays\n",
    "def gen_flow_for_one_input(X1, y):\n",
    "    genX1 = gen.flow(X1, y, batch_size=batch_size, seed=42)\n",
    "    while True:\n",
    "        X1i = genX1.next()\n",
    "        yield X1i[0], X1i[1]\n",
    "\n",
    "#Finally create out generator\n",
    "gen_flow = gen_flow_for_one_input(X_train, Y_train)\n",
    "\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "epochs_to_wait_for_improve = 50\n",
    "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=epochs_to_wait_for_improve)\n",
    "checkpoint_callback = ModelCheckpoint(weights_path + 'BestKerasModelVGG16_flat.h5', monitor='val_loss',\n",
    "                                      verbose=1, save_best_only=True, mode='min')\n",
    "#fit the model\n",
    "model.fit_generator(gen_flow, validation_data=(X_valid, Y_valid),\n",
    "                    steps_per_epoch=int(np.ceil(len(X_train)/batch_size)),\n",
    "                    epochs=500, verbose=1, callbacks=[early_stopping_callback, checkpoint_callback])\n",
    "                    #class_weights = class_weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Â IV. Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(weights_path+\"BestKerasModelVGG16_flat.h5\")\n",
    "score = model.evaluate(X_valid, Y_valid, verbose=1)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#compute log loss\n",
    "pred = model.predict(X_valid)\n",
    "log_loss(Y_valid,pred)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#Generate the training data\n",
    "#Create 3 bands having HH, HV and avg of both\n",
    "X_band_1=np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in train[\"band_1\"]])\n",
    "X_band_2=np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in train[\"band_2\"]])\n",
    "X_train = np.concatenate([X_band_1[:, :, :, np.newaxis], X_band_2[:, :, :, np.newaxis],\n",
    "                          ((X_band_1+X_band_2)/2)[:, :, :, np.newaxis]], axis=-1)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#parse corrupted notebook file\n",
    "t = [\"#Generate the training data\\n\",\n",
    "    \"#Create 3 bands having HH, HV and avg of both\\n\",\n",
    "    \"X_band_1=np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in train[\\\"band_1\\\"]])\\n\",\n",
    "    \"X_band_2=np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in train[\\\"band_2\\\"]])\\n\",\n",
    "    \"X_train = np.concatenate([X_band_1[:, :, :, np.newaxis], X_band_2[:, :, :, np.newaxis],\\n\",\n",
    "    \"                          ((X_band_1+X_band_2)/2)[:, :, :, np.newaxis]], axis=-1)\"]\n",
    "#t.remove(\"\\n\")\n",
    "t=[x.replace(\"\\n\",'') for x in t]\n",
    "for x in t:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
