{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#general & system\\n\",\n",
    "import os\n",
    "\n",
    "#data processing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.rcParams['figure.figsize'] = 10, 10  #default setting\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "#data augmentation\n",
    "from PIL import Image\n",
    "from random import choice\n",
    "import cv2\n",
    "import numpy as np\n",
    "#import keras.preprocessing.image as prep\n",
    "\n",
    "#ML part\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.applications.resnet50 import preprocess_input\n",
    "from keras.preprocessing import image as kimage\n",
    "from keras.models import Sequential\n",
    "from keras.layers import GlobalMaxPooling2D, Dense, BatchNormalization, GlobalAveragePooling2D,Dropout,Activation,Flatten\n",
    "from keras.models import Model\n",
    "from keras.optimizers import SGD\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "#validation\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import roc_curve, auc,classification_report,roc_auc_score\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import roc_curve, auc,classification_report,roc_auc_score\n",
    "\n",
    "\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.utils import resample\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8 ms, sys: 0 ns, total: 8 ms\n",
      "Wall time: 5.59 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "meta = pd.read_csv(\"../data/label_learn.csv\", sep = \";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000000.jpg</td>\n",
       "      <td>benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000002.jpg</td>\n",
       "      <td>malignant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0000006.jpg</td>\n",
       "      <td>benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0000008.jpg</td>\n",
       "      <td>benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0000009.jpg</td>\n",
       "      <td>benign</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          name      label\n",
       "0  0000000.jpg     benign\n",
       "1  0000002.jpg  malignant\n",
       "2  0000006.jpg     benign\n",
       "3  0000008.jpg     benign\n",
       "4  0000009.jpg     benign"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 4 ms, total: 4 ms\n",
      "Wall time: 4.29 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_list = os.listdir(\"../data/norm_dir/\")\n",
    "len(train_list) == len(meta.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 22.6 s, sys: 1.64 s, total: 24.2 s\n",
      "Wall time: 24 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train = np.array([np.array(Image.open(\"../data/resized_train/\"+fname)) for fname in meta.name])\n",
    "Y_train = [1 if x==\"malignant\" else 0 for x in meta.label]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hair removal : "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We proceed following the steps :\n",
    "\n",
    "- Data acquisition : Select a subset of data with Hair\n",
    "- RGB to Grayscale conversion â€“ Contrast Enhancement: Convert to Gray scale\n",
    "- Binarization : Binarize the Image : Convert the image to binary using an adaptive threshold\n",
    "- Edge Detection : Using Canny edge detector algorithm\n",
    "- Removal non-hair edges : \n",
    "- Hair mask creation : \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data split for validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(X_train)\n",
    "Y_train = np.array(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=2, random_state=None, shuffle=False)\n",
    "Data_sets = []\n",
    "for train_index, test_index in skf.split(X_train, Y_train):\n",
    "    x_train, x_valid = X_train[train_index], X_train[test_index]\n",
    "    y_train, y_valid = Y_train[train_index], Y_train[test_index]\n",
    "    Data_sets.append([x_train, x_valid, y_train, y_valid])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = np.array(Data_sets[0][0])\n",
    "Y_train = np.array(Data_sets[0][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = sum(Y_train)\n",
    "sample_size = temp*2700/(374+254)  #1372\n",
    "sample_size\n",
    "def random_undersampling(X, Y,sample_size = sample_size, n_sample=1):\n",
    "    \"\"\"\n",
    "    X,y : numpy arrays\n",
    "    return :\n",
    "    5 random ensemble of indices general_balenced_set:\n",
    "        general_balenced_set[0] = the shuffeled indices that inssure the class balance\n",
    "    \"\"\"\n",
    "    indices = np.array(range(len(Y)))\n",
    "    positive_samples = indices[Y==1]\n",
    "    #print(type(positive_samples))\n",
    "    negative_samples = indices[Y==0]\n",
    "    #print(type(negative_samples))\n",
    "    general_balenced_set = []\n",
    "    for k in range(n_sample):\n",
    "        indices_ = np.random.choice(negative_samples, sample_size, replace=False)\n",
    "        #print(len(indices_))\n",
    "        # append positive and negative\n",
    "        balenced_set = np.append(indices_, positive_samples)\n",
    "        #print(len(balenced_set))\n",
    "        # shuffle indices\n",
    "        np.random.shuffle(balenced_set)\n",
    "        #print(len(balenced_set))\n",
    "        general_balenced_set.append(balenced_set)\n",
    "    return general_balenced_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "general_balenced_set = random_undersampling(X_train,Y_train)\n",
    "X_train = X_train[general_balenced_set]\n",
    "Y_train = Y_train[general_balenced_set]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss Function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "def weighted_categorical_crossentropy(weights):\n",
    "    \"\"\"\n",
    "    [w_0, w_1] : weight of 0 class and weight of 1 class\n",
    "    \"\"\"\n",
    "    weights = K.variable(weights)\n",
    "\n",
    "    def loss(y_true, y_pred):\n",
    "        # scale predictions so that the class probas of each sample sum to 1\n",
    "        #y_pred /= K.sum(y_pred, axis=-1, keepdims=True)\n",
    "        # clip to prevent NaN's and Inf's\n",
    "        y_pred = K.clip(y_pred, K.epsilon(), 1 - K.epsilon())\n",
    "        # calc\n",
    "        loss = y_true * K.log(y_pred) * weights[1] + (1 - y_true) * K.log(1 - y_pred) * weights[0]\n",
    "        loss = -K.sum(loss, -1)\n",
    "        return loss\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss1 = weighted_categorical_crossentropy(np.array([0.8,4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weight_or = np.array([0.8,4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics to print "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#freeze lower layers of the model\n",
    "#for layer in model.layers[:]:\n",
    "    #layer.trainable = False\n",
    "for layer in model.layers[0:]:\n",
    "    layer.trainable = True\n",
    "    \n",
    "\n",
    "def sensitivity(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    return true_positives / (possible_positives + K.epsilon())\n",
    "\n",
    "def specificity(y_true, y_pred):\n",
    "    true_negatives = K.sum(K.round(K.clip((1-y_true) * (1-y_pred), 0, 1)))\n",
    "    possible_negatives = K.sum(K.round(K.clip(1-y_true, 0, 1)))\n",
    "    return true_negatives / (possible_negatives + K.epsilon())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define  Deep Learing Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_path = '../model/checkpoints/'\n",
    "\n",
    "if not os.path.exists(weights_path):\n",
    "    os.makedirs(weights_path)\n",
    "    \n",
    "epochs = 500\n",
    "batch_size = 50\n",
    "\n",
    "#load base model\n",
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(299,299,3))\n",
    "#adding top layers\n",
    "    #sequentialy\n",
    "add_model = Sequential()\n",
    "add_model.add(GlobalAveragePooling2D(input_shape=base_model.output_shape[1:])) #Flatten/GlobalAveragePooling2D\n",
    "add_model.add(Dense(1024, activation='relu'))\n",
    "add_model.add(Dropout(0.25))\n",
    "add_model.add(Dense(512, activation='relu'))\n",
    "add_model.add(Dropout(0.25))\n",
    "add_model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=add_model(base_model.output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.compile(optimizer=SGD(lr=0.0001, momentum=0.9), loss=loss1, #binary_crossentropy\n",
    "              metrics=[sensitivity, specificity,\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "34/35 [============================>.] - ETA: 1s - loss: 1.0616 - sensitivity: 0.5016 - specificity: 0.5585 - acc: 0.5482Epoch 00001: val_loss improved from inf to 0.72096, saving model to ../model/checkpoints/BestKerasResnet50_flat_3_loss.h5\n",
      "35/35 [==============================] - 95s 3s/step - loss: 1.0540 - sensitivity: 0.5158 - specificity: 0.5555 - acc: 0.5480 - val_loss: 0.7210 - val_sensitivity: 0.1454 - val_specificity: 0.3268 - val_acc: 0.3848\n",
      "Epoch 2/500\n",
      "34/35 [============================>.] - ETA: 0s - loss: 0.8220 - sensitivity: 0.8447 - specificity: 0.5127 - acc: 0.5740Epoch 00002: val_loss improved from 0.72096 to 0.60980, saving model to ../model/checkpoints/BestKerasResnet50_flat_3_loss.h5\n",
      "35/35 [==============================] - 49s 1s/step - loss: 0.8195 - sensitivity: 0.8467 - specificity: 0.5161 - acc: 0.5776 - val_loss: 0.6098 - val_sensitivity: 0.1181 - val_specificity: 0.7413 - val_acc: 0.7772\n",
      "Epoch 3/500\n",
      "34/35 [============================>.] - ETA: 0s - loss: 0.7208 - sensitivity: 0.8190 - specificity: 0.6884 - acc: 0.7098Epoch 00003: val_loss improved from 0.60980 to 0.53151, saving model to ../model/checkpoints/BestKerasResnet50_flat_3_loss.h5\n",
      "35/35 [==============================] - 49s 1s/step - loss: 0.7205 - sensitivity: 0.8178 - specificity: 0.6890 - acc: 0.7101 - val_loss: 0.5315 - val_sensitivity: 0.1131 - val_specificity: 0.8472 - val_acc: 0.8781\n",
      "Epoch 4/500\n",
      "34/35 [============================>.] - ETA: 0s - loss: 0.6589 - sensitivity: 0.8507 - specificity: 0.7287 - acc: 0.7496Epoch 00004: val_loss improved from 0.53151 to 0.47428, saving model to ../model/checkpoints/BestKerasResnet50_flat_3_loss.h5\n",
      "35/35 [==============================] - 49s 1s/step - loss: 0.6651 - sensitivity: 0.8371 - specificity: 0.7296 - acc: 0.7482 - val_loss: 0.4743 - val_sensitivity: 0.0983 - val_specificity: 0.9127 - val_acc: 0.9306\n",
      "Epoch 5/500\n",
      "34/35 [============================>.] - ETA: 0s - loss: 0.6407 - sensitivity: 0.8842 - specificity: 0.7428 - acc: 0.7659Epoch 00005: val_loss improved from 0.47428 to 0.41667, saving model to ../model/checkpoints/BestKerasResnet50_flat_3_loss.h5\n",
      "35/35 [==============================] - 49s 1s/step - loss: 0.6363 - sensitivity: 0.8875 - specificity: 0.7421 - acc: 0.7652 - val_loss: 0.4167 - val_sensitivity: 0.1112 - val_specificity: 0.9131 - val_acc: 0.9361\n",
      "Epoch 6/500\n",
      "34/35 [============================>.] - ETA: 0s - loss: 0.5980 - sensitivity: 0.8873 - specificity: 0.7956 - acc: 0.8078Epoch 00006: val_loss improved from 0.41667 to 0.36160, saving model to ../model/checkpoints/BestKerasResnet50_flat_3_loss.h5\n",
      "35/35 [==============================] - 49s 1s/step - loss: 0.6015 - sensitivity: 0.8829 - specificity: 0.7973 - acc: 0.8082 - val_loss: 0.3616 - val_sensitivity: 0.1160 - val_specificity: 0.9132 - val_acc: 0.9394\n",
      "Epoch 7/500\n",
      "34/35 [============================>.] - ETA: 0s - loss: 0.5452 - sensitivity: 0.9036 - specificity: 0.7880 - acc: 0.8077Epoch 00007: val_loss improved from 0.36160 to 0.35177, saving model to ../model/checkpoints/BestKerasResnet50_flat_3_loss.h5\n",
      "35/35 [==============================] - 49s 1s/step - loss: 0.5440 - sensitivity: 0.9063 - specificity: 0.7852 - acc: 0.8058 - val_loss: 0.3518 - val_sensitivity: 0.1177 - val_specificity: 0.9107 - val_acc: 0.9394\n",
      "Epoch 8/500\n",
      "34/35 [============================>.] - ETA: 0s - loss: 0.5447 - sensitivity: 0.8907 - specificity: 0.8081 - acc: 0.8206Epoch 00008: val_loss improved from 0.35177 to 0.34135, saving model to ../model/checkpoints/BestKerasResnet50_flat_3_loss.h5\n",
      "35/35 [==============================] - 49s 1s/step - loss: 0.5413 - sensitivity: 0.8938 - specificity: 0.8055 - acc: 0.8188 - val_loss: 0.3413 - val_sensitivity: 0.1144 - val_specificity: 0.9184 - val_acc: 0.9422\n",
      "Epoch 9/500\n",
      "34/35 [============================>.] - ETA: 0s - loss: 0.5025 - sensitivity: 0.8965 - specificity: 0.8206 - acc: 0.8336Epoch 00009: val_loss improved from 0.34135 to 0.33748, saving model to ../model/checkpoints/BestKerasResnet50_flat_3_loss.h5\n",
      "35/35 [==============================] - 49s 1s/step - loss: 0.4997 - sensitivity: 0.8994 - specificity: 0.8214 - acc: 0.8349 - val_loss: 0.3375 - val_sensitivity: 0.1118 - val_specificity: 0.9183 - val_acc: 0.9420\n",
      "Epoch 10/500\n",
      "34/35 [============================>.] - ETA: 0s - loss: 0.4633 - sensitivity: 0.9269 - specificity: 0.8176 - acc: 0.8361Epoch 00010: val_loss improved from 0.33748 to 0.32258, saving model to ../model/checkpoints/BestKerasResnet50_flat_3_loss.h5\n",
      "35/35 [==============================] - 49s 1s/step - loss: 0.4670 - sensitivity: 0.9252 - specificity: 0.8187 - acc: 0.8367 - val_loss: 0.3226 - val_sensitivity: 0.1175 - val_specificity: 0.9169 - val_acc: 0.9429\n",
      "Epoch 11/500\n",
      "34/35 [============================>.] - ETA: 0s - loss: 0.4755 - sensitivity: 0.8858 - specificity: 0.8355 - acc: 0.8432Epoch 00011: val_loss improved from 0.32258 to 0.30168, saving model to ../model/checkpoints/BestKerasResnet50_flat_3_loss.h5\n",
      "35/35 [==============================] - 49s 1s/step - loss: 0.4771 - sensitivity: 0.8855 - specificity: 0.8321 - acc: 0.8402 - val_loss: 0.3017 - val_sensitivity: 0.1237 - val_specificity: 0.9120 - val_acc: 0.9427\n",
      "Epoch 12/500\n",
      "34/35 [============================>.] - ETA: 0s - loss: 0.4547 - sensitivity: 0.9106 - specificity: 0.8158 - acc: 0.8326Epoch 00012: val_loss did not improve\n",
      "35/35 [==============================] - 48s 1s/step - loss: 0.4541 - sensitivity: 0.9132 - specificity: 0.8149 - acc: 0.8328 - val_loss: 0.3274 - val_sensitivity: 0.1118 - val_specificity: 0.9205 - val_acc: 0.9420\n",
      "Epoch 13/500\n",
      "34/35 [============================>.] - ETA: 0s - loss: 0.4560 - sensitivity: 0.8914 - specificity: 0.8278 - acc: 0.8368Epoch 00013: val_loss did not improve\n",
      "35/35 [==============================] - 48s 1s/step - loss: 0.4540 - sensitivity: 0.8945 - specificity: 0.8271 - acc: 0.8369 - val_loss: 0.3276 - val_sensitivity: 0.1085 - val_specificity: 0.9203 - val_acc: 0.9408\n",
      "Epoch 14/500\n",
      "34/35 [============================>.] - ETA: 0s - loss: 0.4430 - sensitivity: 0.9008 - specificity: 0.8299 - acc: 0.8409Epoch 00014: val_loss did not improve\n",
      "35/35 [==============================] - 48s 1s/step - loss: 0.4442 - sensitivity: 0.8979 - specificity: 0.8265 - acc: 0.8375 - val_loss: 0.3222 - val_sensitivity: 0.1052 - val_specificity: 0.9240 - val_acc: 0.9427\n",
      "Epoch 15/500\n",
      "34/35 [============================>.] - ETA: 0s - loss: 0.4293 - sensitivity: 0.9208 - specificity: 0.8453 - acc: 0.8568Epoch 00015: val_loss did not improve\n",
      "35/35 [==============================] - 48s 1s/step - loss: 0.4290 - sensitivity: 0.9183 - specificity: 0.8452 - acc: 0.8563 - val_loss: 0.3071 - val_sensitivity: 0.1139 - val_specificity: 0.9186 - val_acc: 0.9424\n",
      "Epoch 16/500\n",
      "34/35 [============================>.] - ETA: 0s - loss: 0.4188 - sensitivity: 0.9314 - specificity: 0.8423 - acc: 0.8573Epoch 00016: val_loss did not improve\n",
      "35/35 [==============================] - 48s 1s/step - loss: 0.4154 - sensitivity: 0.9305 - specificity: 0.8432 - acc: 0.8580 - val_loss: 0.3083 - val_sensitivity: 0.1193 - val_specificity: 0.9177 - val_acc: 0.9450\n",
      "Epoch 17/500\n",
      "34/35 [============================>.] - ETA: 0s - loss: 0.4409 - sensitivity: 0.8807 - specificity: 0.8375 - acc: 0.8451Epoch 00017: val_loss did not improve\n",
      "35/35 [==============================] - 48s 1s/step - loss: 0.4412 - sensitivity: 0.8820 - specificity: 0.8382 - acc: 0.8461 - val_loss: 0.3186 - val_sensitivity: 0.1165 - val_specificity: 0.9208 - val_acc: 0.9464\n",
      "Epoch 18/500\n",
      "34/35 [============================>.] - ETA: 0s - loss: 0.4148 - sensitivity: 0.9227 - specificity: 0.8265 - acc: 0.8439Epoch 00018: val_loss improved from 0.30168 to 0.30156, saving model to ../model/checkpoints/BestKerasResnet50_flat_3_loss.h5\n",
      "35/35 [==============================] - 49s 1s/step - loss: 0.4183 - sensitivity: 0.9197 - specificity: 0.8256 - acc: 0.8426 - val_loss: 0.3016 - val_sensitivity: 0.1200 - val_specificity: 0.9174 - val_acc: 0.9441\n",
      "Epoch 19/500\n",
      "34/35 [============================>.] - ETA: 0s - loss: 0.4291 - sensitivity: 0.9234 - specificity: 0.8424 - acc: 0.8544Epoch 00019: val_loss did not improve\n",
      "35/35 [==============================] - 48s 1s/step - loss: 0.4274 - sensitivity: 0.9256 - specificity: 0.8421 - acc: 0.8546 - val_loss: 0.3171 - val_sensitivity: 0.1018 - val_specificity: 0.9276 - val_acc: 0.9457\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/500\n",
      "34/35 [============================>.] - ETA: 0s - loss: 0.3932 - sensitivity: 0.9417 - specificity: 0.8499 - acc: 0.8655Epoch 00020: val_loss did not improve\n",
      "35/35 [==============================] - 48s 1s/step - loss: 0.3914 - sensitivity: 0.9434 - specificity: 0.8497 - acc: 0.8653 - val_loss: 0.3218 - val_sensitivity: 0.0989 - val_specificity: 0.9285 - val_acc: 0.9441\n",
      "Epoch 21/500\n",
      "34/35 [============================>.] - ETA: 0s - loss: 0.4350 - sensitivity: 0.9165 - specificity: 0.8238 - acc: 0.8385Epoch 00021: val_loss did not improve\n",
      "35/35 [==============================] - 48s 1s/step - loss: 0.4378 - sensitivity: 0.9145 - specificity: 0.8250 - acc: 0.8391 - val_loss: 0.3280 - val_sensitivity: 0.0996 - val_specificity: 0.9267 - val_acc: 0.9427\n",
      "Epoch 22/500\n",
      "34/35 [============================>.] - ETA: 0s - loss: 0.3978 - sensitivity: 0.9234 - specificity: 0.8481 - acc: 0.8586Epoch 00022: val_loss did not improve\n",
      "35/35 [==============================] - 48s 1s/step - loss: 0.3957 - sensitivity: 0.9256 - specificity: 0.8498 - acc: 0.8603 - val_loss: 0.3048 - val_sensitivity: 0.1142 - val_specificity: 0.9203 - val_acc: 0.9443\n",
      "Epoch 23/500\n",
      "34/35 [============================>.] - ETA: 0s - loss: 0.3891 - sensitivity: 0.9076 - specificity: 0.8476 - acc: 0.8589Epoch 00023: val_loss did not improve\n",
      "35/35 [==============================] - 48s 1s/step - loss: 0.3860 - sensitivity: 0.9103 - specificity: 0.8478 - acc: 0.8595 - val_loss: 0.3236 - val_sensitivity: 0.1020 - val_specificity: 0.9251 - val_acc: 0.9424\n",
      "Epoch 24/500\n",
      "34/35 [============================>.] - ETA: 0s - loss: 0.3900 - sensitivity: 0.9150 - specificity: 0.8434 - acc: 0.8554Epoch 00024: val_loss did not improve\n",
      "35/35 [==============================] - 48s 1s/step - loss: 0.3907 - sensitivity: 0.9154 - specificity: 0.8454 - acc: 0.8572 - val_loss: 0.3691 - val_sensitivity: 0.0846 - val_specificity: 0.9330 - val_acc: 0.9410\n",
      "Epoch 25/500\n",
      "34/35 [============================>.] - ETA: 0s - loss: 0.3749 - sensitivity: 0.9173 - specificity: 0.8645 - acc: 0.8726Epoch 00025: val_loss did not improve\n",
      "35/35 [==============================] - 48s 1s/step - loss: 0.3759 - sensitivity: 0.9168 - specificity: 0.8633 - acc: 0.8717 - val_loss: 0.3192 - val_sensitivity: 0.1062 - val_specificity: 0.9223 - val_acc: 0.9431\n",
      "Epoch 26/500\n",
      "34/35 [============================>.] - ETA: 0s - loss: 0.3853 - sensitivity: 0.9334 - specificity: 0.8632 - acc: 0.8738Epoch 00026: val_loss did not improve\n",
      "35/35 [==============================] - 48s 1s/step - loss: 0.3860 - sensitivity: 0.9353 - specificity: 0.8610 - acc: 0.8723 - val_loss: 0.3193 - val_sensitivity: 0.1068 - val_specificity: 0.9240 - val_acc: 0.9443\n",
      "Epoch 27/500\n",
      "34/35 [============================>.] - ETA: 0s - loss: 0.3619 - sensitivity: 0.9521 - specificity: 0.8598 - acc: 0.8755Epoch 00027: val_loss did not improve\n",
      "35/35 [==============================] - 48s 1s/step - loss: 0.3591 - sensitivity: 0.9535 - specificity: 0.8585 - acc: 0.8745 - val_loss: 0.3080 - val_sensitivity: 0.1106 - val_specificity: 0.9201 - val_acc: 0.9427\n",
      "Epoch 28/500\n",
      "34/35 [============================>.] - ETA: 0s - loss: 0.3406 - sensitivity: 0.9515 - specificity: 0.8643 - acc: 0.8792"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-76-a18f0fb14429>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mu'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mu''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mu\"#Lets define the image transormations that we wan\\n\\ngen = ImageDataGenerator(horizontal_flip=True,\\n                         vertical_flip=True,\\n                         width_shift_range=0.2,\\n                         height_shift_range=0.2,\\n                         zoom_range=0.2,\\n                         rotation_range=40)\\n\\nval_datagen = ImageDataGenerator()\\n# Here is the function that merges our two generators\\n# We use the exact same generator with the same random seed for both the y and angle arrays\\ndef gen_flow_for_one_input(X1, y):\\n    genX1 = gen.flow(X1, y, batch_size=batch_size, seed=42)\\n    while True:\\n        X1i = genX1.next()\\n        yield X1i[0], X1i[1]\\n\\ndef val_datagen_(X1, y):\\n    genX1 = val_datagen.flow(X1, y, batch_size=batch_size, seed=42)\\n    while True:\\n        X1i = genX1.next()\\n        yield X1i[0], X1i[1]\\n#Finally create out generator\\ngen_flow_train = gen_flow_for_one_input(X_train, Y_train)\\n#gen_flow_val = gen_flow_for_one_input(X_valid, Y_valid)\\ngen_flow_val = val_datagen_(Data_sets[0][1], Data_sets[0][3])\\n\\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint\\nepochs_to_wait_for_improve = 30\\nearly_stopping_callback = EarlyStopping(monitor='val_loss', patience=epochs_to_wait_for_improve)\\ncheckpoint_callback = ModelCheckpoint(weights_path + 'BestKerasResnet50_flat_3_loss.h5', monitor='val_loss',\\n                                      verbose=1, save_best_only=True, mode='min')\\n#fit the model\\nmodel.fit_generator(gen_flow_train, validation_data=(Data_sets[0][1], Data_sets[0][3]),\\n                    steps_per_epoch=int(np.ceil(len(X_train)/batch_size)),\\n                    epochs=500, verbose=1, callbacks=[early_stopping_callback, checkpoint_callback],\\n                    class_weight = class_weight_or)\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/sara_rabhi/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.pyc\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2115\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2116\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2117\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2118\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<decorator-gen-60>\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n",
      "\u001b[0;32m/home/sara_rabhi/anaconda2/lib/python2.7/site-packages/IPython/core/magic.pyc\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/sara_rabhi/anaconda2/lib/python2.7/site-packages/IPython/core/magics/execution.pyc\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1183\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1184\u001b[0m             \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1185\u001b[0;31m             \u001b[0;32mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1186\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1187\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/home/sara_rabhi/anaconda2/lib/python2.7/site-packages/keras/legacy/interfaces.pyc\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     86\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/sara_rabhi/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2142\u001b[0m                                 \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2143\u001b[0m                                 \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_sample_weights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2144\u001b[0;31m                                 verbose=0)\n\u001b[0m\u001b[1;32m   2145\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2146\u001b[0m                             \u001b[0mval_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mval_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/sara_rabhi/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps)\u001b[0m\n\u001b[1;32m   1725\u001b[0m                                \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1726\u001b[0m                                \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1727\u001b[0;31m                                steps=steps)\n\u001b[0m\u001b[1;32m   1728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1729\u001b[0m     def predict(self, x,\n",
      "\u001b[0;32m/home/sara_rabhi/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_test_loop\u001b[0;34m(self, f, ins, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1368\u001b[0m                     \u001b[0mins_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_slice_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1370\u001b[0;31m                 \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1371\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1372\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/sara_rabhi/anaconda2/lib/python2.7/site-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2350\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2351\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2352\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2353\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2354\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/sara_rabhi/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/sara_rabhi/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/sara_rabhi/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/sara_rabhi/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/sara_rabhi/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Lets define the image transormations that we wan\n",
    "\n",
    "gen = ImageDataGenerator(horizontal_flip=True,\n",
    "                         vertical_flip=True,\n",
    "                         width_shift_range=0.2,\n",
    "                         height_shift_range=0.2,\n",
    "                         zoom_range=0.2,\n",
    "                         rotation_range=40)\n",
    "\n",
    "val_datagen = ImageDataGenerator()\n",
    "# Here is the function that merges our two generators\n",
    "# We use the exact same generator with the same random seed for both the y and angle arrays\n",
    "def gen_flow_for_one_input(X1, y):\n",
    "    genX1 = gen.flow(X1, y, batch_size=batch_size, seed=42)\n",
    "    while True:\n",
    "        X1i = genX1.next()\n",
    "        yield X1i[0], X1i[1]\n",
    "\n",
    "def val_datagen_(X1, y):\n",
    "    genX1 = val_datagen.flow(X1, y, batch_size=batch_size, seed=42)\n",
    "    while True:\n",
    "        X1i = genX1.next()\n",
    "        yield X1i[0], X1i[1]\n",
    "#Finally create out generator\n",
    "gen_flow_train = gen_flow_for_one_input(X_train, Y_train)\n",
    "#gen_flow_val = gen_flow_for_one_input(X_valid, Y_valid)\n",
    "gen_flow_val = val_datagen_(Data_sets[0][1], Data_sets[0][3])\n",
    "\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "epochs_to_wait_for_improve = 30\n",
    "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=epochs_to_wait_for_improve)\n",
    "checkpoint_callback = ModelCheckpoint(weights_path + 'BestKerasResnet50_flat_3_loss.h5', monitor='val_loss',\n",
    "                                      verbose=1, save_best_only=True, mode='min')\n",
    "#fit the model\n",
    "model.fit_generator(gen_flow_train, validation_data=(Data_sets[0][1], Data_sets[0][3]),\n",
    "                    steps_per_epoch=int(np.ceil(len(X_train)/batch_size)),\n",
    "                    epochs=500, verbose=1, callbacks=[early_stopping_callback, checkpoint_callback],\n",
    "                    class_weight = class_weight_or)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
