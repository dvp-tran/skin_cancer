{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Â Skin Cancer Classification Challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Summary : ** skin cancer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminaries and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#general & system\\n\",\n",
    "import os\n",
    "\n",
    "#data processing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.rcParams['figure.figsize'] = 10, 10  #default setting\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "#data augmentation\n",
    "from PIL import Image\n",
    "from random import choice\n",
    "import cv2\n",
    "import numpy as np\n",
    "#import keras.preprocessing.image as prep\n",
    "\n",
    "#ML part\n",
    "from keras.applications import VGG16\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.preprocessing import image as kimage\n",
    "from keras.models import Sequential\n",
    "from keras.layers import GlobalMaxPooling2D, Dense, BatchNormalization, GlobalAveragePooling2D, Dropout,Activation,Flatten\n",
    "from keras.models import Model\n",
    "from keras.optimizers import SGD\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "#validation\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Rq : ** Datasets are quite light, can be fully loaded in a laptop memory with ease."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4 ms, sys: 0 ns, total: 4 ms\n",
      "Wall time: 3.34 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "meta = pd.read_csv(\"data/metadata.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 688 ms, sys: 36 ms, total: 724 ms\n",
      "Wall time: 722 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "filelist = os.listdir(\"data/resized/\")\n",
    "X_train = np.array([np.array(Image.open(\"data/resized/\"+fname)) for fname in filelist])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(617, 224, 224, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get target\n",
    "filelist = [x.replace(\".jpg\",\"\") for x in filelist]\n",
    "Y_train = [meta[meta[\"name\"]==x][\"meta_clinical_benign_malignant\"].values[0] for x in filelist]\n",
    "Y_train = [1 if x==\"malignant\" else 0 for x in Y_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ISIC_0000256', 'ISIC_0000282', 'ISIC_0000153', 'ISIC_0000225', 'ISIC_0001150']\n",
      "[0, 1, 1, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "#control\n",
    "print(filelist[0:5])\n",
    "print(Y_train[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#data splitting\n",
    "X_train, X_valid, Y_train, Y_valid = train_test_split(X_train, Y_train, random_state=42, train_size=0.80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III. Deep Learning with Transfer Learning"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# generator from folder\n",
    "batch_size = 16\n",
    "\n",
    "# prepare data augmentation configuration\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        target_size=(img_height, img_width),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        validation_data_dir,\n",
    "        target_size=(img_height, img_width),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary')\n",
    "\n",
    "# fine-tune the model\n",
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=nb_train_samples // batch_size,\n",
    "        epochs=epochs,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=nb_validation_samples // batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weights_path = 'model/checkpoints/'\n",
    "\n",
    "if not os.path.exists(weights_path):\n",
    "    os.makedirs(weights_path)\n",
    "    \n",
    "epochs = 500\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Using VGG16 : **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#load base model\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224,224,3))\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "sequential_1 (Sequential)    (None, 1)                 26216449  \n",
      "=================================================================\n",
      "Total params: 40,931,137\n",
      "Trainable params: 40,931,137\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#adding top layers\n",
    "    #sequentialy\n",
    "add_model = Sequential()\n",
    "add_model.add(Flatten(input_shape=base_model.output_shape[1:])) #Flatten/GlobalAveragePooling2D\n",
    "add_model.add(Dense(1024, activation='relu'))\n",
    "add_model.add(Dropout(0.25))\n",
    "add_model.add(Dense(512, activation='relu'))\n",
    "add_model.add(Dropout(0.25))\n",
    "add_model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=add_model(base_model.output))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#adding top layers\n",
    "    #need to check api to add layers sequentialy\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x) #Flatten instead?\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "x = Dropout(0.25)(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = Dropout(0.25)(x)\n",
    "predictions = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#freeze lower layers of the model\n",
    "#for layer in model.layers[:]:\n",
    "    #layer.trainable = False\n",
    "for layer in model.layers[0:]:\n",
    "    layer.trainable = True\n",
    "    \n",
    "#compile\n",
    "#model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.compile(optimizer=SGD(lr=0.0001, momentum=0.9), loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "29/30 [============================>.] - ETA: 1s - loss: 1.1987 - acc: 0.6121Epoch 00001: val_loss improved from inf to 0.66516, saving model to model/checkpoints/BestKerasModelVGG16_flat.h5\n",
      "30/30 [==============================] - 38s 1s/step - loss: 1.1799 - acc: 0.6167 - val_loss: 0.6652 - val_acc: 0.6129\n",
      "Epoch 2/500\n",
      "29/30 [============================>.] - ETA: 1s - loss: 0.6434 - acc: 0.7037Epoch 00002: val_loss did not improve\n",
      "30/30 [==============================] - 35s 1s/step - loss: 0.6466 - acc: 0.6990 - val_loss: 0.6697 - val_acc: 0.6129\n",
      "Epoch 3/500\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.6212 - acc: 0.6860Epoch 00003: val_loss did not improve\n",
      "30/30 [==============================] - 31s 1s/step - loss: 0.6351 - acc: 0.6756 - val_loss: 0.6753 - val_acc: 0.6129\n",
      "Epoch 4/500\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.6087 - acc: 0.6903Epoch 00004: val_loss did not improve\n",
      "30/30 [==============================] - 31s 1s/step - loss: 0.6060 - acc: 0.6944 - val_loss: 0.6788 - val_acc: 0.6129\n",
      "Epoch 5/500\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.5946 - acc: 0.7028Epoch 00005: val_loss did not improve\n",
      "30/30 [==============================] - 31s 1s/step - loss: 0.5921 - acc: 0.7127 - val_loss: 0.6764 - val_acc: 0.6129\n",
      "Epoch 6/500\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.6210 - acc: 0.6824Epoch 00006: val_loss did not improve\n",
      "30/30 [==============================] - 31s 1s/step - loss: 0.6269 - acc: 0.6742 - val_loss: 0.6700 - val_acc: 0.6129\n",
      "Epoch 7/500\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.6103 - acc: 0.7006Epoch 00007: val_loss did not improve\n",
      "30/30 [==============================] - 31s 1s/step - loss: 0.6087 - acc: 0.6981 - val_loss: 0.6701 - val_acc: 0.6129\n",
      "Epoch 8/500\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.6026 - acc: 0.6862Epoch 00008: val_loss did not improve\n",
      "30/30 [==============================] - 32s 1s/step - loss: 0.6003 - acc: 0.6883 - val_loss: 0.6886 - val_acc: 0.6129\n",
      "Epoch 9/500\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.6171 - acc: 0.6931Epoch 00009: val_loss did not improve\n",
      "30/30 [==============================] - 31s 1s/step - loss: 0.6200 - acc: 0.6930 - val_loss: 0.7051 - val_acc: 0.6129\n",
      "Epoch 10/500\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.6198 - acc: 0.6721Epoch 00010: val_loss did not improve\n",
      "30/30 [==============================] - 31s 1s/step - loss: 0.6219 - acc: 0.6684 - val_loss: 0.6998 - val_acc: 0.6129\n",
      "Epoch 11/500\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.5910 - acc: 0.7032Epoch 00011: val_loss improved from 0.66516 to 0.64875, saving model to model/checkpoints/BestKerasModelVGG16_flat.h5\n",
      "30/30 [==============================] - 32s 1s/step - loss: 0.5859 - acc: 0.7090 - val_loss: 0.6488 - val_acc: 0.6129\n",
      "Epoch 12/500\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.5949 - acc: 0.6968Epoch 00012: val_loss improved from 0.64875 to 0.64344, saving model to model/checkpoints/BestKerasModelVGG16_flat.h5\n",
      "30/30 [==============================] - 32s 1s/step - loss: 0.5948 - acc: 0.6965 - val_loss: 0.6434 - val_acc: 0.6129\n",
      "Epoch 13/500\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.6312 - acc: 0.6925Epoch 00013: val_loss improved from 0.64344 to 0.64201, saving model to model/checkpoints/BestKerasModelVGG16_flat.h5\n",
      "30/30 [==============================] - 33s 1s/step - loss: 0.6305 - acc: 0.6985 - val_loss: 0.6420 - val_acc: 0.6129\n",
      "Epoch 14/500\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.6186 - acc: 0.6935Epoch 00014: val_loss did not improve\n",
      "30/30 [==============================] - 32s 1s/step - loss: 0.6188 - acc: 0.6953 - val_loss: 0.8139 - val_acc: 0.6129\n",
      "Epoch 15/500\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.5652 - acc: 0.7270Epoch 00015: val_loss did not improve\n",
      "30/30 [==============================] - 31s 1s/step - loss: 0.5715 - acc: 0.7215 - val_loss: 0.6735 - val_acc: 0.6129\n",
      "Epoch 16/500\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.5920 - acc: 0.6870Epoch 00016: val_loss did not improve\n",
      "30/30 [==============================] - 31s 1s/step - loss: 0.5872 - acc: 0.6932 - val_loss: 0.6698 - val_acc: 0.6129\n",
      "Epoch 17/500\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.5891 - acc: 0.7092Epoch 00017: val_loss did not improve\n",
      "30/30 [==============================] - 32s 1s/step - loss: 0.5916 - acc: 0.7064 - val_loss: 0.7635 - val_acc: 0.6129\n",
      "Epoch 18/500\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.5463 - acc: 0.7341Epoch 00018: val_loss did not improve\n",
      "30/30 [==============================] - 31s 1s/step - loss: 0.5462 - acc: 0.7326 - val_loss: 0.8358 - val_acc: 0.6129\n",
      "Epoch 19/500\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.6451 - acc: 0.6366Epoch 00019: val_loss did not improve\n",
      "30/30 [==============================] - 31s 1s/step - loss: 0.6576 - acc: 0.6279 - val_loss: 0.8941 - val_acc: 0.6129\n",
      "Epoch 20/500\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.6015 - acc: 0.7071Epoch 00020: val_loss did not improve\n",
      "30/30 [==============================] - 31s 1s/step - loss: 0.6024 - acc: 0.7043 - val_loss: 0.6573 - val_acc: 0.6129\n",
      "Epoch 21/500\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.6181 - acc: 0.7086Epoch 00021: val_loss did not improve\n",
      "30/30 [==============================] - 31s 1s/step - loss: 0.6181 - acc: 0.7036 - val_loss: 0.6768 - val_acc: 0.6129\n",
      "Epoch 22/500\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.5489 - acc: 0.7112Epoch 00022: val_loss did not improve\n",
      "30/30 [==============================] - 31s 1s/step - loss: 0.5553 - acc: 0.7083 - val_loss: 0.6667 - val_acc: 0.6129\n",
      "Epoch 23/500\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.5454 - acc: 0.7276Epoch 00023: val_loss did not improve\n",
      "30/30 [==============================] - 31s 1s/step - loss: 0.5458 - acc: 0.7242 - val_loss: 0.7082 - val_acc: 0.6129\n",
      "Epoch 24/500\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.6031 - acc: 0.6742Epoch 00024: val_loss did not improve\n",
      "30/30 [==============================] - 32s 1s/step - loss: 0.6074 - acc: 0.6726 - val_loss: 0.6635 - val_acc: 0.6129\n",
      "Epoch 25/500\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.5800 - acc: 0.7037Epoch 00025: val_loss did not improve\n",
      "30/30 [==============================] - 32s 1s/step - loss: 0.5795 - acc: 0.7011 - val_loss: 0.6423 - val_acc: 0.6129\n",
      "Epoch 26/500\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.5571 - acc: 0.7243Epoch 00026: val_loss improved from 0.64201 to 0.63650, saving model to model/checkpoints/BestKerasModelVGG16_flat.h5\n",
      "30/30 [==============================] - 32s 1s/step - loss: 0.5507 - acc: 0.7293 - val_loss: 0.6365 - val_acc: 0.6129\n",
      "Epoch 27/500\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.5937 - acc: 0.6762Epoch 00027: val_loss improved from 0.63650 to 0.63176, saving model to model/checkpoints/BestKerasModelVGG16_flat.h5\n",
      "30/30 [==============================] - 30s 994ms/step - loss: 0.5939 - acc: 0.6766 - val_loss: 0.6318 - val_acc: 0.6290\n",
      "Epoch 28/500\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.5585 - acc: 0.6994Epoch 00028: val_loss did not improve\n",
      "30/30 [==============================] - 29s 950ms/step - loss: 0.5586 - acc: 0.6969 - val_loss: 0.6374 - val_acc: 0.6371\n",
      "Epoch 29/500\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.5612 - acc: 0.7323Epoch 00029: val_loss improved from 0.63176 to 0.63116, saving model to model/checkpoints/BestKerasModelVGG16_flat.h5\n",
      "30/30 [==============================] - 29s 970ms/step - loss: 0.5565 - acc: 0.7349 - val_loss: 0.6312 - val_acc: 0.6371\n",
      "Epoch 30/500\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.5552 - acc: 0.7167Epoch 00030: val_loss did not improve\n",
      "30/30 [==============================] - 29s 960ms/step - loss: 0.5488 - acc: 0.7219 - val_loss: 0.6819 - val_acc: 0.6210\n",
      "Epoch 31/500\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.5611 - acc: 0.7134Epoch 00031: val_loss improved from 0.63116 to 0.63025, saving model to model/checkpoints/BestKerasModelVGG16_flat.h5\n",
      "30/30 [==============================] - 30s 1s/step - loss: 0.5599 - acc: 0.7127 - val_loss: 0.6302 - val_acc: 0.6290\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/500\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.5668 - acc: 0.7112Epoch 00032: val_loss improved from 0.63025 to 0.62570, saving model to model/checkpoints/BestKerasModelVGG16_flat.h5\n",
      "30/30 [==============================] - 29s 972ms/step - loss: 0.5662 - acc: 0.7125 - val_loss: 0.6257 - val_acc: 0.6290\n",
      "Epoch 33/500\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.5473 - acc: 0.7226Epoch 00033: val_loss did not improve\n",
      "30/30 [==============================] - 28s 948ms/step - loss: 0.5377 - acc: 0.7298 - val_loss: 0.6307 - val_acc: 0.6452\n",
      "Epoch 34/500\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.5557 - acc: 0.7049Epoch 00034: val_loss did not improve\n",
      "30/30 [==============================] - 28s 950ms/step - loss: 0.5493 - acc: 0.7147 - val_loss: 0.6342 - val_acc: 0.6452\n",
      "Epoch 35/500\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.5325 - acc: 0.7394Epoch 00035: val_loss improved from 0.62570 to 0.61162, saving model to model/checkpoints/BestKerasModelVGG16_flat.h5\n",
      "30/30 [==============================] - 29s 967ms/step - loss: 0.5346 - acc: 0.7377 - val_loss: 0.6116 - val_acc: 0.6452\n",
      "Epoch 36/500\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.5667 - acc: 0.7454Epoch 00036: val_loss did not improve\n",
      "30/30 [==============================] - 28s 949ms/step - loss: 0.5647 - acc: 0.7476 - val_loss: 0.6144 - val_acc: 0.6855\n",
      "Epoch 37/500\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.5462 - acc: 0.7296Epoch 00037: val_loss did not improve\n",
      "30/30 [==============================] - 29s 953ms/step - loss: 0.5447 - acc: 0.7344 - val_loss: 0.6181 - val_acc: 0.6855\n",
      "Epoch 38/500\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.5711 - acc: 0.7221Epoch 00038: val_loss improved from 0.61162 to 0.59838, saving model to model/checkpoints/BestKerasModelVGG16_flat.h5\n",
      "30/30 [==============================] - 29s 969ms/step - loss: 0.5736 - acc: 0.7189 - val_loss: 0.5984 - val_acc: 0.6452\n",
      "Epoch 39/500\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.5334 - acc: 0.7495Epoch 00039: val_loss did not improve\n",
      "30/30 [==============================] - 29s 953ms/step - loss: 0.5319 - acc: 0.7474 - val_loss: 0.6014 - val_acc: 0.6532\n",
      "Epoch 40/500\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.5190 - acc: 0.7619Epoch 00040: val_loss did not improve\n",
      "30/30 [==============================] - 29s 952ms/step - loss: 0.5195 - acc: 0.7594 - val_loss: 0.6039 - val_acc: 0.6855\n",
      "Epoch 41/500\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.5419 - acc: 0.7366Epoch 00041: val_loss did not improve\n",
      "30/30 [==============================] - 28s 949ms/step - loss: 0.5383 - acc: 0.7391 - val_loss: 0.6265 - val_acc: 0.6532\n",
      "Epoch 42/500\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.5278 - acc: 0.7540Epoch 00042: val_loss improved from 0.59838 to 0.59136, saving model to model/checkpoints/BestKerasModelVGG16_flat.h5\n",
      "30/30 [==============================] - 29s 969ms/step - loss: 0.5313 - acc: 0.7518 - val_loss: 0.5914 - val_acc: 0.6613\n",
      "Epoch 43/500\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.5204 - acc: 0.7679Epoch 00043: val_loss improved from 0.59136 to 0.57120, saving model to model/checkpoints/BestKerasModelVGG16_flat.h5\n",
      "30/30 [==============================] - 29s 970ms/step - loss: 0.5242 - acc: 0.7652 - val_loss: 0.5712 - val_acc: 0.7258\n",
      "Epoch 44/500\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.5376 - acc: 0.7593Epoch 00044: val_loss did not improve\n",
      "30/30 [==============================] - 28s 949ms/step - loss: 0.5358 - acc: 0.7652 - val_loss: 0.5728 - val_acc: 0.7016\n",
      "Epoch 45/500\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.5433 - acc: 0.7384Epoch 00045: val_loss did not improve\n",
      "30/30 [==============================] - 29s 957ms/step - loss: 0.5420 - acc: 0.7388 - val_loss: 0.5831 - val_acc: 0.7016\n",
      "Epoch 46/500\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.5091 - acc: 0.7712Epoch 00046: val_loss improved from 0.57120 to 0.56126, saving model to model/checkpoints/BestKerasModelVGG16_flat.h5\n",
      "30/30 [==============================] - 29s 968ms/step - loss: 0.5148 - acc: 0.7664 - val_loss: 0.5613 - val_acc: 0.7177\n",
      "Epoch 47/500\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.5955 - acc: 0.6807Epoch 00047: val_loss did not improve\n",
      "30/30 [==============================] - 28s 947ms/step - loss: 0.5954 - acc: 0.6789 - val_loss: 0.5878 - val_acc: 0.7258\n",
      "Epoch 48/500\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.5149 - acc: 0.7550Epoch 00048: val_loss did not improve\n",
      "30/30 [==============================] - 28s 947ms/step - loss: 0.5120 - acc: 0.7548 - val_loss: 0.6209 - val_acc: 0.6452\n",
      "Epoch 49/500\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.5704 - acc: 0.7329Epoch 00049: val_loss did not improve\n",
      "30/30 [==============================] - 29s 952ms/step - loss: 0.5763 - acc: 0.7314 - val_loss: 0.5803 - val_acc: 0.7177\n",
      "Epoch 50/500\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.5248 - acc: 0.7581Epoch 00050: val_loss improved from 0.56126 to 0.56120, saving model to model/checkpoints/BestKerasModelVGG16_flat.h5\n",
      "30/30 [==============================] - 29s 966ms/step - loss: 0.5245 - acc: 0.7599 - val_loss: 0.5612 - val_acc: 0.7097\n",
      "Epoch 51/500\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.5172 - acc: 0.7614Epoch 00051: val_loss did not improve\n",
      "30/30 [==============================] - 28s 945ms/step - loss: 0.5136 - acc: 0.7631 - val_loss: 0.5706 - val_acc: 0.6935\n",
      "Epoch 52/500\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.5116 - acc: 0.7787Epoch 00052: val_loss improved from 0.56120 to 0.55429, saving model to model/checkpoints/BestKerasModelVGG16_flat.h5\n",
      "30/30 [==============================] - 29s 966ms/step - loss: 0.5120 - acc: 0.7756 - val_loss: 0.5543 - val_acc: 0.7097\n",
      "Epoch 53/500\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.4974 - acc: 0.7691Epoch 00053: val_loss improved from 0.55429 to 0.54010, saving model to model/checkpoints/BestKerasModelVGG16_flat.h5\n",
      "30/30 [==============================] - 29s 966ms/step - loss: 0.4977 - acc: 0.7664 - val_loss: 0.5401 - val_acc: 0.7742\n",
      "Epoch 54/500\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.5129 - acc: 0.7648Epoch 00054: val_loss did not improve\n",
      "30/30 [==============================] - 28s 949ms/step - loss: 0.5076 - acc: 0.7685 - val_loss: 0.5420 - val_acc: 0.7339\n",
      "Epoch 55/500\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.4830 - acc: 0.7802Epoch 00055: val_loss did not improve\n",
      "30/30 [==============================] - 28s 945ms/step - loss: 0.4832 - acc: 0.7854 - val_loss: 0.5847 - val_acc: 0.7258\n",
      "Epoch 56/500\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.5103 - acc: 0.7792Epoch 00056: val_loss improved from 0.54010 to 0.52866, saving model to model/checkpoints/BestKerasModelVGG16_flat.h5\n",
      "30/30 [==============================] - 29s 972ms/step - loss: 0.5127 - acc: 0.7782 - val_loss: 0.5287 - val_acc: 0.6935\n",
      "Epoch 57/500\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.5055 - acc: 0.7717Epoch 00057: val_loss improved from 0.52866 to 0.51912, saving model to model/checkpoints/BestKerasModelVGG16_flat.h5\n",
      "30/30 [==============================] - 29s 967ms/step - loss: 0.5029 - acc: 0.7731 - val_loss: 0.5191 - val_acc: 0.7419\n",
      "Epoch 58/500\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.4583 - acc: 0.7969Epoch 00058: val_loss did not improve\n",
      "30/30 [==============================] - 28s 946ms/step - loss: 0.4571 - acc: 0.7953 - val_loss: 0.7069 - val_acc: 0.6935\n",
      "Epoch 59/500\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.5019 - acc: 0.8014Epoch 00059: val_loss improved from 0.51912 to 0.50652, saving model to model/checkpoints/BestKerasModelVGG16_flat.h5\n",
      "30/30 [==============================] - 29s 964ms/step - loss: 0.5045 - acc: 0.7997 - val_loss: 0.5065 - val_acc: 0.7177\n",
      "Epoch 60/500\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.4560 - acc: 0.8045Epoch 00060: val_loss improved from 0.50652 to 0.48660, saving model to model/checkpoints/BestKerasModelVGG16_flat.h5\n",
      "30/30 [==============================] - 29s 967ms/step - loss: 0.4510 - acc: 0.8069 - val_loss: 0.4866 - val_acc: 0.7661\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/500\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.4699 - acc: 0.7992Epoch 00061: val_loss did not improve\n",
      "30/30 [==============================] - 29s 957ms/step - loss: 0.4678 - acc: 0.7997 - val_loss: 0.4920 - val_acc: 0.7339\n",
      "Epoch 62/500\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.4805 - acc: 0.8082Epoch 00062: val_loss improved from 0.48660 to 0.48126, saving model to model/checkpoints/BestKerasModelVGG16_flat.h5\n",
      "30/30 [==============================] - 29s 975ms/step - loss: 0.4792 - acc: 0.8094 - val_loss: 0.4813 - val_acc: 0.7581\n",
      "Epoch 63/500\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.4916 - acc: 0.7672Epoch 00063: val_loss did not improve\n",
      "30/30 [==============================] - 29s 953ms/step - loss: 0.4927 - acc: 0.7688 - val_loss: 0.5843 - val_acc: 0.6613\n",
      "Epoch 64/500\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.4954 - acc: 0.7717Epoch 00064: val_loss did not improve\n",
      "30/30 [==============================] - 28s 948ms/step - loss: 0.4990 - acc: 0.7710 - val_loss: 0.5485 - val_acc: 0.7258\n",
      "Epoch 65/500\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.4731 - acc: 0.7825Epoch 00065: val_loss did not improve\n",
      "30/30 [==============================] - 29s 958ms/step - loss: 0.4700 - acc: 0.7835 - val_loss: 0.4845 - val_acc: 0.7581\n",
      "Epoch 66/500\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.4522 - acc: 0.7825Epoch 00066: val_loss did not improve\n",
      "30/30 [==============================] - 28s 949ms/step - loss: 0.4647 - acc: 0.7773 - val_loss: 0.4958 - val_acc: 0.7661\n",
      "Epoch 67/500\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.4826 - acc: 0.7787Epoch 00067: val_loss did not improve\n",
      "30/30 [==============================] - 28s 945ms/step - loss: 0.4869 - acc: 0.7756 - val_loss: 0.6298 - val_acc: 0.7177\n",
      "Epoch 68/500\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.4578 - acc: 0.7969Epoch 00068: val_loss did not improve\n",
      "30/30 [==============================] - 29s 962ms/step - loss: 0.4554 - acc: 0.7995 - val_loss: 0.5090 - val_acc: 0.7581\n",
      "Epoch 69/500\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.4624 - acc: 0.7938Epoch 00069: val_loss did not improve\n",
      "30/30 [==============================] - 28s 949ms/step - loss: 0.4724 - acc: 0.7902 - val_loss: 0.5771 - val_acc: 0.7097\n",
      "Epoch 70/500\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.4381 - acc: 0.8089Epoch 00070: val_loss improved from 0.48126 to 0.44836, saving model to model/checkpoints/BestKerasModelVGG16_flat.h5\n",
      "30/30 [==============================] - 29s 968ms/step - loss: 0.4328 - acc: 0.8111 - val_loss: 0.4484 - val_acc: 0.7742\n",
      "Epoch 71/500\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.4283 - acc: 0.8213Epoch 00071: val_loss did not improve\n",
      "30/30 [==============================] - 28s 946ms/step - loss: 0.4233 - acc: 0.8252 - val_loss: 0.6499 - val_acc: 0.6935\n",
      "Epoch 72/500\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.4717 - acc: 0.7561Epoch 00072: val_loss did not improve\n",
      "30/30 [==============================] - 28s 949ms/step - loss: 0.4707 - acc: 0.7560 - val_loss: 0.4845 - val_acc: 0.7419\n",
      "Epoch 73/500\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.4431 - acc: 0.8034Epoch 00073: val_loss did not improve\n",
      "30/30 [==============================] - 29s 950ms/step - loss: 0.4418 - acc: 0.8037 - val_loss: 0.4596 - val_acc: 0.7742\n",
      "Epoch 74/500\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.4076 - acc: 0.8342Epoch 00074: val_loss did not improve\n",
      "30/30 [==============================] - 28s 948ms/step - loss: 0.4025 - acc: 0.8377 - val_loss: 0.4809 - val_acc: 0.7742\n",
      "Epoch 75/500\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.4514 - acc: 0.7966Epoch 00075: val_loss improved from 0.44836 to 0.44551, saving model to model/checkpoints/BestKerasModelVGG16_flat.h5\n",
      "30/30 [==============================] - 29s 968ms/step - loss: 0.4475 - acc: 0.7972 - val_loss: 0.4455 - val_acc: 0.7742\n",
      "Epoch 76/500\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.4228 - acc: 0.8098Epoch 00076: val_loss did not improve\n",
      "30/30 [==============================] - 28s 949ms/step - loss: 0.4291 - acc: 0.8099 - val_loss: 0.4549 - val_acc: 0.7903\n",
      "Epoch 77/500\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.3988 - acc: 0.8352Epoch 00077: val_loss did not improve\n",
      "30/30 [==============================] - 29s 951ms/step - loss: 0.3929 - acc: 0.8386 - val_loss: 0.4619 - val_acc: 0.7742\n",
      "Epoch 78/500\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.4391 - acc: 0.7906Epoch 00078: val_loss did not improve\n",
      "30/30 [==============================] - 29s 955ms/step - loss: 0.4398 - acc: 0.7914 - val_loss: 0.4746 - val_acc: 0.7742\n",
      "Epoch 79/500\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.4045 - acc: 0.8234Epoch 00079: val_loss improved from 0.44551 to 0.43574, saving model to model/checkpoints/BestKerasModelVGG16_flat.h5\n",
      "30/30 [==============================] - 29s 968ms/step - loss: 0.4018 - acc: 0.8252 - val_loss: 0.4357 - val_acc: 0.7903\n",
      "Epoch 80/500\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.4356 - acc: 0.8347Epoch 00080: val_loss did not improve\n",
      "30/30 [==============================] - 28s 946ms/step - loss: 0.4345 - acc: 0.8319 - val_loss: 0.5536 - val_acc: 0.7339\n",
      "Epoch 81/500\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.4028 - acc: 0.8331Epoch 00081: val_loss did not improve\n",
      "30/30 [==============================] - 29s 952ms/step - loss: 0.4039 - acc: 0.8303 - val_loss: 0.4422 - val_acc: 0.7903\n",
      "Epoch 82/500\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.3885 - acc: 0.8400Epoch 00082: val_loss did not improve\n",
      "30/30 [==============================] - 28s 941ms/step - loss: 0.3828 - acc: 0.8433 - val_loss: 0.4735 - val_acc: 0.7581\n",
      "Epoch 83/500\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.3813 - acc: 0.8369Epoch 00083: val_loss did not improve\n",
      "30/30 [==============================] - 28s 942ms/step - loss: 0.3881 - acc: 0.8298 - val_loss: 0.4775 - val_acc: 0.7823\n",
      "Epoch 84/500\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.3729 - acc: 0.8417Epoch 00084: val_loss did not improve\n",
      "30/30 [==============================] - 29s 962ms/step - loss: 0.3688 - acc: 0.8449 - val_loss: 0.4529 - val_acc: 0.7661\n",
      "Epoch 85/500\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.3850 - acc: 0.8374Epoch 00085: val_loss did not improve\n",
      "30/30 [==============================] - 28s 949ms/step - loss: 0.3836 - acc: 0.8386 - val_loss: 0.6655 - val_acc: 0.7258\n",
      "Epoch 86/500\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.4499 - acc: 0.7921Epoch 00086: val_loss did not improve\n",
      "30/30 [==============================] - 28s 945ms/step - loss: 0.4434 - acc: 0.7969 - val_loss: 0.7030 - val_acc: 0.6855\n",
      "Epoch 87/500\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.4046 - acc: 0.8282Epoch 00087: val_loss did not improve\n",
      "30/30 [==============================] - 28s 950ms/step - loss: 0.4177 - acc: 0.8173 - val_loss: 0.4898 - val_acc: 0.7419\n",
      "Epoch 88/500\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.4060 - acc: 0.8175Epoch 00088: val_loss did not improve\n",
      "30/30 [==============================] - 28s 946ms/step - loss: 0.4093 - acc: 0.8152 - val_loss: 0.5391 - val_acc: 0.7742\n",
      "Epoch 89/500\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.4045 - acc: 0.8110Epoch 00089: val_loss did not improve\n",
      "30/30 [==============================] - 28s 945ms/step - loss: 0.4081 - acc: 0.8090 - val_loss: 0.4784 - val_acc: 0.8065\n",
      "Epoch 90/500\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.3548 - acc: 0.8491Epoch 00090: val_loss did not improve\n",
      "30/30 [==============================] - 28s 947ms/step - loss: 0.3531 - acc: 0.8500 - val_loss: 0.4603 - val_acc: 0.8145\n",
      "Epoch 91/500\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.3728 - acc: 0.8266Epoch 00091: val_loss did not improve\n",
      "30/30 [==============================] - 29s 950ms/step - loss: 0.3768 - acc: 0.8220 - val_loss: 0.4627 - val_acc: 0.7661\n",
      "Epoch 92/500\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.3329 - acc: 0.8530Epoch 00092: val_loss did not improve\n",
      "30/30 [==============================] - 29s 951ms/step - loss: 0.3267 - acc: 0.8558 - val_loss: 0.5285 - val_acc: 0.7661\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 93/500\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.3520 - acc: 0.8707Epoch 00093: val_loss did not improve\n",
      "30/30 [==============================] - 29s 955ms/step - loss: 0.3557 - acc: 0.8699 - val_loss: 0.4812 - val_acc: 0.7500\n",
      "Epoch 94/500\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.4173 - acc: 0.8082Epoch 00094: val_loss did not improve\n",
      "30/30 [==============================] - 29s 954ms/step - loss: 0.4189 - acc: 0.8104 - val_loss: 0.4610 - val_acc: 0.7903\n",
      "Epoch 95/500\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.3240 - acc: 0.8858Epoch 00095: val_loss did not improve\n",
      "30/30 [==============================] - 29s 950ms/step - loss: 0.3284 - acc: 0.8771 - val_loss: 0.4765 - val_acc: 0.7581\n",
      "Epoch 96/500\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.3586 - acc: 0.8525Epoch 00096: val_loss did not improve\n",
      "30/30 [==============================] - 28s 950ms/step - loss: 0.3566 - acc: 0.8511 - val_loss: 0.4670 - val_acc: 0.7500\n",
      "Epoch 97/500\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.3490 - acc: 0.8525Epoch 00097: val_loss did not improve\n",
      "30/30 [==============================] - 28s 946ms/step - loss: 0.3423 - acc: 0.8553 - val_loss: 0.4571 - val_acc: 0.7742\n",
      "Epoch 98/500\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.3671 - acc: 0.8412Epoch 00098: val_loss did not improve\n",
      "30/30 [==============================] - 29s 956ms/step - loss: 0.3691 - acc: 0.8423 - val_loss: 0.5023 - val_acc: 0.7742\n",
      "Epoch 99/500\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.3336 - acc: 0.8632Epoch 00099: val_loss improved from 0.43574 to 0.42739, saving model to model/checkpoints/BestKerasModelVGG16_flat.h5\n",
      "30/30 [==============================] - 29s 967ms/step - loss: 0.3406 - acc: 0.8574 - val_loss: 0.4274 - val_acc: 0.7984\n",
      "Epoch 100/500\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.3269 - acc: 0.8665Epoch 00100: val_loss did not improve\n",
      "30/30 [==============================] - 28s 947ms/step - loss: 0.3251 - acc: 0.8689 - val_loss: 0.6464 - val_acc: 0.7339\n",
      "Epoch 101/500\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.3724 - acc: 0.8287Epoch 00101: val_loss did not improve\n",
      "30/30 [==============================] - 28s 943ms/step - loss: 0.3727 - acc: 0.8303 - val_loss: 0.4322 - val_acc: 0.8226\n",
      "Epoch 102/500\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.2927 - acc: 0.8826Epoch 00102: val_loss did not improve\n",
      "30/30 [==============================] - 29s 956ms/step - loss: 0.3049 - acc: 0.8782 - val_loss: 0.5263 - val_acc: 0.7661\n",
      "Epoch 103/500\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.3048 - acc: 0.8740Epoch 00103: val_loss did not improve\n",
      "30/30 [==============================] - 28s 942ms/step - loss: 0.3095 - acc: 0.8678 - val_loss: 0.6363 - val_acc: 0.7581\n",
      "Epoch 104/500\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.3467 - acc: 0.8476Epoch 00104: val_loss did not improve\n",
      "30/30 [==============================] - 29s 950ms/step - loss: 0.3397 - acc: 0.8507 - val_loss: 0.7716 - val_acc: 0.7177\n",
      "Epoch 105/500\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.3175 - acc: 0.8632Epoch 00105: val_loss did not improve\n",
      "30/30 [==============================] - 28s 945ms/step - loss: 0.3173 - acc: 0.8636 - val_loss: 0.4912 - val_acc: 0.7661\n",
      "Epoch 106/500\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.3044 - acc: 0.8714Epoch 00106: val_loss did not improve\n",
      "30/30 [==============================] - 29s 959ms/step - loss: 0.3070 - acc: 0.8673 - val_loss: 0.4741 - val_acc: 0.8145\n",
      "Epoch 107/500\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.2950 - acc: 0.8644Epoch 00107: val_loss did not improve\n",
      "30/30 [==============================] - 28s 946ms/step - loss: 0.2911 - acc: 0.8648 - val_loss: 0.8769 - val_acc: 0.6855\n",
      "Epoch 108/500\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.3426 - acc: 0.8632Epoch 00108: val_loss did not improve\n",
      "30/30 [==============================] - 29s 950ms/step - loss: 0.3496 - acc: 0.8595 - val_loss: 0.9828 - val_acc: 0.6613\n",
      "Epoch 109/500\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.3200 - acc: 0.8745Epoch 00109: val_loss did not improve\n",
      "30/30 [==============================] - 28s 949ms/step - loss: 0.3125 - acc: 0.8766 - val_loss: 0.6887 - val_acc: 0.7742\n",
      "Epoch 110/500\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.2785 - acc: 0.8750Epoch 00110: val_loss did not improve\n",
      "30/30 [==============================] - 28s 948ms/step - loss: 0.2738 - acc: 0.8791 - val_loss: 0.5883 - val_acc: 0.7581\n",
      "Epoch 111/500\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.2686 - acc: 0.8922Epoch 00111: val_loss did not improve\n",
      "30/30 [==============================] - 28s 940ms/step - loss: 0.2638 - acc: 0.8958 - val_loss: 0.6391 - val_acc: 0.7661\n",
      "Epoch 112/500\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.2398 - acc: 0.8934Epoch 00112: val_loss did not improve\n",
      "30/30 [==============================] - 28s 949ms/step - loss: 0.2372 - acc: 0.8949 - val_loss: 0.8186 - val_acc: 0.7339\n",
      "Epoch 113/500\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.2578 - acc: 0.8961Epoch 00113: val_loss did not improve\n",
      "30/30 [==============================] - 29s 953ms/step - loss: 0.2571 - acc: 0.8953 - val_loss: 0.9219 - val_acc: 0.7339\n",
      "Epoch 114/500\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.2403 - acc: 0.9095Epoch 00114: val_loss did not improve\n",
      "30/30 [==============================] - 28s 949ms/step - loss: 0.2549 - acc: 0.9041 - val_loss: 0.7136 - val_acc: 0.7581\n",
      "Epoch 115/500\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.2514 - acc: 0.9037Epoch 00115: val_loss did not improve\n",
      "30/30 [==============================] - 28s 945ms/step - loss: 0.2491 - acc: 0.9048 - val_loss: 0.6004 - val_acc: 0.7661\n",
      "Epoch 116/500\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.2352 - acc: 0.9090Epoch 00116: val_loss did not improve\n",
      "30/30 [==============================] - 28s 947ms/step - loss: 0.2375 - acc: 0.9099 - val_loss: 0.8112 - val_acc: 0.7258\n",
      "Epoch 117/500\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.2980 - acc: 0.8750Epoch 00117: val_loss did not improve\n",
      "30/30 [==============================] - 28s 949ms/step - loss: 0.3034 - acc: 0.8750 - val_loss: 0.6981 - val_acc: 0.6855\n",
      "Epoch 118/500\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.3731 - acc: 0.8438Epoch 00118: val_loss did not improve\n",
      "30/30 [==============================] - 29s 952ms/step - loss: 0.3682 - acc: 0.8470 - val_loss: 0.5974 - val_acc: 0.7258\n",
      "Epoch 119/500\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.3176 - acc: 0.8719Epoch 00119: val_loss did not improve\n",
      "30/30 [==============================] - 28s 945ms/step - loss: 0.3167 - acc: 0.8740 - val_loss: 0.5842 - val_acc: 0.7419\n",
      "Epoch 120/500\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.2414 - acc: 0.8999Epoch 00120: val_loss did not improve\n",
      "30/30 [==============================] - 29s 958ms/step - loss: 0.2446 - acc: 0.8990 - val_loss: 0.6042 - val_acc: 0.7742\n",
      "Epoch 121/500\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.2218 - acc: 0.9198Epoch 00121: val_loss did not improve\n",
      "30/30 [==============================] - 28s 943ms/step - loss: 0.2239 - acc: 0.9183 - val_loss: 0.6439 - val_acc: 0.7742\n",
      "Epoch 122/500\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.2094 - acc: 0.9133Epoch 00122: val_loss did not improve\n",
      "30/30 [==============================] - 28s 946ms/step - loss: 0.2070 - acc: 0.9162 - val_loss: 0.6870 - val_acc: 0.7419\n",
      "Epoch 123/500\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.2073 - acc: 0.9203Epoch 00123: val_loss did not improve\n",
      "30/30 [==============================] - 28s 946ms/step - loss: 0.2043 - acc: 0.9229 - val_loss: 0.6848 - val_acc: 0.7500\n",
      "Epoch 124/500\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.2872 - acc: 0.8944Epoch 00124: val_loss did not improve\n",
      "30/30 [==============================] - 29s 953ms/step - loss: 0.2909 - acc: 0.8902 - val_loss: 0.8235 - val_acc: 0.7339\n",
      "Epoch 125/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/30 [============================>.] - ETA: 0s - loss: 0.3009 - acc: 0.8621Epoch 00125: val_loss did not improve\n",
      "30/30 [==============================] - 29s 955ms/step - loss: 0.3042 - acc: 0.8583 - val_loss: 1.0667 - val_acc: 0.6694\n",
      "Epoch 126/500\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.2068 - acc: 0.9284Epoch 00126: val_loss did not improve\n",
      "30/30 [==============================] - 28s 946ms/step - loss: 0.2098 - acc: 0.9224 - val_loss: 0.5110 - val_acc: 0.7581\n",
      "Epoch 127/500\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.2410 - acc: 0.9047Epoch 00127: val_loss did not improve\n",
      "30/30 [==============================] - 29s 953ms/step - loss: 0.2414 - acc: 0.9037 - val_loss: 0.5985 - val_acc: 0.7823\n",
      "Epoch 128/500\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.2592 - acc: 0.8907Epoch 00128: val_loss did not improve\n",
      "30/30 [==============================] - 28s 944ms/step - loss: 0.2584 - acc: 0.8923 - val_loss: 0.5450 - val_acc: 0.7581\n",
      "Epoch 129/500\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.2567 - acc: 0.8956Epoch 00129: val_loss did not improve\n",
      "30/30 [==============================] - 28s 945ms/step - loss: 0.2620 - acc: 0.8928 - val_loss: 0.5268 - val_acc: 0.7581\n",
      "Epoch 130/500\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.2441 - acc: 0.9068Epoch 00130: val_loss did not improve\n",
      "30/30 [==============================] - 28s 950ms/step - loss: 0.2384 - acc: 0.9099 - val_loss: 0.6875 - val_acc: 0.7742\n",
      "Epoch 131/500\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.1937 - acc: 0.9203Epoch 00131: val_loss did not improve\n",
      "30/30 [==============================] - 29s 953ms/step - loss: 0.1896 - acc: 0.9208 - val_loss: 0.7285 - val_acc: 0.7419\n",
      "Epoch 132/500\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.1834 - acc: 0.9284Epoch 00132: val_loss did not improve\n",
      "30/30 [==============================] - 28s 949ms/step - loss: 0.1792 - acc: 0.9308 - val_loss: 1.0213 - val_acc: 0.7097\n",
      "Epoch 133/500\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.2123 - acc: 0.9090Epoch 00133: val_loss did not improve\n",
      "30/30 [==============================] - 28s 945ms/step - loss: 0.2115 - acc: 0.9078 - val_loss: 1.1281 - val_acc: 0.6935\n",
      "Epoch 134/500\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.1989 - acc: 0.9198Epoch 00134: val_loss did not improve\n",
      "30/30 [==============================] - 28s 946ms/step - loss: 0.1931 - acc: 0.9224 - val_loss: 1.1835 - val_acc: 0.7016\n",
      "Epoch 135/500\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.2685 - acc: 0.8848Epoch 00135: val_loss did not improve\n",
      "30/30 [==============================] - 28s 946ms/step - loss: 0.2633 - acc: 0.8865 - val_loss: 0.7149 - val_acc: 0.7742\n",
      "Epoch 136/500\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.1658 - acc: 0.9392Epoch 00136: val_loss did not improve\n",
      "30/30 [==============================] - 29s 959ms/step - loss: 0.1711 - acc: 0.9370 - val_loss: 0.6622 - val_acc: 0.7823\n",
      "Epoch 137/500\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.1518 - acc: 0.9413Epoch 00137: val_loss did not improve\n",
      "30/30 [==============================] - 29s 962ms/step - loss: 0.1486 - acc: 0.9433 - val_loss: 1.0077 - val_acc: 0.7419\n",
      "Epoch 138/500\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.1712 - acc: 0.9353Epoch 00138: val_loss did not improve\n",
      "30/30 [==============================] - 29s 962ms/step - loss: 0.1685 - acc: 0.9354 - val_loss: 0.9014 - val_acc: 0.7339\n",
      "Epoch 139/500\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.1674 - acc: 0.9327Epoch 00139: val_loss did not improve\n",
      "30/30 [==============================] - 28s 947ms/step - loss: 0.1644 - acc: 0.9349 - val_loss: 0.8297 - val_acc: 0.7419\n",
      "Epoch 140/500\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.1546 - acc: 0.9418Epoch 00140: val_loss did not improve\n",
      "30/30 [==============================] - 28s 944ms/step - loss: 0.1503 - acc: 0.9437 - val_loss: 1.0221 - val_acc: 0.7258\n",
      "Epoch 141/500\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.1409 - acc: 0.9483Epoch 00141: val_loss did not improve\n",
      "30/30 [==============================] - 28s 949ms/step - loss: 0.1450 - acc: 0.9458 - val_loss: 1.0590 - val_acc: 0.7339\n",
      "Epoch 142/500\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.1400 - acc: 0.9526Epoch 00142: val_loss did not improve\n",
      "30/30 [==============================] - 28s 943ms/step - loss: 0.1371 - acc: 0.9542 - val_loss: 0.7744 - val_acc: 0.7500\n",
      "Epoch 143/500\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.1658 - acc: 0.9327Epoch 00143: val_loss did not improve\n",
      "30/30 [==============================] - 28s 939ms/step - loss: 0.1607 - acc: 0.9349 - val_loss: 0.7742 - val_acc: 0.7742\n",
      "Epoch 144/500\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.1868 - acc: 0.9353Epoch 00144: val_loss did not improve\n",
      "30/30 [==============================] - 29s 954ms/step - loss: 0.1808 - acc: 0.9375 - val_loss: 0.8940 - val_acc: 0.7500\n",
      "Epoch 145/500\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.1278 - acc: 0.9564Epoch 00145: val_loss did not improve\n",
      "30/30 [==============================] - 28s 944ms/step - loss: 0.1272 - acc: 0.9558 - val_loss: 0.8358 - val_acc: 0.7661\n",
      "Epoch 146/500\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.1645 - acc: 0.9418Epoch 00146: val_loss did not improve\n",
      "30/30 [==============================] - 28s 947ms/step - loss: 0.1762 - acc: 0.9375 - val_loss: 0.7681 - val_acc: 0.7742\n",
      "Epoch 147/500\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.1276 - acc: 0.9440Epoch 00147: val_loss did not improve\n",
      "30/30 [==============================] - 28s 949ms/step - loss: 0.1250 - acc: 0.9458 - val_loss: 0.9777 - val_acc: 0.7500\n",
      "Epoch 148/500\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.1440 - acc: 0.9353Epoch 00148: val_loss did not improve\n",
      "30/30 [==============================] - 28s 943ms/step - loss: 0.1415 - acc: 0.9375 - val_loss: 1.7363 - val_acc: 0.7097\n",
      "Epoch 149/500\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.1548 - acc: 0.9418Epoch 00149: val_loss did not improve\n",
      "30/30 [==============================] - 28s 948ms/step - loss: 0.1517 - acc: 0.9437 - val_loss: 1.0647 - val_acc: 0.7500\n",
      "CPU times: user 47min 49s, sys: 8min 23s, total: 56min 13s\n",
      "Wall time: 1h 12min 24s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Lets define the image transormations that we wan\n",
    "\n",
    "gen = ImageDataGenerator(horizontal_flip=True,\n",
    "                         vertical_flip=True,\n",
    "                         width_shift_range=0.2,\n",
    "                         height_shift_range=0.2,\n",
    "                         zoom_range=0.2,\n",
    "                         rotation_range=40)\n",
    "\n",
    "# Here is the function that merges our two generators\n",
    "# We use the exact same generator with the same random seed for both the y and angle arrays\n",
    "def gen_flow_for_one_input(X1, y):\n",
    "    genX1 = gen.flow(X1, y, batch_size=batch_size, seed=42)\n",
    "    while True:\n",
    "        X1i = genX1.next()\n",
    "        yield X1i[0], X1i[1]\n",
    "\n",
    "#Finally create out generator\n",
    "gen_flow = gen_flow_for_one_input(X_train, Y_train)\n",
    "\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "epochs_to_wait_for_improve = 50\n",
    "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=epochs_to_wait_for_improve)\n",
    "checkpoint_callback = ModelCheckpoint(weights_path + 'BestKerasModelVGG16_flat.h5', monitor='val_loss',\n",
    "                                      verbose=1, save_best_only=True, mode='min')\n",
    "#fit the model\n",
    "model.fit_generator(gen_flow, validation_data=(X_valid, Y_valid),\n",
    "                    steps_per_epoch=int(np.ceil(len(X_train)/batch_size)),\n",
    "                    epochs=500, verbose=1, callbacks=[early_stopping_callback, checkpoint_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Â IV. Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[32,64,224,224]\n\t [[Node: block1_conv2_1/convolution = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](block1_conv1_1/Relu, block1_conv2_1/kernel/read)]]\n\t [[Node: loss_1/mul/_923 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_274_loss_1/mul\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n\nCaused by op u'block1_conv2_1/convolution', defined at:\n  File \"/home/paul/anaconda2/lib/python2.7/runpy.py\", line 174, in _run_module_as_main\n    \"__main__\", fname, loader, pkg_name)\n  File \"/home/paul/anaconda2/lib/python2.7/runpy.py\", line 72, in _run_code\n    exec code in run_globals\n  File \"/home/paul/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/paul/anaconda2/lib/python2.7/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/paul/anaconda2/lib/python2.7/site-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/home/paul/anaconda2/lib/python2.7/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/paul/anaconda2/lib/python2.7/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/home/paul/anaconda2/lib/python2.7/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/paul/anaconda2/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/paul/anaconda2/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/paul/anaconda2/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/paul/anaconda2/lib/python2.7/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/paul/anaconda2/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/paul/anaconda2/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/paul/anaconda2/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/paul/anaconda2/lib/python2.7/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/paul/anaconda2/lib/python2.7/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/paul/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2718, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/paul/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2822, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/paul/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-13-7fae685cf408>\", line 1, in <module>\n    model = load_model(weights_path+\"BestKerasModelVGG16_flat.h5\")\n  File \"/home/paul/anaconda2/lib/python2.7/site-packages/keras/models.py\", line 239, in load_model\n    model = model_from_config(model_config, custom_objects=custom_objects)\n  File \"/home/paul/anaconda2/lib/python2.7/site-packages/keras/models.py\", line 313, in model_from_config\n    return layer_module.deserialize(config, custom_objects=custom_objects)\n  File \"/home/paul/anaconda2/lib/python2.7/site-packages/keras/layers/__init__.py\", line 55, in deserialize\n    printable_module_name='layer')\n  File \"/home/paul/anaconda2/lib/python2.7/site-packages/keras/utils/generic_utils.py\", line 139, in deserialize_keras_object\n    list(custom_objects.items())))\n  File \"/home/paul/anaconda2/lib/python2.7/site-packages/keras/engine/topology.py\", line 2500, in from_config\n    process_node(layer, node_data)\n  File \"/home/paul/anaconda2/lib/python2.7/site-packages/keras/engine/topology.py\", line 2457, in process_node\n    layer(input_tensors[0], **kwargs)\n  File \"/home/paul/anaconda2/lib/python2.7/site-packages/keras/engine/topology.py\", line 603, in __call__\n    output = self.call(inputs, **kwargs)\n  File \"/home/paul/anaconda2/lib/python2.7/site-packages/keras/layers/convolutional.py\", line 164, in call\n    dilation_rate=self.dilation_rate)\n  File \"/home/paul/anaconda2/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py\", line 3185, in conv2d\n    data_format=tf_data_format)\n  File \"/home/paul/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/nn_ops.py\", line 751, in convolution\n    return op(input, filter)\n  File \"/home/paul/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/nn_ops.py\", line 835, in __call__\n    return self.conv_op(inp, filter)\n  File \"/home/paul/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/nn_ops.py\", line 499, in __call__\n    return self.call(inp, filter)\n  File \"/home/paul/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/nn_ops.py\", line 187, in __call__\n    name=self.name)\n  File \"/home/paul/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/gen_nn_ops.py\", line 631, in conv2d\n    data_format=data_format, name=name)\n  File \"/home/paul/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/paul/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 2956, in create_op\n    op_def=op_def)\n  File \"/home/paul/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1470, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[32,64,224,224]\n\t [[Node: block1_conv2_1/convolution = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](block1_conv1_1/Relu, block1_conv2_1/kernel/read)]]\n\t [[Node: loss_1/mul/_923 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_274_loss_1/mul\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-7fae685cf408>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights_path\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"BestKerasModelVGG16_flat.h5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Test loss:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Test accuracy:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/paul/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps)\u001b[0m\n\u001b[1;32m   1690\u001b[0m                                \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m                                \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1692\u001b[0;31m                                steps=steps)\n\u001b[0m\u001b[1;32m   1693\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1694\u001b[0m     def predict(self, x,\n",
      "\u001b[0;32m/home/paul/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_test_loop\u001b[0;34m(self, f, ins, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1368\u001b[0m                     \u001b[0mins_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_slice_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1370\u001b[0;31m                 \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1371\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1372\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/paul/anaconda2/lib/python2.7/site-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2330\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[1;32m   2331\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2332\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2333\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2334\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/paul/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/paul/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/paul/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/paul/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1334\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1335\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1336\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1338\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[32,64,224,224]\n\t [[Node: block1_conv2_1/convolution = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](block1_conv1_1/Relu, block1_conv2_1/kernel/read)]]\n\t [[Node: loss_1/mul/_923 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_274_loss_1/mul\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n\nCaused by op u'block1_conv2_1/convolution', defined at:\n  File \"/home/paul/anaconda2/lib/python2.7/runpy.py\", line 174, in _run_module_as_main\n    \"__main__\", fname, loader, pkg_name)\n  File \"/home/paul/anaconda2/lib/python2.7/runpy.py\", line 72, in _run_code\n    exec code in run_globals\n  File \"/home/paul/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/paul/anaconda2/lib/python2.7/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/paul/anaconda2/lib/python2.7/site-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/home/paul/anaconda2/lib/python2.7/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/paul/anaconda2/lib/python2.7/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/home/paul/anaconda2/lib/python2.7/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/paul/anaconda2/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/paul/anaconda2/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/paul/anaconda2/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/paul/anaconda2/lib/python2.7/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/paul/anaconda2/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/paul/anaconda2/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/paul/anaconda2/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/paul/anaconda2/lib/python2.7/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/paul/anaconda2/lib/python2.7/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/paul/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2718, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/paul/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2822, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/paul/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-13-7fae685cf408>\", line 1, in <module>\n    model = load_model(weights_path+\"BestKerasModelVGG16_flat.h5\")\n  File \"/home/paul/anaconda2/lib/python2.7/site-packages/keras/models.py\", line 239, in load_model\n    model = model_from_config(model_config, custom_objects=custom_objects)\n  File \"/home/paul/anaconda2/lib/python2.7/site-packages/keras/models.py\", line 313, in model_from_config\n    return layer_module.deserialize(config, custom_objects=custom_objects)\n  File \"/home/paul/anaconda2/lib/python2.7/site-packages/keras/layers/__init__.py\", line 55, in deserialize\n    printable_module_name='layer')\n  File \"/home/paul/anaconda2/lib/python2.7/site-packages/keras/utils/generic_utils.py\", line 139, in deserialize_keras_object\n    list(custom_objects.items())))\n  File \"/home/paul/anaconda2/lib/python2.7/site-packages/keras/engine/topology.py\", line 2500, in from_config\n    process_node(layer, node_data)\n  File \"/home/paul/anaconda2/lib/python2.7/site-packages/keras/engine/topology.py\", line 2457, in process_node\n    layer(input_tensors[0], **kwargs)\n  File \"/home/paul/anaconda2/lib/python2.7/site-packages/keras/engine/topology.py\", line 603, in __call__\n    output = self.call(inputs, **kwargs)\n  File \"/home/paul/anaconda2/lib/python2.7/site-packages/keras/layers/convolutional.py\", line 164, in call\n    dilation_rate=self.dilation_rate)\n  File \"/home/paul/anaconda2/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py\", line 3185, in conv2d\n    data_format=tf_data_format)\n  File \"/home/paul/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/nn_ops.py\", line 751, in convolution\n    return op(input, filter)\n  File \"/home/paul/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/nn_ops.py\", line 835, in __call__\n    return self.conv_op(inp, filter)\n  File \"/home/paul/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/nn_ops.py\", line 499, in __call__\n    return self.call(inp, filter)\n  File \"/home/paul/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/nn_ops.py\", line 187, in __call__\n    name=self.name)\n  File \"/home/paul/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/gen_nn_ops.py\", line 631, in conv2d\n    data_format=data_format, name=name)\n  File \"/home/paul/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/paul/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 2956, in create_op\n    op_def=op_def)\n  File \"/home/paul/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1470, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[32,64,224,224]\n\t [[Node: block1_conv2_1/convolution = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](block1_conv1_1/Relu, block1_conv2_1/kernel/read)]]\n\t [[Node: loss_1/mul/_923 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_274_loss_1/mul\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n"
     ]
    }
   ],
   "source": [
    "model = load_model(weights_path+\"BestKerasModelVGG16_flat.h5\")\n",
    "score = model.evaluate(X_valid, Y_valid, verbose=1)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#compute log loss\n",
    "pred = model.predict(X_valid)\n",
    "log_loss(Y_valid,pred)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#Generate the training data\n",
    "#Create 3 bands having HH, HV and avg of both\n",
    "X_band_1=np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in train[\"band_1\"]])\n",
    "X_band_2=np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in train[\"band_2\"]])\n",
    "X_train = np.concatenate([X_band_1[:, :, :, np.newaxis], X_band_2[:, :, :, np.newaxis],\n",
    "                          ((X_band_1+X_band_2)/2)[:, :, :, np.newaxis]], axis=-1)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#parse corrupted notebook file\n",
    "t = [\"#Generate the training data\\n\",\n",
    "    \"#Create 3 bands having HH, HV and avg of both\\n\",\n",
    "    \"X_band_1=np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in train[\\\"band_1\\\"]])\\n\",\n",
    "    \"X_band_2=np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in train[\\\"band_2\\\"]])\\n\",\n",
    "    \"X_train = np.concatenate([X_band_1[:, :, :, np.newaxis], X_band_2[:, :, :, np.newaxis],\\n\",\n",
    "    \"                          ((X_band_1+X_band_2)/2)[:, :, :, np.newaxis]], axis=-1)\"]\n",
    "#t.remove(\"\\n\")\n",
    "t=[x.replace(\"\\n\",'') for x in t]\n",
    "for x in t:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
